## Updated at 2025-08-08 20:07:50

## 3DGS Semantic

Query: (abs:'Gaussian' OR abs:'Gaussians' OR abs:'GS' OR abs:'3DGS' OR abs:'3D-GS') AND (abs:'open vocabulary' OR abs:'semantic' OR abs:'semantics' OR abs:'language' OR abs:'segmentation' OR abs:'scene understanding' OR abs:'feature field' OR abs:'CLIP' OR abs:'SAM') AND cat:'cs.CV'

Prompt: 该论文的研究重点必须是扩展3D高斯溅射（3D Gaussian Splatting）技术，以实现的三维下的语义、实例、场景的理解任务。其方法可能（注意是可能，完全可能有其他方法）涉及从大规模二维预训练模型（如CLIP、SAM等）中提取、蒸馏或集成语义、实例或语言特征到3D高斯表示中。关键是论文的主要应用目标应为三维分割、开放词汇查询、或语言引导的编辑等，而不仅仅是新视角合成或几何重建。

|Date|Title|Comments|Journal|Authors|
|---|---|---|---|---|
|**2025-08-05**|**[Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images](https://arxiv.org/abs/2508.03643)**|The code is available at https://github.com/HorizonRobotics/Uni3R|None|Xiangyu Sun et al.|
|**2025-08-05**|**[Trace3D: Consistent Segmentation Lifting via Gaussian Instance Tracing](https://arxiv.org/abs/2508.03227)**|None|None|Hongyu Shen et al.|
|**2025-08-03**|**[AG$^2$aussian: Anchor-Graph Structured Gaussian Splatting for Instance-Level 3D Scene Understanding and Editing](https://arxiv.org/abs/2508.01740)**|None|None|Zhaonan Wang et al.|
|**2025-08-02**|**[OpenGS-Fusion: Open-Vocabulary Dense Mapping with Hybrid 3D Gaussian Splatting for Refined Object-Level Understanding](https://arxiv.org/abs/2508.01150)**|IROS2025|None|Dianyi Yang et al.|
|**2025-07-31**|**[SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting](https://arxiv.org/abs/2507.23772)**|None|None|Di Li et al.|
|**2025-07-10**|**[Seg-Wild: Interactive Segmentation based on 3D Gaussian Splatting for Unconstrained Image Collections](https://arxiv.org/abs/2507.07395)**|None|None|Yongtang Bao et al.|
|**2025-07-07**|**[Mastering Regional 3DGS: Locating, Initializing, and Editing with Diverse 2D Priors](https://arxiv.org/abs/2507.05426)**|None|None|Lanqing Guo et al.|
|**2025-07-01**|**[GaussianVLM: Scene-centric 3D Vision-Language Models using Language-aligned Gaussian Splats for Embodied Reasoning and Beyond](https://arxiv.org/abs/2507.00886)**|None|None|Anna-Maria Halacheva et al.|
|**2025-06-11**|**[SemanticSplat: Feed-Forward 3D Scene Understanding with Language-Aware Gaussian Fields](https://arxiv.org/abs/2506.09565)**|None|None|Qijing Li et al.|
|**2025-06-11**|**[UniForward: Unified 3D Scene and Semantic Field Reconstruction via Feed-Forward Gaussian Splatting from Only Sparse-View Images](https://arxiv.org/abs/2506.09378)**|None|None|Qijian Tian et al.|
|**2025-06-10**|**[SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting](https://arxiv.org/abs/2506.08710)**|15 pages, codes, data and benchmark will be released|None|Mengjiao Ma et al.|
|**2025-06-09**|**[OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting](https://arxiv.org/abs/2506.07697)**|None|None|Jens Piekenbrinck et al.|
|**2025-06-07**|**[Hi-LSplat: Hierarchical 3D Language Gaussian Splatting](https://arxiv.org/abs/2506.06822)**|None|None|Chenlu Zhan et al.|
|**2025-06-01**|**[CountingFruit: Language-Guided 3D Fruit Counting with Semantic Gaussian Splatting](https://arxiv.org/abs/2506.01109)**|None|None|Fengze Li et al.|
|**2025-05-30**|**[Tackling View-Dependent Semantics in 3D Language Gaussian Splatting](https://arxiv.org/abs/2505.24746)**|ICML 2025 camera ready. Project Page: https://jumpat.github.io/laga-page/|None|Jiazhong Cen et al.|
|**2025-05-26**|**[CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting](https://arxiv.org/abs/2505.20469)**|None|None|Lei Tian et al.|
|**2025-05-25**|**[FHGS: Feature-Homogenized Gaussian Splatting](https://arxiv.org/abs/2505.19154)**|None|None|Q. G. Duan et al.|
|**2025-05-12**|**[SLAG: Scalable Language-Augmented Gaussian Splatting](https://arxiv.org/abs/2505.08124)**|None|None|Laszlo Szilagyi et al.|
|**2025-04-20**|**[NVSMask3D: Hard Visual Prompting with Camera Pose Interpolation for 3D Open Vocabulary Instance Segmentation](https://arxiv.org/abs/2504.14638)**|15 pages, 4 figures, Scandinavian Conference on Image Analysis 2025|None|Junyuan Fang et al.|
|**2025-04-17**|**[Training-Free Hierarchical Scene Understanding for Gaussian Splatting with Superpoint Graphs](https://arxiv.org/abs/2504.13153)**|None|None|Shaohui Dai et al.|
|**2025-04-16**|**[CAGS: Open-Vocabulary 3D Scene Understanding with Context-Aware Gaussian Splatting](https://arxiv.org/abs/2504.11893)**|None|None|Wei Sun et al.|
|**2025-04-13**|**[TextSplat: Text-Guided Semantic Fusion for Generalizable Gaussian Splatting](https://arxiv.org/abs/2504.09588)**|None|None|Zhicong Wu et al.|
|**2025-04-11**|**[FMLGS: Fast Multilevel Language Embedded Gaussians for Part-level Interactive Agents](https://arxiv.org/abs/2504.08581)**|None|None|Xin Tan et al.|
|**2025-04-09**|**[Wheat3DGS: In-field 3D Reconstruction, Instance Segmentation and Phenotyping of Wheat Heads with Gaussian Splatting](https://arxiv.org/abs/2504.06978)**|Copyright 2025 IEEE. This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive version is published in the 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)|None|Daiwei Zhang et al.|
|**2025-04-08**|**[econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic Gaussians](https://arxiv.org/abs/2504.06003)**|None|None|Can Zhang, Gim Hee Lee|
|**2025-03-30**|**[ReasonGrounder: LVLM-Guided Hierarchical Feature Splatting for Open-Vocabulary 3D Visual Grounding and Reasoning](https://arxiv.org/abs/2503.23297)**|None|None|Zhenyang Liu et al.|
|**2025-03-28**|**[Segment then Splat: A Unified Approach for 3D Open-Vocabulary Segmentation based on Gaussian Splatting](https://arxiv.org/abs/2503.22204)**|Project page: https://vulab-ai.github.io/Segment-then-Splat/|None|Yiren Lu et al.|
|**2025-03-27**|**[Semantic Consistent Language Gaussian Splatting for Point-Level Open-vocabulary Querying](https://arxiv.org/abs/2503.21767)**|None|None|Hairong Yin et al.|
|**2025-03-26**|**[Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile Gaussian Feature Fields](https://arxiv.org/abs/2503.20776)**|None|None|Shijie Zhou et al.|
|**2025-03-23**|**[PanoGS: Gaussian-based Panoptic Segmentation for 3D Open Vocabulary Scene Understanding](https://arxiv.org/abs/2503.18107)**|CVPR 2025|None|Hongjia Zhai et al.|
|**2025-03-23**|**[PanopticSplatting: End-to-End Panoptic Gaussian Splatting](https://arxiv.org/abs/2503.18073)**|8 pages, 6 figures|None|Yuxuan Xie et al.|
|**2025-03-23**|**[SceneSplat: Gaussian Splatting-based Scene Understanding with Vision-Language Pretraining](https://arxiv.org/abs/2503.18052)**|Our code, model, and dataset will be released at https://unique1i.github.io/SceneSplat_webpage/|None|Yue Li et al.|
|**2025-03-18**|**[Rethinking End-to-End 2D to 3D Scene Segmentation in Gaussian Splatting](https://arxiv.org/abs/2503.14029)**|CVPR 2025. The code is publicly available at this https URL (https://github.com/Runsong123/Unified-Lift)|None|Runsong Zhu et al.|
|**2025-03-16**|**[SPC-GS: Gaussian Splatting with Semantic-Prompt Consistency for Indoor Open-World Free-view Synthesis from Sparse Inputs](https://arxiv.org/abs/2503.12535)**|Accepted by CVPR2025. The project page is available at https://gbliao.github.io/SPC-GS.github.io/|None|Guibiao Liao et al.|
|**2025-03-14**|**[EgoSplat: Open-Vocabulary Egocentric Scene Understanding with Language Embedded 3D Gaussian Splatting](https://arxiv.org/abs/2503.11345)**|None|None|Di Li et al.|
|**2025-03-13**|**[4D LangSplat: 4D Language Gaussian Splatting via Multimodal Large Language Models](https://arxiv.org/abs/2503.10437)**|CVPR 2025. Project Page: https://4d-langsplat.github.io|None|Wanhua Li et al.|
|**2025-03-11**|**[SAS: Segment Any 3D Scene with Integrated 2D Priors](https://arxiv.org/abs/2503.08512)**|None|None|Zhuoyuan Li et al.|
|**2025-03-11**|**[TT-Occ: Test-Time Compute for Self-Supervised Occupancy via Spatio-Temporal Gaussian Splatting](https://arxiv.org/abs/2503.08485)**|None|None|Fengyi Zhang et al.|
|**2025-03-07**|**[Bayesian Fields: Task-driven Open-Set Semantic Gaussian Splatting](https://arxiv.org/abs/2503.05949)**|None|None|Dominic Maggio, Luca Carlone|
|**2025-03-06**|**[GaussianGraph: 3D Gaussian-based Scene Graph Generation for Open-world Scene Understanding](https://arxiv.org/abs/2503.04034)**|None|None|Xihan Wang et al.|
|**2025-03-03**|**[OpenGS-SLAM: Open-Set Dense Semantic SLAM with 3D Gaussian Splatting for Object-Level Scene Understanding](https://arxiv.org/abs/2503.01646)**|None|None|Dianyi Yang et al.|
|**2025-02-27**|**[From Thousands to Billions: 3D Visual Language Grounding via Render-Supervised Distillation from 2D VLMs](https://arxiv.org/abs/2502.20389)**|Project page: https://liftgs.github.io|None|Ang Cao et al.|
|**2025-02-27**|**[Open-Vocabulary Semantic Part Segmentation of 3D Human](https://arxiv.org/abs/2502.19782)**|3DV 2025|None|Keito Suzuki et al.|
|**2025-02-25**|**[UniGS: Unified Language-Image-3D Pretraining with Gaussian Splatting](https://arxiv.org/abs/2502.17860)**|ICLR 2025; Corrected citation of Uni3D;|None|Haoyuan Li et al.|
|**2025-02-23**|**[Dr. Splat: Directly Referring 3D Gaussian Splatting via Direct Language Embedding Registration](https://arxiv.org/abs/2502.16652)**|20 pages|None|Kim Jun-Seong et al.|
|**2025-02-07**|**[AutoOcc: Automatic Open-Ended Semantic Occupancy Annotation via Vision-Language Guided Gaussian Splatting](https://arxiv.org/abs/2502.04981)**|None|None|Xiaoyu Zhou et al.|
|**2025-01-31**|**[Lifting by Gaussians: A Simple, Fast and Flexible Method for 3D Instance Segmentation](https://arxiv.org/abs/2502.00173)**|Accepted to WACV 2025|None|Rohan Chacko et al.|
|**2025-01-02**|**[Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic Reconstruction](https://arxiv.org/abs/2501.01119)**|18 pages, 10 figures|None|Xuan Yu et al.|
|**2024-12-31**|**[PanoSLAM: Panoptic 3D Scene Reconstruction via Gaussian SLAM](https://arxiv.org/abs/2501.00352)**|None|None|Runnan Chen et al.|
|**2024-12-31**|**[OVGaussian: Generalizable 3D Gaussian Segmentation with Open Vocabularies](https://arxiv.org/abs/2501.00326)**|None|None|Runnan Chen et al.|
|**2024-12-23**|**[LangSurf: Language-Embedded Surface Gaussians for 3D Scene Understanding](https://arxiv.org/abs/2412.17635)**|\url{https://langsurf.github.io}|None|Hao Li et al.|
|**2024-12-22**|**[GSemSplat: Generalizable Semantic 3D Gaussian Splatting from Uncalibrated Image Pairs](https://arxiv.org/abs/2412.16932)**|None|None|Xingrui Wang et al.|
|**2024-12-18**|**[GAGS: Granularity-Aware Feature Distillation for Language Gaussian Splatting](https://arxiv.org/abs/2412.13654)**|Project page: https://pz0826.github.io/GAGS-Webpage/|None|Yuning Peng et al.|
|**2024-12-17**|**[GaussTR: Foundation Model-Aligned Gaussian Transformer for Self-Supervised 3D Spatial Understanding](https://arxiv.org/abs/2412.13193)**|CVPR 2025|None|Haoyi Jiang et al.|
|**2024-12-14**|**[DCSEG: Decoupled 3D Open-Set Segmentation using Gaussian Splatting](https://arxiv.org/abs/2412.10972)**|To be published in CVPR Workshop on Open-World 3D Scene Understanding with Foundation Models|None|Luis Wiedmann et al.|
|**2024-12-13**|**[SuperGSeg: Open-Vocabulary 3D Segmentation with Structured Super-Gaussians](https://arxiv.org/abs/2412.10231)**|13 pages, 8 figures|None|Siyun Liang et al.|
|**2024-12-11**|**[SLGaussian: Fast Language Gaussian Splatting in Sparse Views](https://arxiv.org/abs/2412.08331)**|Accepted by ACM MM 2025. Project page: https://chenkangjie1123.github.io/SLGaussian.github.io/|None|Kangjie Chen et al.|
|**2024-12-08**|**[Efficient Semantic Splatting for Remote Sensing Multi-view Segmentation](https://arxiv.org/abs/2412.05969)**|None|None|Zipeng Qi et al.|
|**2024-12-03**|**[SparseLGS: Sparse View Language Embedded Gaussian Splatting](https://arxiv.org/abs/2412.02245)**|Project Page: https://ustc3dv.github.io/SparseLGS|None|Jun Hu et al.|
|**2024-12-02**|**[Occam's LGS: An Efficient Approach for Language Gaussian Splatting](https://arxiv.org/abs/2412.01807)**|Project Page: https://insait-institute.github.io/OccamLGS/|None|Jiahuan Cheng et al.|
|**2024-12-02**|**[3DSceneEditor: Controllable 3D Scene Editing with Gaussian Splatting](https://arxiv.org/abs/2412.01583)**|Project Page: https://ziyangyan.github.io/3DSceneEditor|None|Ziyang Yan et al.|
|**2024-12-01**|**[ChatSplat: 3D Conversational Gaussian Splatting](https://arxiv.org/abs/2412.00734)**|None|None|Hanlin Chen et al.|
|**2024-11-30**|**[GradiSeg: Gradient-Guided Gaussian Segmentation with Enhanced 3D Boundary Precision](https://arxiv.org/abs/2412.00392)**|None|None|Zehao Li et al.|
|**2024-11-29**|**[Bootstraping Clustering of Gaussians for View-consistent 3D Scene Understanding](https://arxiv.org/abs/2411.19551)**|Accepted to AAAI25|None|Wenbo Zhang et al.|
|**2024-11-28**|**[SADG: Segment Any Dynamic Gaussian Without Object Trackers](https://arxiv.org/abs/2411.19290)**|Project page https://yunjinli.github.io/project-sadg|None|Yun-Jin Li et al.|
|**2024-11-28**|**[InstanceGaussian: Appearance-Semantic Joint Gaussian Representation for 3D Instance-Level Perception](https://arxiv.org/abs/2411.19235)**|14 pages, accepted by CVPR 2025 as poster|None|Haijie Li et al.|
|**2024-11-27**|**[GLS: Geometry-aware 3D Language Gaussian Splatting](https://arxiv.org/abs/2411.18066)**|Technical Report|None|Jiaxiong Qiu et al.|
|**2024-11-22**|**[Open-Vocabulary Online Semantic Mapping for SLAM](https://arxiv.org/abs/2411.15043)**|None|None|Tomas Berriel Martins et al.|
|**2024-11-20**|**[FAST-Splat: Fast, Ambiguity-Free Semantics Transfer in Gaussian Splatting](https://arxiv.org/abs/2411.13753)**|None|None|Ola Shorinwa et al.|
|**2024-11-12**|**[GaussianCut: Interactive segmentation via graph cut for 3D Gaussian Splatting](https://arxiv.org/abs/2411.07555)**|None|None|Umangi Jain et al.|
|**2024-10-24**|**[Large Spatial Model: End-to-end Unposed Images to Semantic 3D](https://arxiv.org/abs/2410.18956)**|Project Website: https://largespatialmodel.github.io|None|Zhiwen Fan et al.|
|**2024-10-23**|**[PLGS: Robust Panoptic Lifting with 3D Gaussian Splatting](https://arxiv.org/abs/2410.17505)**|None|None|Yu Wang et al.|
|**2024-10-18**|**[LUDVIG: Learning-Free Uplifting of 2D Visual Features to Gaussian Splatting Scenes](https://arxiv.org/abs/2410.14462)**|Published at ICCV 2025. Project page: https://juliettemarrie.github.io/ludvig|None|Juliette Marrie et al.|
|**2024-10-10**|**[3D Vision-Language Gaussian Splatting](https://arxiv.org/abs/2410.07577)**|Accepted at ICLR 2025. Main paper + supplementary material|None|Qucheng Peng et al.|
|**2024-09-24**|**[Semantics-Controlled Gaussian Splatting for Outdoor Scene Reconstruction and Rendering in Virtual Reality](https://arxiv.org/abs/2409.15959)**|None|None|Hannah Schieber et al.|
|**2024-09-18**|**[Gradient-Driven 3D Segmentation and Affordance Transfer in Gaussian Splatting Using 2D Masks](https://arxiv.org/abs/2409.11681)**|Preprint, Under review for ICRA 2025|None|Joji Joseph et al.|
|**2024-08-14**|**[Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space](https://arxiv.org/abs/2408.07416)**|AAAI 2025. Project page: https://hyunji12.github.io/Open3DRF|None|Hyunjee Lee et al.|
|**2024-08-07**|**[Query3D: LLM-Powered Open-Vocabulary Scene Segmentation with Language Embedded 3D Gaussian](https://arxiv.org/abs/2408.03516)**|None|None|Amirhosein Chahe, Lifeng Zhou|
|**2024-07-16**|**[Click-Gaussian: Interactive Segmentation to Any 3D Gaussians](https://arxiv.org/abs/2407.11793)**|Accepted to ECCV 2024. The first two authors contributed equally to this work|None|Seokhun Choi et al.|
|**2024-07-05**|**[Segment Any 4D Gaussians](https://arxiv.org/abs/2407.04504)**|22 pages|None|Shengxiang Ji et al.|
|**2024-07-01**|**[Fast and Efficient: Mask Neural Fields for 3D Scene Segmentation](https://arxiv.org/abs/2407.01220)**|15 pages, 9 figures, Code:https://github.com/keloee/MaskField|None|Zihan Gao et al.|
|**2024-06-04**|**[OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary Understanding](https://arxiv.org/abs/2406.02058)**|NeurIPS2024|None|Yanmin Wu et al.|
|**2024-06-04**|**[FastLGS: Speeding up Language Embedded Gaussians with Feature Grid Mapping](https://arxiv.org/abs/2406.01916)**|This paper is accepted to AAAI 2025|None|Yuzhou Ji et al.|
|**2024-05-29**|**[DGD: Dynamic 3D Gaussians Distillation](https://arxiv.org/abs/2405.19321)**|None|None|Isaac Labe et al.|
|**2024-05-28**|**[RT-GS2: Real-Time Generalizable Semantic Segmentation for 3D Gaussian Representations of Radiance Fields](https://arxiv.org/abs/2405.18033)**|Accepted paper at BMVC 2024|None|Mihnea-Bogdan Jurca et al.|
|**2024-05-27**|**[GOI: Find 3D Gaussians of Interest with an Optimizable Open-vocabulary Semantic-space Hyperplane](https://arxiv.org/abs/2405.17596)**|Our project page is available at https://quyans.github.io/GOI-Hyperplane/|None|Yansong Qu et al.|
|**2024-05-23**|**[TIGER: Text-Instructed 3D Gaussian Retrieval and Coherent Editing](https://arxiv.org/abs/2405.14455)**|None|None|Teng Xu et al.|
|**2024-04-22**|**[CLIP-GS: CLIP-Informed Gaussian Splatting for View-Consistent 3D Indoor Semantic Understanding](https://arxiv.org/abs/2404.14249)**|ACM TOMM 2025|None|Guibiao Liao et al.|
|**2024-04-19**|**[Contrastive Gaussian Clustering: Weakly Supervised 3D Scene Segmentation](https://arxiv.org/abs/2404.12784)**|None|None|Myrna C. Silva et al.|
|**2024-04-01**|**[Feature Splatting: Language-Driven Physics-Based Scene Synthesis and Editing](https://arxiv.org/abs/2404.01223)**|Project website: https://feature-splatting.github.io/|None|Ri-Zhao Qiu et al.|
|**2024-03-26**|**[EgoLifter: Open-world 3D Segmentation for Egocentric Perception](https://arxiv.org/abs/2403.18118)**|ECCV 2024 camera ready version. Project page: https://egolifter.github.io/|None|Qiao Gu et al.|
|**2024-03-22**|**[Semantic Gaussians: Open-Vocabulary Scene Understanding with 3D Gaussian Splatting](https://arxiv.org/abs/2403.15624)**|Project page: see https://semantic-gaussians.github.io|None|Jun Guo et al.|
|**2024-03-19**|**[HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting](https://arxiv.org/abs/2403.12722)**|Our project page is at https://xdimlab.github.io/hugs_website|None|Hongyu Zhou et al.|
|**2024-02-09**|**[GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D Pretraining from Real-World Data](https://arxiv.org/abs/2402.06198)**|The content of the technical report needs to be updated and retracted to avoid other impacts|None|Haoyuan Li et al.|
|**2024-01-31**|**[SAGD: Boundary-Enhanced Segment Anything in 3D Gaussian via Gaussian Decomposition](https://arxiv.org/abs/2401.17857)**|None|None|Xu Hu et al.|
|**2024-01-11**|**[Learning Segmented 3D Gaussians via Efficient Feature Unprojection for Zero-shot Neural Scene Segmentation](https://arxiv.org/abs/2401.05925)**|16 pages, 9 figures, correct writing details|None|Bin Dou et al.|
|**2024-01-03**|**[FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://arxiv.org/abs/2401.01970)**|Project page: https://xingxingzuo.github.io/fmgs|None|Xingxing Zuo et al.|
|**2023-12-26**|**[LangSplat: 3D Language Gaussian Splatting](https://arxiv.org/abs/2312.16084)**|CVPR 2024. Project Page: https://langsplat.github.io|None|Minghan Qin et al.|
|**2023-12-06**|**[Feature 3DGS: Supercharging 3D Gaussian Splatting to Enable Distilled Feature Fields](https://arxiv.org/abs/2312.03203)**|None|None|Shijie Zhou et al.|
|**2023-12-01**|**[Segment Any 3D Gaussians](https://arxiv.org/abs/2312.00860)**|AAAI-25. Project page: https://jumpat.github.io/SAGA|None|Jiazhong Cen et al.|
|**2023-12-01**|**[Gaussian Grouping: Segment and Edit Anything in 3D Scenes](https://arxiv.org/abs/2312.00732)**|ECCV 2024. Gaussian Grouping extends Gaussian Splatting to fine-grained open-world 3D scene understanding. Github: https://github.com/lkeab/gaussian-grouping|None|Mingqiao Ye et al.|
|**2023-11-30**|**[Language Embedded 3D Gaussians for Open-Vocabulary Scene Understanding](https://arxiv.org/abs/2311.18482)**|None|None|Jin-Chuan Shi et al.|

## MVS

Query: (abs:'Multi-View Stereo' OR abs:'Multi View Stereo' OR abs:'Multi-View Depth' OR abs:'Multi View Depth') AND cat:'cs.CV'

|Date|Title|Comments|Journal|Authors|
|---|---|---|---|---|
|**2025-08-06**|**[MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction](https://arxiv.org/abs/2508.04297)**|This work is accepted by ICCV 2025|None|Yaopeng Lou et al.|
|**2025-08-02**|**[Construction of Digital Terrain Maps from Multi-view Satellite Imagery using Neural Volume Rendering](https://arxiv.org/abs/2508.01386)**|None|None|Josef X. Biberstein et al.|
|**2025-07-24**|**[Unposed 3DGS Reconstruction with Probabilistic Procrustes Mapping](https://arxiv.org/abs/2507.18541)**|None|None|Chong Cheng et al.|
|**2025-07-18**|**[TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views](https://arxiv.org/abs/2507.13929)**|Accepted by MM 2024|None|Hsiang-Hui Hung et al.|
|**2025-07-17**|**[Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation](https://arxiv.org/abs/2507.13486)**|16 pages, 9 figures, this manuscript has been submitted to ISPRS Journal of Photogrammetry and Remote Sensing for consideration|None|Debao Huang, Rongjun Qin|
|**2025-07-15**|**[MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network](https://arxiv.org/abs/2507.11333)**|Accepted by ICCV 2025|None|Jianfei Jiang et al.|
|**2025-07-14**|**[Kaleidoscopic Background Attack: Disrupting Pose Estimation with Multi-Fold Radial Symmetry Textures](https://arxiv.org/abs/2507.10265)**|Accepted at ICCV 2025. Project page is available at https://wakuwu.github.io/KBA|None|Xinlong Ding et al.|
|**2025-07-11**|**[Review of Feed-forward 3D Reconstruction: From DUSt3R to VGGT](https://arxiv.org/abs/2507.08448)**|None|None|Wei Zhang et al.|
|**2025-06-29**|**[BridgeShape: Latent Diffusion Schrödinger Bridge for 3D Shape Completion](https://arxiv.org/abs/2506.23205)**|None|None|Dequan Kong et al.|
|**2025-06-16**|**[Test3R: Learning to Reconstruct 3D at Test Time](https://arxiv.org/abs/2506.13750)**|None|None|Yuheng Yuan et al.|
|**2025-06-16**|**[DVP-MVS++: Synergize Depth-Normal-Edge and Harmonized Visibility Prior for Multi-View Stereo](https://arxiv.org/abs/2506.13215)**|None|None|Zhenlong Yuan et al.|
|**2025-06-06**|**[Aerial Multi-View Stereo via Adaptive Depth Range Inference and Normal Cues](https://arxiv.org/abs/2506.05655)**|IEEE TGRS 2025|None|Yimei Liu et al.|
|**2025-06-04**|**[Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation](https://arxiv.org/abs/2506.04225)**|None|None|Tianyu Huang et al.|
|**2025-06-04**|**[Multi-view Surface Reconstruction Using Normal and Reflectance Cues](https://arxiv.org/abs/2506.04115)**|22 pages, 15 figures, 11 tables. A thorough qualitative and quantitive study is available in the supplementary material at https://drive.google.com/file/d/1KDfCKediXNP5Os954TL_QldaUWS0nKcD/view?usp=drive_link|None|Robin Bruneau et al.|
|**2025-06-04**|**[JointSplat: Probabilistic Joint Flow-Depth Optimization for Sparse-View Gaussian Splatting](https://arxiv.org/abs/2506.03872)**|None|None|Yang Xiao et al.|
|**2025-05-31**|**[XYZ-IBD: A High-precision Bin-picking Dataset for Object 6D Pose Estimation Capturing Real-world Industrial Complexity](https://arxiv.org/abs/2506.00599)**|None|None|Junwen Huang et al.|
|**2025-05-19**|**[3D Visual Illusion Depth Estimation](https://arxiv.org/abs/2505.13061)**|Project: https://github.com/YaoChengTang/3D-Visual-Illusion-Depth-Estimation|None|Chengtang Yao et al.|
|**2025-05-19**|**[IA-MVS: Instance-Focused Adaptive Depth Sampling for Multi-View Stereo](https://arxiv.org/abs/2505.12714)**|None|None|Yinzhe Wang et al.|
|**2025-05-11**|**[Enhancing Monocular Height Estimation via Sparse LiDAR-Guided Correction](https://arxiv.org/abs/2505.06905)**|None|None|Jian Song et al.|
|**2025-05-06**|**[Blending 3D Geometry and Machine Learning for Multi-View Stereopsis](https://arxiv.org/abs/2505.03470)**|A pre-print -- paper under-review. arXiv admin note: substantial text overlap with arXiv:2310.19583|None|Vibhas Vats et al.|
|**2025-05-04**|**[SparSplat: Fast Multi-View Reconstruction with Generalizable 2D Gaussian Splatting](https://arxiv.org/abs/2505.02175)**|Project page : https://shubhendu-jena.github.io/SparSplat/|None|Shubhendu Jena et al.|
|**2025-05-03**|**[AquaGS: Fast Underwater Scene Reconstruction with SfM-Free Gaussian Splatting](https://arxiv.org/abs/2505.01799)**|None|None|Junhao Shi et al.|
|**2025-04-29**|**[Sparse2DGS: Geometry-Prioritized Gaussian Splatting for Surface Reconstruction from Sparse Views](https://arxiv.org/abs/2504.20378)**|CVPR 2025|None|Jiang Wu et al.|
|**2025-04-25**|**[Dense Geometry Supervision for Underwater Depth Estimation](https://arxiv.org/abs/2504.18233)**|None|None|Wenxiang Gua, Lin Qia|
|**2025-04-22**|**[DERD-Net: Learning Depth from Event-based Ray Densities](https://arxiv.org/abs/2504.15863)**|13 pages, 3 figures, 14 tables. Project page: https://github.com/tub-rip/DERD-Net|None|Diego de Oliveira Hitzges et al.|
|**2025-04-16**|**[Boosting Multi-View Stereo with Depth Foundation Model in the Absence of Real-World Labels](https://arxiv.org/abs/2504.11845)**|None|None|Jie Zhu et al.|
|**2025-04-14**|**[ESCT3D: Efficient and Selectively Controllable Text-Driven 3D Content Generation with Gaussian Splatting](https://arxiv.org/abs/2504.10316)**|None|None|Huiqi Wu et al.|
|**2025-03-31**|**[Detail-aware multi-view stereo network for depth estimation](https://arxiv.org/abs/2503.23684)**|None|None|Haitao Tian et al.|
|**2025-03-28**|**[MVSAnywhere: Zero-Shot Multi-View Stereo](https://arxiv.org/abs/2503.22430)**|CVPR 2025|None|Sergio Izquierdo et al.|
|**2025-03-27**|**[ICG-MVSNet: Learning Intra-view and Cross-view Relationships for Guidance in Multi-View Stereo](https://arxiv.org/abs/2503.21525)**|None|None|Yuxi Hu et al.|
|**2025-03-21**|**[Pow3R: Empowering Unconstrained 3D Reconstruction with Camera and Scene Priors](https://arxiv.org/abs/2503.17316)**|CVPR 2025|None|Wonbong Jang et al.|
|**2025-03-21**|**[DroneSplat: 3D Gaussian Splatting for Robust 3D Reconstruction from In-the-Wild Drone Imagery](https://arxiv.org/abs/2503.16964)**|None|None|Jiadong Tang et al.|
|**2025-03-17**|**[SED-MVS: Segmentation-Driven and Edge-Aligned Deformation Multi-View Stereo with Depth Restoration and Occlusion Constraint](https://arxiv.org/abs/2503.13721)**|None|None|Zhenlong Yuan et al.|
|**2025-03-17**|**[Improving Geometric Consistency for 360-Degree Neural Radiance Fields in Indoor Scenarios](https://arxiv.org/abs/2503.13710)**|None|Proc. VISAPP 2025|Iryna Repinetska et al.|
|**2025-03-17**|**[Scale Efficient Training for Large Datasets](https://arxiv.org/abs/2503.13385)**|Accepted by CVPR2025|None|Qing Zhou et al.|
|**2025-03-15**|**[3D Gaussian Splatting against Moving Objects for High-Fidelity Street Scene Reconstruction](https://arxiv.org/abs/2503.12001)**|None|None|Peizhen Zheng et al.|
|**2025-03-14**|**[VGGT: Visual Geometry Grounded Transformer](https://arxiv.org/abs/2503.11651)**|CVPR 2025, Project Page: https://vgg-t.github.io/|None|Jianyuan Wang et al.|
|**2025-03-11**|**[CL-MVSNet: Unsupervised Multi-view Stereo with Dual-level Contrastive Learning](https://arxiv.org/abs/2503.08219)**|Accpetd by ICCV2023|None|Kaiqiang Xiong et al.|
|**2025-03-03**|**[MUSt3R: Multi-view Network for Stereo 3D Reconstruction](https://arxiv.org/abs/2503.01661)**|Accepted at CVPR 2025|None|Yohann Cabon et al.|
|**2025-01-30**|**[Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric Diffusion](https://arxiv.org/abs/2501.18804)**|Project page: https://mvgd.github.io|None|Vitor Guizilini et al.|
|**2025-01-21**|**[Fast Underwater Scene Reconstruction using Multi-View Stereo and Physical Imaging](https://arxiv.org/abs/2501.11884)**|None|None|Shuyi Hu, Qi Liu|
|**2025-01-12**|**[CULTURE3D: A Large-Scale and Diverse Dataset of Cultural Landmarks and Terrains for Gaussian-Based Scene Rendering](https://arxiv.org/abs/2501.06927)**|None|None|Xinyi Zheng et al.|
|**2025-01-02**|**[TS-SatMVSNet: Slope Aware Height Estimation for Large-Scale Earth Terrain Multi-view Stereo](https://arxiv.org/abs/2501.01049)**|None|None|Song Zhang et al.|
|**2024-12-29**|**[Dual-Level Precision Edges Guided Multi-View Stereo with Accurate Planarization](https://arxiv.org/abs/2412.20328)**|Accepted by AAAI25|None|Kehua Chen et al.|
|**2024-12-28**|**[DepthMamba with Adaptive Fusion](https://arxiv.org/abs/2412.19964)**|None|None|Zelin Meng, Zhichen Wang|
|**2024-12-27**|**[Dust to Tower: Coarse-to-Fine Photo-Realistic Scene Reconstruction from Sparse Uncalibrated Images](https://arxiv.org/abs/2412.19518)**|None|None|Xudong Cai et al.|
|**2024-12-26**|**[MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo](https://arxiv.org/abs/2412.19130)**|7 pages, 6 figures, submitted to IEEE ICRA 2025|None|Byeonggwon Lee et al.|
|**2024-12-19**|**[Improving Geometry in Sparse-View 3DGS via Reprojection-based DoF Separation](https://arxiv.org/abs/2412.14568)**|11 pages|None|Yongsung Kim et al.|
|**2024-12-16**|**[CAP4D: Creating Animatable 4D Portrait Avatars with Morphable Multi-View Diffusion Models](https://arxiv.org/abs/2412.12093)**|23 pages, 15 figures|None|Felix Taubner et al.|
|**2024-12-16**|**[DVP-MVS: Synergize Depth-Edge and Visibility Prior for Multi-View Stereo](https://arxiv.org/abs/2412.11578)**|None|None|Zhenlong Yuan et al.|
|**2024-12-16**|**[RoMeO: Robust Metric Visual Odometry](https://arxiv.org/abs/2412.11530)**|None|None|Junda Cheng et al.|
|**2024-12-09**|**[MV-DUSt3R+: Single-Stage Scene Reconstruction from Sparse Views In 2 Seconds](https://arxiv.org/abs/2412.06974)**|None|None|Zhenggang Tang et al.|
|**2024-12-08**|**[Lightweight Spatial Embedding for Vision-based 3D Occupancy Prediction](https://arxiv.org/abs/2412.05976)**|None|None|Jinqing Zhang et al.|
|**2024-12-08**|**[Prism: Semi-Supervised Multi-View Stereo with Monocular Structure Priors](https://arxiv.org/abs/2412.05771)**|11 pages, 6 figures, 3 tables|None|Alex Rich et al.|
|**2024-12-02**|**[World-consistent Video Diffusion with Explicit 3D Modeling](https://arxiv.org/abs/2412.01821)**|16 pages, 10 figures|None|Qihang Zhang et al.|
|**2024-11-29**|**[GausSurf: Geometry-Guided 3D Gaussian Splatting for Surface Reconstruction](https://arxiv.org/abs/2411.19454)**|Project page: https://jiepengwang.github.io/GausSurf/|None|Jiepeng Wang et al.|
|**2024-11-24**|**[PriorDiffusion: Leverage Language Prior in Diffusion Models for Monocular Depth Estimation](https://arxiv.org/abs/2411.16750)**|None|None|Ziyao Zeng et al.|
|**2024-11-15**|**[The Oxford Spires Dataset: Benchmarking Large-Scale LiDAR-Visual Localisation, Reconstruction and Radiance Field Methods](https://arxiv.org/abs/2411.10546)**|Website: https://dynamic.robots.ox.ac.uk/datasets/oxford-spires/|None|Yifu Tao et al.|
|**2024-11-08**|**[From Transparent to Opaque: Rethinking Neural Implicit Surfaces with $α$-NeuS](https://arxiv.org/abs/2411.05362)**|NeurIPS 2024|None|Haoran Zhang et al.|
|**2024-11-04**|**[A Global Depth-Range-Free Multi-View Stereo Transformer Network with Pose Embedding](https://arxiv.org/abs/2411.01893)**|None|None|Yitong Dong et al.|
|**2024-10-24**|**[Segmentation-aware Prior Assisted Joint Global Information Aggregated 3D Building Reconstruction](https://arxiv.org/abs/2410.18433)**|None|None|Hongxin Peng et al.|
|**2024-10-17**|**[DepthSplat: Connecting Gaussian Splatting and Depth](https://arxiv.org/abs/2410.13862)**|CVPR 2025, Project page: https://haofeixu.github.io/depthsplat/, Code: https://github.com/cvg/depthsplat|None|Haofei Xu et al.|
|**2024-10-15**|**[MCGS: Multiview Consistency Enhancement for Sparse-View 3D Gaussian Radiance Fields](https://arxiv.org/abs/2410.11394)**|None|None|Yuru Xiao et al.|
|**2024-09-22**|**[MVPGS: Excavating Multi-view Priors for Gaussian Splatting from Sparse Input Views](https://arxiv.org/abs/2409.14316)**|Accepted by ECCV 2024, Project page: https://zezeaaa.github.io/projects/MVPGS/|None|Wangze Xu et al.|
|**2024-09-20**|**[Towards Zero-shot Point Cloud Anomaly Detection: A Multi-View Projection Framework](https://arxiv.org/abs/2409.13162)**|None|None|Yuqi Cheng et al.|
|**2024-09-04**|**[UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views](https://arxiv.org/abs/2409.02917)**|Accepted to IEEE Transactions on Medical Imaging|None|Jiaxin Guo et al.|
|**2024-09-03**|**[EPRecon: An Efficient Framework for Real-Time Panoptic 3D Reconstruction from Monocular Video](https://arxiv.org/abs/2409.01807)**|None|None|Zhen Zhou et al.|
|**2024-08-31**|**[3D Gaussian Splatting for Large-scale Surface Reconstruction from Aerial Images](https://arxiv.org/abs/2409.00381)**|12 pages|None|YuanZheng Wu et al.|
|**2024-08-29**|**[Spurfies: Sparse Surface Reconstruction using Local Geometry Priors](https://arxiv.org/abs/2408.16544)**|https://geometric-rl.mpi-inf.mpg.de/spurfies/|None|Kevin Raj et al.|
|**2024-08-27**|**[Learning-based Multi-View Stereo: A Survey](https://arxiv.org/abs/2408.15235)**|None|None|Fangjinhua Wang et al.|
|**2024-08-20**|**[Multi-view Hand Reconstruction with a Point-Embedded Transformer](https://arxiv.org/abs/2408.10581)**|Generalizable multi-view Hand Mesh Reconstruction (HMR) model. Extension of the original work at CVPR2023|None|Lixin Yang et al.|
|**2024-08-13**|**[GeoFormer: Learning Point Cloud Completion with Tri-Plane Integrated Transformer](https://arxiv.org/abs/2408.06596)**|accepted by the 32nd ACM International Conference on Multimedia (MM'24)|None|Jinpeng Yu et al.|
|**2024-08-07**|**[CLIP-based Point Cloud Classification via Point Cloud to Image Translation](https://arxiv.org/abs/2408.03545)**|Accepted by ICPR2024|None|Shuvozit Ghose et al.|
|**2024-08-04**|**[Improving Neural Surface Reconstruction with Feature Priors from Multi-View Image](https://arxiv.org/abs/2408.02079)**|ECCV2024|None|Xinlin Ren et al.|
|**2024-08-04**|**[PanicleNeRF: low-cost, high-precision in-field phenotypingof rice panicles with smartphone](https://arxiv.org/abs/2408.02053)**|None|None|Xin Yang et al.|
|**2024-07-27**|**[MSP-MVS: Multi-Granularity Segmentation Prior Guided Multi-View Stereo](https://arxiv.org/abs/2407.19323)**|None|None|Zhenlong Yuan et al.|
|**2024-07-25**|**[Towards the Spectral bias Alleviation by Normalizations in Coordinate Networks](https://arxiv.org/abs/2407.17834)**|None|None|Zhicheng Cai et al.|
|**2024-07-19**|**[SparseCraft: Few-Shot Neural Reconstruction through Stereopsis Guided Geometric Linearization](https://arxiv.org/abs/2407.14257)**|ECCV 2024. Project page: https://sparsecraft.github.io|None|Mae Younes et al.|
|**2024-07-16**|**[MVG-Splatting: Multi-View Guided Gaussian Splatting with Adaptive Quantile-Based Geometric Consistency Densification](https://arxiv.org/abs/2407.11840)**|https://mvgsplatting.github.io|None|Zhuoxiao Li et al.|
|**2024-07-13**|**[Unsupervised 3D Point Cloud Completion via Multi-view Adversarial Learning](https://arxiv.org/abs/2407.09786)**|Accepted in IEEE TVCG|None|Lintai Wu et al.|
|**2024-07-09**|**[Computer vision tasks for intelligent aerospace missions: An overview](https://arxiv.org/abs/2407.06513)**|23 pages, 7 figures, journal|None|Huilin Chen et al.|
|**2024-06-26**|**[DoubleTake: Geometry Guided Depth Estimation](https://arxiv.org/abs/2406.18387)**|ECCV 2024 Version|None|Mohamed Sayed et al.|
|**2024-06-19**|**[MVSBoost: An Efficient Point Cloud-based 3D Reconstruction](https://arxiv.org/abs/2406.13515)**|The work is under review|None|Umair Haroon et al.|
|**2024-06-01**|**[Topo4D: Topology-Preserving Gaussian Splatting for High-Fidelity 4D Head Capture](https://arxiv.org/abs/2406.00440)**|None|None|Xuanchen Li et al.|
|**2024-05-27**|**[SDL-MVS: View Space and Depth Deformable Learning Paradigm for Multi-View Stereo Reconstruction in Remote Sensing](https://arxiv.org/abs/2405.17140)**|None|None|Yong-Qiang Mao et al.|
|**2024-05-24**|**[Transparent Object Depth Completion](https://arxiv.org/abs/2405.15299)**|None|None|Yifan Zhou et al.|
|**2024-05-21**|**[Cross-spectral Gated-RGB Stereo Depth Estimation](https://arxiv.org/abs/2405.12759)**|None|None|Samuel Brucker et al.|
|**2024-05-20**|**[MVSGaussian: Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo](https://arxiv.org/abs/2405.12218)**|ECCV2024, Project page: https://mvsgaussian.github.io/ , Code: https://github.com/TQTQliu/MVSGaussian|None|Tianqi Liu et al.|
|**2024-05-15**|**[RobustMVS: Single Domain Generalized Deep Multi-view Stereo](https://arxiv.org/abs/2405.09131)**|Accepted to TCSVT. Code will be released at: https://github.com/ToughStoneX/Robust-MVS. Benchmark will be released at: https://github.com/ToughStoneX/MVS_Evaluation_Benchmark|None|Hongbin Xu et al.|
|**2024-05-14**|**[The RoboDrive Challenge: Drive Anytime Anywhere in Any Condition](https://arxiv.org/abs/2405.08816)**|ICRA 2024; 32 pages, 24 figures, 5 tables; Code at https://robodrive-24.github.io/|None|Lingdong Kong et al.|
|**2024-05-13**|**[SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling](https://arxiv.org/abs/2405.07847)**|Accepted to IEEE Transactions on Robotics (T-RO). For project page and code, please find https://jarrome.github.io/SceneFactory/|None|Yijun Yuan et al.|
|**2024-05-10**|**[MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization](https://arxiv.org/abs/2405.06241)**|Accepted by IEEE Robotics and Automation Letters|None|Pengcheng Zhu et al.|
|**2024-05-08**|**[Geometry-Informed Distance Candidate Selection for Adaptive Lightweight Omnidirectional Stereo Vision with Fisheye Images](https://arxiv.org/abs/2405.05355)**|None|None|Conner Pulling et al.|
|**2024-04-25**|**[Depth Supervised Neural Surface Reconstruction from Airborne Imagery](https://arxiv.org/abs/2404.16429)**|None|None|Vincent Hackstein et al.|
|**2024-04-21**|**[Generalizable Novel-View Synthesis using a Stereo Camera](https://arxiv.org/abs/2404.13541)**|Accepted to CVPR 2024. Project page URL: https://jinwonjoon.github.io/stereonerf/|None|Haechan Lee et al.|
|**2024-04-11**|**[GoMVS: Geometrically Consistent Cost Aggregation for Multi-View Stereo](https://arxiv.org/abs/2404.07992)**|CVPR 2024. Project page: https://wuuu3511.github.io/gomvs/ Code: https://github.com/Wuuu3511/GoMVS|None|Jiang Wu et al.|
|**2024-04-10**|**[MoCha-Stereo: Motif Channel Attention Network for Stereo Matching](https://arxiv.org/abs/2404.06842)**|Accepted to CVPR 2024|The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2024|Ziyang Chen et al.|
|**2024-04-08**|**[Learning Topology Uniformed Face Mesh by Volume Rendering for Multi-view Reconstruction](https://arxiv.org/abs/2404.05606)**|None|None|Yating Wang et al.|
|**2024-04-08**|**[Adaptive Learning for Multi-view Stereo Reconstruction](https://arxiv.org/abs/2404.05181)**|None|None|Qinglu Min et al.|
|**2024-04-04**|**[MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation](https://arxiv.org/abs/2404.03656)**|Project page: https://mvd-fusion.github.io/|None|Hanzhe Hu et al.|
|**2024-04-02**|**[CHOSEN: Contrastive Hypothesis Selection for Multi-View Depth Refinement](https://arxiv.org/abs/2404.02225)**|None|None|Di Qiu et al.|
|**2024-03-18**|**[GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with Noisy Polarization Priors](https://arxiv.org/abs/2403.11899)**|Accepted to ICLR 2024 Poster. For the Appendix, please see http://yukiumi13.github.io/gnerp_page|None|LI Yang et al.|
|**2024-03-14**|**[Intention-driven Ego-to-Exo Video Generation](https://arxiv.org/abs/2403.09194)**|None|None|Hongchen Luo et al.|
|**2024-03-12**|**[Adaptive Fusion of Single-View and Multi-View Depth for Autonomous Driving](https://arxiv.org/abs/2403.07535)**|Accepted to CVPR 2024|None|JunDa Cheng et al.|
|**2024-02-22**|**[GaussianPro: 3D Gaussian Splatting with Progressive Propagation](https://arxiv.org/abs/2402.14650)**|See the project page for code, data: https://kcheng1021.github.io/gaussianpro.github.io|None|Kai Cheng et al.|
|**2024-02-19**|**[SDGE: Stereo Guided Depth Estimation for 360$^\circ$ Camera Sets](https://arxiv.org/abs/2402.11791)**|None|None|Jialei Xu et al.|
|**2024-01-28**|**[Multi-Person 3D Pose Estimation from Multi-View Uncalibrated Depth Cameras](https://arxiv.org/abs/2401.15616)**|17 pages including appendix|None|Yu-Jhe Li et al.|
|**2024-01-25**|**[Range-Agnostic Multi-View Depth Estimation With Keyframe Selection](https://arxiv.org/abs/2401.14401)**|3DV 2024 Project Page https://andreaconti.github.io/projects/range_agnostic_multi_view_depth GitHub Page https://github.com/andreaconti/ramdepth.git|None|Andrea Conti et al.|
|**2024-01-23**|**[PSDF: Prior-Driven Neural Implicit Surface Learning for Multi-view Reconstruction](https://arxiv.org/abs/2401.12751)**|None|None|Wanjuan Su et al.|
|**2024-01-22**|**[Boosting Multi-view Stereo with Late Cost Aggregation](https://arxiv.org/abs/2401.11751)**|Code and models are available at https://github.com/Wuuu3511/LAMVSNET|None|Jiang Wu et al.|
|**2024-01-22**|**[MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo](https://arxiv.org/abs/2401.11673)**|Accepted to ICLR2024|ICLR(International Conference on Learning Representations) 2024|Chenjie Cao et al.|
|**2024-01-17**|**[3D Scene Geometry Estimation from 360$^\circ$ Imagery: A Survey](https://arxiv.org/abs/2401.09252)**|Published in ACM Computing Surveys|ACM Comput. Surv. 55, 4, Article 68, 2023|Thiago Lopes Trugillo da Silveira et al.|
|**2024-01-12**|**[SD-MVS: Segmentation-Driven Deformation Multi-View Stereo with Spherical Refinement and EM optimization](https://arxiv.org/abs/2401.06385)**|10 pages, 9 figures, published to AAAI2024|None|Zhenlong Yuan et al.|
|**2023-12-26**|**[Learning Deformable Hypothesis Sampling for Accurate PatchMatch Multi-View Stereo](https://arxiv.org/abs/2312.15970)**|None|None|Hongjie Li et al.|
|**2023-12-23**|**[NoPose-NeuS: Jointly Optimizing Camera Poses with Neural Implicit Surfaces for Multi-view Reconstruction](https://arxiv.org/abs/2312.15238)**|None|UniReps: the First Workshop on Unifying Representations in Neural Models (2023)|Mohamed Shawky Sabae et al.|
|**2023-12-21**|**[DUSt3R: Geometric 3D Vision Made Easy](https://arxiv.org/abs/2312.14132)**|fixing the ref for StaticThings3D dataset|None|Shuzhe Wang et al.|
|**2023-12-14**|**[CT-MVSNet: Efficient Multi-View Stereo with Cross-scale Transformer](https://arxiv.org/abs/2312.08594)**|Accepted at the 30th International Conference on Multimedia Modeling(MMM'24 Oral)|None|Sicheng Wang et al.|
|**2023-12-08**|**[MVDD: Multi-View Depth Diffusion Models](https://arxiv.org/abs/2312.04875)**|None|None|Zhen Wang et al.|
|**2023-11-17**|**[Point Cloud Self-supervised Learning via 3D to Multi-view Masked Learner](https://arxiv.org/abs/2311.10887)**|Accepted by ICCV 2025|None|Zhimin Chen et al.|
|**2023-11-11**|**[Polarimetric PatchMatch Multi-View Stereo](https://arxiv.org/abs/2311.07600)**|None|None|Jinyu Zhao et al.|
|**2023-11-07**|**[High-fidelity 3D Reconstruction of Plants using Neural Radiance Field](https://arxiv.org/abs/2311.04154)**|None|None|Kewei Hu et al.|
|**2023-11-02**|**[Novel View Synthesis from a Single RGBD Image for Indoor Scenes](https://arxiv.org/abs/2311.01065)**|2nd International Conference on Image Processing, Computer Vision and Machine Learning, November 2023|None|Congrui Hetang, Yuping Wang|
|**2023-10-31**|**[Joint Depth Prediction and Semantic Segmentation with Multi-View SAM](https://arxiv.org/abs/2311.00134)**|To appear in the 2024 IEEE/CVF Winter Conference on Applications of Computer Vision|None|Mykhailo Shvets et al.|
|**2023-10-30**|**[GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo](https://arxiv.org/abs/2310.19583)**|Accepted in WACV 2024 Link: https://openaccess.thecvf.com/content/WACV2024/html/Vats_GC-MVSNet_Multi-View_Multi-Scale_Geometrically-Consistent_Multi-View_Stereo_WACV_2024_paper.html|Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024|Vibhas K. Vats et al.|
|**2023-10-03**|**[RSRD: A Road Surface Reconstruction Dataset and Benchmark for Safe and Comfortable Autonomous Driving](https://arxiv.org/abs/2310.02262)**|None|None|Tong Zhao et al.|
|**2023-09-29**|**[When Epipolar Constraint Meets Non-local Operators in Multi-View Stereo](https://arxiv.org/abs/2309.17218)**|ICCV2023|None|Tianqi Liu et al.|
|**2023-09-26**|**[3D Reconstruction with Generalizable Neural Fields using Scene Priors](https://arxiv.org/abs/2309.15164)**|Project Page: https://oasisyang.github.io/neural-prior|None|Yang Fu et al.|
|**2023-09-23**|**[MP-MVS: Multi-Scale Windows PatchMatch and Planar Prior Multi-View Stereo](https://arxiv.org/abs/2309.13294)**|None|None|Rongxuan Tan et al.|
|**2023-09-17**|**[A Critical Analysis of Internal Reliability for Uncertainty Quantification of Dense Image Matching in Multi-view Stereo](https://arxiv.org/abs/2309.09379)**|Figure 8|ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2023|Debao Huang, Rongjun Qin|
|**2023-09-01**|**[Dense Voxel 3D Reconstruction Using a Monocular Event Camera](https://arxiv.org/abs/2309.00385)**|None|None|Haodong Chen et al.|
|**2023-09-01**|**[SparseSat-NeRF: Dense Depth Supervised Neural Radiance Fields for Sparse Satellite Images](https://arxiv.org/abs/2309.00277)**|ISPRS Annals 2023|None|Lulin Zhang, Ewelina Rupnik|
|**2023-08-26**|**[Disjoint Pose and Shape for 3D Face Reconstruction](https://arxiv.org/abs/2308.13903)**|ICCV workshops 2023|None|Raja Kumar et al.|
|**2023-08-19**|**[TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo](https://arxiv.org/abs/2308.09990)**|None|None|Zhenlong Yuan et al.|
|**2023-08-17**|**[ARAI-MVSNet: A multi-view stereo depth estimation network with adaptive depth range and depth interval](https://arxiv.org/abs/2308.09022)**|None|None|Song Zhang et al.|
|**2023-08-17**|**[V-FUSE: Volumetric Depth Map Fusion with Long-Range Constraints](https://arxiv.org/abs/2308.08715)**|ICCV 2023|None|Nathaniel Burgdorfer, Philippos Mordohai|
|**2023-08-15**|**[ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces](https://arxiv.org/abs/2308.07868)**|ICCV 2023. Project Page: https://qianyiwu.github.io/objectsdf++ Code: https://github.com/QianyiWu/objectsdf_plus|None|Qianyi Wu et al.|
|**2023-08-14**|**[A One Stop 3D Target Reconstruction and multilevel Segmentation Method](https://arxiv.org/abs/2308.06974)**|None|None|Jiexiong Xu et al.|
|**2023-08-09**|**[WaveNeRF: Wavelet-based Generalizable Neural Radiance Fields](https://arxiv.org/abs/2308.04826)**|Accepted to ICCV 2023. Project website: https://mxuai.github.io/WaveNeRF/|None|Muyu Xu et al.|
|**2023-08-07**|**[Learning Photometric Feature Transform for Free-form Object Scan](https://arxiv.org/abs/2308.03492)**|None|None|Xiang Feng et al.|
|**2023-08-04**|**[ES-MVSNet: Efficient Framework for End-to-end Self-supervised Multi-View Stereo](https://arxiv.org/abs/2308.02191)**|arXiv admin note: text overlap with arXiv:2203.03949 by other authors|None|Qiang Zhou et al.|
|**2023-08-02**|**[Tirtha -- An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites](https://arxiv.org/abs/2308.01246)**|Accepted at The 28th International ACM Conference on 3D Web Technology (Web3D 2023)|None|Jyotirmaya Shivottam, Subhankar Mishra|
|**2023-07-18**|**[Constraining Depth Map Geometry for Multi-View Stereo: A Dual-Depth Approach with Saddle-shaped Depth Cells](https://arxiv.org/abs/2307.09160)**|Accepted by ICCV 2023|None|Xinyi Ye et al.|
|**2023-07-16**|**[RayMVSNet++: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo](https://arxiv.org/abs/2307.10233)**|IEEE Transactions on Pattern Analysis and Machine Intelligence. arXiv admin note: substantial text overlap with arXiv:2204.01320|None|Yifei Shi et al.|
|**2023-07-03**|**[MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion](https://arxiv.org/abs/2307.01097)**|Project page, https://mvdiffusion.github.io; NeurIPS 2023 (spotlight); Compressed camera-ready version|None|Shitao Tang et al.|
|**2023-06-22**|**[One at a Time: Progressive Multi-step Volumetric Probability Learning for Reliable 3D Scene Perception](https://arxiv.org/abs/2306.12681)**|AAAI2024|None|Bohan Li et al.|
|**2023-06-16**|**[C2F2NeUS: Cascade Cost Frustum Fusion for High Fidelity and Generalizable Neural Surface Reconstruction](https://arxiv.org/abs/2306.10003)**|Accepted by ICCV2023|None|Luoyuan Xu et al.|
|**2023-06-14**|**[SimpleMapping: Real-Time Visual-Inertial Dense Mapping with Deep Multi-View Stereo](https://arxiv.org/abs/2306.08648)**|None|None|Yingye Xin et al.|
|**2023-06-12**|**[Instant Multi-View Head Capture through Learnable Registration](https://arxiv.org/abs/2306.07437)**|Conference on Computer Vision and Pattern Recognition (CVPR) 2023|None|Timo Bolkart et al.|
|**2023-06-01**|**[DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation](https://arxiv.org/abs/2306.00519)**|Updated: new work|None|Xiaoliang Ju et al.|
|**2023-05-31**|**[A technique to jointly estimate depth and depth uncertainty for unmanned aerial vehicles](https://arxiv.org/abs/2305.19780)**|The code is available at https://github.com/michael-fonder/M4DepthU|None|Michaël Fonder, Marc Van Droogenbroeck|
|**2023-05-28**|**[OccCasNet: Occlusion-aware Cascade Cost Volume for Light Field Depth Estimation](https://arxiv.org/abs/2305.17710)**|None|None|Wentao Chao et al.|
|**2023-05-24**|**[Incremental Dense Reconstruction from Monocular Video with Guided Sparse Feature Volume Fusion](https://arxiv.org/abs/2305.14918)**|8 pages, 5 figures, RA-L 2023|None|Xingxing Zuo et al.|
|**2023-05-18**|**[MVPSNet: Fast Generalizable Multi-view Photometric Stereo](https://arxiv.org/abs/2305.11167)**|None|None|Dongxu Zhao et al.|
|**2023-05-17**|**[CostFormer:Cost Transformer for Cost Aggregation in Multi-view Stereo](https://arxiv.org/abs/2305.10320)**|Accepted by IJCAI-23|None|Weitao Chen et al.|
|**2023-05-10**|**[FusionDepth: Complement Self-Supervised Monocular Depth Estimation with Cost Volume](https://arxiv.org/abs/2305.06036)**|None|None|Zhuofei Huang et al.|
|**2023-04-28**|**[CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction](https://arxiv.org/abs/2304.14633)**|Accepted by ICCV 2023|None|Ziyue Feng et al.|
|**2023-04-26**|**[Multi-View Stereo Representation Revisit: Region-Aware MVSNet](https://arxiv.org/abs/2304.13614)**|CVPR 2023|None|Yisu Zhang et al.|
|**2023-04-20**|**[A Comparative Neural Radiance Field (NeRF) 3D Analysis of Camera Poses from HoloLens Trajectories and Structure from Motion](https://arxiv.org/abs/2304.10664)**|7 pages, 5 figures. Will be published in the ISPRS The International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences|None|Miriam Jäger et al.|
|**2023-04-09**|**[BEVStereo++: Accurate Depth Estimation in Multi-view 3D Object Detection via Dynamic Temporal Stereo](https://arxiv.org/abs/2304.04185)**|None|None|Yinhao Li et al.|
|**2023-04-08**|**[POEM: Reconstructing Hand in a Point Embedded Multi-view Stereo](https://arxiv.org/abs/2304.04038)**|Accepted by CVPR 2023. (v2 fix typos)|None|Lixin Yang et al.|
|**2023-04-04**|**[End-to-End Latency Optimization of Multi-view 3D Reconstruction for Disaster Response](https://arxiv.org/abs/2304.01488)**|2022 10th IEEE International Conference on Mobile Cloud Computing, Services, and Engineering (MobileCloud)|None|Xiaojie Zhang et al.|
|**2023-04-04**|**[FineRecon: Depth-aware Feed-forward Network for Detailed 3D Reconstruction](https://arxiv.org/abs/2304.01480)**|ICCV 2023|None|Noah Stier et al.|
|**2023-03-30**|**[S-VolSDF: Sparse Multi-View Stereo Regularization of Neural Implicit Surfaces](https://arxiv.org/abs/2303.17712)**|ICCV 2023, Project page: https://hao-yu-wu.github.io/s-volsdf/|None|Haoyu Wu et al.|
|**2023-03-29**|**[DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object Detection and Tracking](https://arxiv.org/abs/2303.16628)**|None|None|Qing Lian et al.|
|**2023-03-29**|**[Multi-View Azimuth Stereo via Tangent Space Consistency](https://arxiv.org/abs/2303.16447)**|CVPR 2023 camera-ready. Appendices after references. 16 pages, 20 figures. Project page: https://xucao-42.github.io/mvas_homepage/|None|Xu Cao et al.|
|**2023-03-28**|**[Sparse Depth-Guided Attention for Accurate Depth Completion: A Stereo-Assisted Monitored Distillation Approach](https://arxiv.org/abs/2303.15840)**|7 pages, 8 figures, references added|None|Jia-Wei Guo et al.|
|**2023-03-27**|**[TMO: Textured Mesh Acquisition of Objects with a Mobile Device by using Differentiable Rendering](https://arxiv.org/abs/2303.15060)**|Accepted to CVPR23. Project Page: https://jh-choi.github.io/TMO/|None|Jaehoon Choi et al.|
|**2023-03-17**|**[Hierarchical Prior Mining for Non-local Multi-View Stereo](https://arxiv.org/abs/2303.09758)**|None|None|Chunlin Ren et al.|
|**2023-03-15**|**[RefiNeRF: Modelling dynamic neural radiance fields with inconsistent or missing camera parameters](https://arxiv.org/abs/2303.08695)**|None|None|Shuja Khalid, Frank Rudzicz|
|**2023-03-12**|**[Iterative Geometry Encoding Volume for Stereo Matching](https://arxiv.org/abs/2303.06615)**|Accepted to CVPR 2023|None|Gangwei Xu et al.|
|**2023-03-11**|**[Rethinking the Multi-view Stereo from the Perspective of Rendering-based Augmentation](https://arxiv.org/abs/2303.06418)**|This is a technical report of team Ewrfcas (Fudan University) in the GigaMVS reconstruction competition. Our method achieved the 1st performance in the 2022 reconstruction benchmark|None|Chenjie Cao et al.|
|**2023-03-10**|**[MVImgNet: A Large-scale Dataset of Multi-view Images](https://arxiv.org/abs/2303.06042)**|To be appear in CVPR2023. Project page: https://gaplab.cuhk.edu.cn/projects/MVImgNet/|None|Xianggang Yu et al.|
|**2023-02-28**|**[HelixSurf: A Robust and Efficient Neural Implicit Surface Learning of Indoor Scenes with Iterative Intertwined Regularization](https://arxiv.org/abs/2302.14340)**|None|None|Zhihao Liang et al.|
|**2023-02-20**|**[Unsupervised OmniMVS: Efficient Omnidirectional Depth Inference via Establishing Pseudo-Stereo Supervision](https://arxiv.org/abs/2302.09922)**|None|None|Zisong Chen et al.|
|**2023-02-14**|**[Visibility-Aware Pixelwise View Selection for Multi-View Stereo Matching](https://arxiv.org/abs/2302.07182)**|8 pages|None|Zhentao Huang et al.|
|**2023-01-21**|**[Dense RGB SLAM with Neural Implicit Maps](https://arxiv.org/abs/2301.08930)**|Accepted by ICLR 2023; Camera-Ready Version; The code is at poptree.github.io/DIM-SLAM|None|Heng Li et al.|
|**2022-12-24**|**[Polarimetric Multi-View Inverse Rendering](https://arxiv.org/abs/2212.12721)**|Paper accepted in IEEE Transactions on Pattern Analysis and Machine Intelligence (2022). arXiv admin note: substantial text overlap with arXiv:2007.08830|None|Jinyu Zhao et al.|
|**2022-12-13**|**[DELS-MVS: Deep Epipolar Line Search for Multi-View Stereo](https://arxiv.org/abs/2212.06626)**|accepted at WACV 2023|None|Christian Sormann et al.|
|**2022-11-30**|**[Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity](https://arxiv.org/abs/2211.16905)**|Accepted at the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI23)|None|Qingsong Yan et al.|
|**2022-10-20**|**[Multi-View Guided Multi-View Stereo](https://arxiv.org/abs/2210.11467)**|IROS 2022. First two authors contributed equally. Project page: https://github.com/andreaconti/multi-view-guided-multi-view-stereo|None|Matteo Poggi et al.|
|**2022-10-14**|**[Multi-View Photometric Stereo Revisited](https://arxiv.org/abs/2210.07670)**|Accepted for publication at IEEE/CVF WACV 2023. Draft info: 10 pages, 5 figure, and 3 tables|None|Berk Kaya et al.|
|**2022-10-14**|**[Deep PatchMatch MVS with Learned Patch Coplanarity, Geometric Consistency and Adaptive Pixel Sampling](https://arxiv.org/abs/2210.07582)**|None|None|Jae Yong Lee et al.|
|**2022-10-05**|**[Multi-Camera Collaborative Depth Prediction via Consistent Structure Estimation](https://arxiv.org/abs/2210.02009)**|None|None|Jialei Xu et al.|
|**2022-10-03**|**[CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth Pre-training](https://arxiv.org/abs/2210.01055)**|Accepted by ICCV2023|None|Tianyu Huang et al.|
|**2022-09-21**|**[BEVStereo: Enhancing Depth Estimation in Multi-view 3D Object Detection with Dynamic Temporal Stereo](https://arxiv.org/abs/2209.10248)**|None|None|Yinhao Li et al.|
|**2022-09-13**|**[A Benchmark and a Baseline for Robust Multi-view Depth Estimation](https://arxiv.org/abs/2209.06681)**|Accepted at 3DV 2022|None|Philipp Schröppel et al.|
|**2022-08-31**|**[Multi-View Reconstruction using Signed Ray Distance Functions (SRDF)](https://arxiv.org/abs/2209.00082)**|None|None|Pierre Zins et al.|
|**2022-08-31**|**[SimpleRecon: 3D Reconstruction Without 3D Convolutions](https://arxiv.org/abs/2208.14743)**|ECCV2022 version with improved timings. 14 pages + 5 pages of references|None|Mohamed Sayed et al.|
|**2022-08-19**|**[Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning](https://arxiv.org/abs/2208.09170)**|code: https://github.com/JeffWang987/MOVEDepth|None|Xiaofeng Wang et al.|
|**2022-08-04**|**[MVSFormer: Multi-View Stereo by Learning Robust Image Features and Temperature-based Depth](https://arxiv.org/abs/2208.02541)**|None|None|Chenjie Cao et al.|
|**2022-07-30**|**[Learning Pseudo Front Depth for 2D Forward-Looking Sonar-based Multi-view Stereo](https://arxiv.org/abs/2208.00233)**|Accepted at IROS 2022|None|Yusheng Wang et al.|
|**2022-07-27**|**[Towards the Probabilistic Fusion of Learned Priors into Standard Pipelines for 3D Reconstruction](https://arxiv.org/abs/2207.13464)**|Accepted at ICRA 2020|None|Tristan Laidlow et al.|
|**2022-07-25**|**[Cost Volume Pyramid Network with Multi-strategies Range Searching for Multi-view Stereo](https://arxiv.org/abs/2207.12032)**|Accepted by CGI2022|None|Shiyu Gao et al.|
|**2022-07-25**|**[nLMVS-Net: Deep Non-Lambertian Multi-View Stereo](https://arxiv.org/abs/2207.11876)**|Accepted to WACV 2023|None|Kohei Yamashita et al.|
|**2022-07-24**|**[Semi-supervised Deep Multi-view Stereo](https://arxiv.org/abs/2207.11699)**|This paper is accepted in ACMMM-2023. The code is released at: https://github.com/ToughStoneX/Semi-MVS|None|Hongbin Xu et al.|
|**2022-07-21**|**[KD-MVS: Knowledge Distillation Based Self-supervised Learning for Multi-view Stereo](https://arxiv.org/abs/2207.10425)**|None|None|Yikang Ding et al.|
|**2022-07-18**|**[Revisiting PatchMatch Multi-View Stereo for Urban 3D Reconstruction](https://arxiv.org/abs/2207.08439)**|Poster presentation at IEEE Intelligent Vehicles Symposium (IV 2022, https://iv2022.com/)|None|Marco Orsingher et al.|
|**2022-07-18**|**[Efficient View Clustering and Selection for City-Scale 3D Reconstruction](https://arxiv.org/abs/2207.08434)**|Oral presentation at ICIAP 2021 (https://www.iciap2021.org/)|None|Marco Orsingher et al.|
|**2022-06-22**|**[Monocular Spherical Depth Estimation with Explicitly Connected Weak Layout Cues](https://arxiv.org/abs/2206.11358)**|Project page at https://vcl3d.github.io/ExplicitLayoutDepth/|ISPRS Journal of Photogrammetry and Remote Sensing, Volume 183, January 2022, Pages 269-285|Nikolaos Zioulis et al.|
|**2022-06-21**|**[Enhancing Multi-view Stereo with Contrastive Matching and Weighted Focal Loss](https://arxiv.org/abs/2206.10360)**|5 pages, 3 figures; Accepted to ICIP2022|None|Yikang Ding et al.|
|**2022-06-16**|**[Virtual Correspondence: Humans as a Cue for Extreme-View Geometry](https://arxiv.org/abs/2206.08365)**|CVPR 2022. Project page: https://people.csail.mit.edu/weichium/virtual-correspondence/|None|Wei-Chiu Ma et al.|
|**2022-06-01**|**[MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction](https://arxiv.org/abs/2206.00665)**|Project page: https://niujinshuchong.github.io/monosdf/|None|Zehao Yu et al.|
|**2022-05-31**|**[Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction](https://arxiv.org/abs/2205.15848)**|None|None|Qiancheng Fu et al.|
|**2022-05-28**|**[RIAV-MVS: Recurrent-Indexing an Asymmetric Volume for Multi-View Stereo](https://arxiv.org/abs/2205.14320)**|CVPR 2023. Code link added|None|Changjiang Cai et al.|
|**2022-05-28**|**[WT-MVSNet: Window-based Transformers for Multi-view Stereo](https://arxiv.org/abs/2205.14319)**|None|None|Jinli Liao et al.|
|**2022-05-25**|**[Multiview Textured Mesh Recovery by Differentiable Rendering](https://arxiv.org/abs/2205.12468)**|None|None|Lixiang Lin et al.|
|**2022-05-14**|**[SaiNet: Stereo aware inpainting behind objects with generative networks](https://arxiv.org/abs/2205.07014)**|Presented at AI4CC workshop at CVPR|None|Violeta Menéndez González et al.|
|**2022-05-08**|**[Non-parametric Depth Distribution Modelling based Depth Inference for Multi-view Stereo](https://arxiv.org/abs/2205.03783)**|CVPR 2022|None|Jiayu Yang et al.|
|**2022-05-05**|**[Neural 3D Scene Reconstruction with the Manhattan-world Assumption](https://arxiv.org/abs/2205.02836)**|CVPR 2022 Oral. Project page: https://zju3dv.github.io/manhattan_sdf|None|Haoyu Guo et al.|
|**2022-05-05**|**[Exploiting Correspondences with All-pairs Correlations for Multi-view Depth Estimation](https://arxiv.org/abs/2205.02481)**|10 pages, 9 figures|None|Kai Cheng et al.|
|**2022-04-22**|**[Leveraging Deepfakes to Close the Domain Gap between Real and Synthetic Images in Facial Capture Pipelines](https://arxiv.org/abs/2204.10746)**|None|None|Winnie Lin et al.|
|**2022-04-15**|**[MVSTER: Epipolar Transformer for Efficient Multi-View Stereo](https://arxiv.org/abs/2204.07346)**|Code: https://github.com/JeffWang987/MVSTER|None|Xiaofeng Wang et al.|
|**2022-04-08**|**[Investigating Spherical Epipolar Rectification for Multi-View Stereo 3D Reconstruction](https://arxiv.org/abs/2204.04141)**|to be published in ISPRS Congress 2022|None|Mostafa Elhashash, Rongjun Qin|
|**2022-04-04**|**[RayMVSNet: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo](https://arxiv.org/abs/2204.01320)**|cvpr 2022, 11 pages|None|Junhua Xi et al.|
|**2022-04-04**|**[Aligning Silhouette Topology for Self-Adaptive 3D Human Pose Recovery](https://arxiv.org/abs/2204.01276)**|NeurIPS 2021|None|Mugalodi Rakesh et al.|
|**2022-03-27**|**[SuperMVS: Non-Uniform Cost Volume For High-Resolution Multi-View Stereo](https://arxiv.org/abs/2203.14331)**|None|None|Tao Zhang|
|**2022-03-24**|**[RayTran: 3D pose estimation and shape reconstruction of multiple objects from videos with ray-traced transformers](https://arxiv.org/abs/2203.13296)**|ECCV 2022 camera ready|None|Michał J. Tyszkiewicz et al.|
|**2022-03-23**|**[Event-Based Dense Reconstruction Pipeline](https://arxiv.org/abs/2203.12270)**|None|None|Kun Xiao et al.|
|**2022-03-22**|**[PlaneMVS: 3D Plane Reconstruction from Multi-View Stereo](https://arxiv.org/abs/2203.12082)**|CVPR 2022; source code: https://github.com/oppo-us-research/PlaneMVS|None|Jiachen Liu et al.|
|**2022-03-16**|**[DiFT: Differentiable Differential Feature Transform for Multi-View Stereo](https://arxiv.org/abs/2203.08435)**|None|None|Kaizhang Kang et al.|
|**2022-03-08**|**[RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering](https://arxiv.org/abs/2203.03949)**|Accepted by ECCV 2022, Project Page: https://boese0601.github.io/rc-mvsnet/|None|Di Chang et al.|
|**2022-03-04**|**[PatchMVSNet: Patch-wise Unsupervised Multi-View Stereo for Weakly-Textured Surface Reconstruction](https://arxiv.org/abs/2203.02156)**|None|None|Haonan Dong, Jian Yao|
|**2022-03-02**|**[DDL-MVS: Depth Discontinuity Learning for MVS Networks](https://arxiv.org/abs/2203.01391)**|None|None|Nail Ibrahimli et al.|
|**2022-02-26**|**[Accurate Human Body Reconstruction for Volumetric Video](https://arxiv.org/abs/2202.13118)**|2021 International Conference on 3D Immersion (IC3D)|None|Decai Chen et al.|
|**2022-02-26**|**[Uncertainty-Aware Deep Multi-View Photometric Stereo](https://arxiv.org/abs/2202.13071)**|Accepted for publication in IEEE/CVF CVPR 2022. (11 Pages, 6 Figures, 3 Tables)|None|Berk Kaya et al.|
|**2022-01-21**|**[Point-NeRF: Point-based Neural Radiance Fields](https://arxiv.org/abs/2201.08845)**|Accepted to CVPR 2022 (Oral)|In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 5438-5448) (2022)|Qiangeng Xu et al.|
|**2022-01-19**|**[A Confidence-based Iterative Solver of Depths and Surface Normals for Deep Multi-view Stereo](https://arxiv.org/abs/2201.07609)**|17 pages, 13 figures, 7 tables. ICCV 2021|None|Wang Zhao et al.|
|**2022-01-05**|**[Rethinking Depth Estimation for Multi-View Stereo: A Unified Representation](https://arxiv.org/abs/2201.01501)**|CVPR 2022 Accepted|None|Rui Peng et al.|
|**2022-01-04**|**[Detailed Facial Geometry Recovery from Multi-View Images by Learning an Implicit Function](https://arxiv.org/abs/2201.01016)**|AAAI 2022 Oral, updated to camera ready version|None|Yunze Xiao et al.|
|**2021-12-18**|**[3D Instance Segmentation of MVS Buildings](https://arxiv.org/abs/2112.09902)**|14 figures, 12 figures|None|Jiazhou Chen et al.|
|**2021-12-15**|**[Multi-View Depth Estimation by Fusing Single-View Depth Probability with Multi-View Geometry](https://arxiv.org/abs/2112.08177)**|CVPR 2022 (oral)|None|Gwangbin Bae et al.|
|**2021-12-13**|**[VirtualCube: An Immersive 3D Video Communication System](https://arxiv.org/abs/2112.06730)**|Project page: https://www.microsoft.com/en-us/research/project/virtualcube/|None|Yizhong Zhang et al.|
|**2021-12-12**|**[MVLayoutNet:3D layout reconstruction with multi-view panoramas](https://arxiv.org/abs/2112.06133)**|None|None|Zhihua Hu et al.|
|**2021-12-11**|**[Curvature-guided dynamic scale networks for Multi-view Stereo](https://arxiv.org/abs/2112.05999)**|Accepted to ICLR 2022|None|Khang Truong Giang et al.|
|**2021-12-09**|**[IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo](https://arxiv.org/abs/2112.05126)**|None|None|Fangjinhua Wang et al.|
|**2021-12-06**|**[Input-level Inductive Biases for 3D Reconstruction](https://arxiv.org/abs/2112.03243)**|CVPR 2022, including supplemental material|None|Wang Yifan et al.|
|**2021-12-04**|**[PointCLIP: Point Cloud Understanding by CLIP](https://arxiv.org/abs/2112.02413)**|Open sourced, Code and Model Available|None|Renrui Zhang et al.|
|**2021-12-04**|**[Generalized Binary Search Network for Highly-Efficient Multi-View Stereo](https://arxiv.org/abs/2112.02338)**|16 pages|None|Zhenxing Mi et al.|
|**2021-12-02**|**[Dimensions of Motion: Monocular Prediction through Flow Subspaces](https://arxiv.org/abs/2112.01502)**|Project page at https://dimensions-of-motion.github.io/|None|Richard Strong Bowen et al.|
|**2021-12-01**|**[FaSS-MVS -- Fast Multi-View Stereo with Surface-Aware Semi-Global Matching from UAV-borne Monocular Imagery](https://arxiv.org/abs/2112.00821)**|None|None|Boitumelo Ruf et al.|
|**2021-12-01**|**[Multi-View Stereo with Transformer](https://arxiv.org/abs/2112.00336)**|None|None|Jie Zhu et al.|
|**2021-12-01**|**[3DVNet: Multi-View Depth Prediction and Volumetric Refinement](https://arxiv.org/abs/2112.00202)**|10 pages, 6 figures, 3 tables. Accepted to 3DV 2021|None|Alexander Rich et al.|
|**2021-11-29**|**[TransMVSNet: Global Context-aware Multi-view Stereo Network with Transformers](https://arxiv.org/abs/2111.14600)**|None|None|Yikang Ding et al.|
|**2021-11-29**|**[IB-MVS: An Iterative Algorithm for Deep Multi-View Stereo based on Binary Decisions](https://arxiv.org/abs/2111.14420)**|accepted at BMVC 2021|None|Christian Sormann et al.|
|**2021-10-16**|**[Multi-View Stereo Network with attention thin volume](https://arxiv.org/abs/2110.08556)**|None|None|Zihang Wan|
|**2021-10-14**|**[DeepMoCap: Deep Optical Motion Capture Using Multiple Depth Sensors and Retro-Reflectors](https://arxiv.org/abs/2110.07283)**|None|Sensors, 19(2), 282, 2019|Anargyros Chatzitofis et al.|
|**2021-10-13**|**[Non-local Recurrent Regularization Networks for Multi-view Stereo](https://arxiv.org/abs/2110.06436)**|None|None|Qingshan Xu et al.|
|**2021-10-11**|**[Neural Radiance Fields Approach to Deep Multi-View Photometric Stereo](https://arxiv.org/abs/2110.05594)**|Accepted for publication at IEEE/CVF WACV 2022. 18 pages|None|Berk Kaya et al.|
|**2021-10-11**|**[Differentiable Stereopsis: Meshes from multiple views using differentiable rendering](https://arxiv.org/abs/2110.05472)**|In CVPR2022. Project webpage: https://shubham-goel.github.io/ds/|In CVPR 2022 (pp. 8635-8644)|Shubham Goel et al.|
|**2021-10-06**|**[Topologically Consistent Multi-View Face Inference Using Volumetric Sampling](https://arxiv.org/abs/2110.02948)**|International Conference on Computer Vision (ICCV)|None|Tianye Li et al.|
|**2021-09-06**|**[Single-Camera 3D Head Fitting for Mixed Reality Clinical Applications](https://arxiv.org/abs/2109.02740)**|None|None|Tejas Mane et al.|
|**2021-09-06**|**[Point-Based Neural Rendering with Per-View Optimization](https://arxiv.org/abs/2109.02369)**|https://repo-sam.inria.fr/fungraph/differentiable-multi-view/|In Computer Graphics Forum, Vol. 10. Wiley Online Library, 29-43 (2021)|Georgios Kopanas et al.|
|**2021-09-02**|**[NerfingMVS: Guided Optimization of Neural Radiance Fields for Indoor Multi-view Stereo](https://arxiv.org/abs/2109.01129)**|To appear in ICCV 2021 (Oral). Project page: https://weiyithu.github.io/NerfingMVS/|None|Yi Wei et al.|
|**2021-08-30**|**[Digging into Uncertainty in Self-supervised Multi-view Stereo](https://arxiv.org/abs/2108.12966)**|This paper is accepted by ICCV-21 as a poster presentation|None|Hongbin Xu et al.|
|**2021-08-19**|**[PatchMatch-RL: Deep MVS with Pixelwise Depth, Normal, and Visibility](https://arxiv.org/abs/2108.08943)**|Accepted to ICCV 2021 for oral presentation|None|Jae Yong Lee et al.|
|**2021-08-19**|**[VolumeFusion: Deep Depth Fusion for 3D Scene Reconstruction](https://arxiv.org/abs/2108.08623)**|ICCV 2021 Accepted|None|Jaesung Choe et al.|
|**2021-08-09**|**[NeuralMVS: Bridging Multi-View Stereo and Novel View Synthesis](https://arxiv.org/abs/2108.03880)**|Accepted for International Joint Conference on Neural Networks (IJCNN) 2022. Code available at https://github.com/AIS-Bonn/neural_mvs|None|Radu Alexandru Rosu, Sven Behnke|
|**2021-08-09**|**[AA-RMVSNet: Adaptive Aggregation Recurrent Multi-view Stereo Network](https://arxiv.org/abs/2108.03824)**|None|None|Zizhuang Wei et al.|
|**2021-08-05**|**[MFuseNet: Robust Depth Estimation with Learned Multiscopic Fusion](https://arxiv.org/abs/2108.02448)**|IEEE International Conference on Robotics and Automation (ICRA) + IEEE Robotics and Automation Letters (RA-L). arXiv admin note: substantial text overlap with arXiv:2001.08212|None|Weihao Yuan et al.|
|**2021-07-28**|**[Improving Multi-View Stereo via Super-Resolution](https://arxiv.org/abs/2107.13261)**|None|None|Eugenio Lomurno et al.|
|**2021-07-13**|**[Scalable Surface Reconstruction with Delaunay-Graph Neural Networks](https://arxiv.org/abs/2107.06130)**|The presentation of this work at SGP 2021 is available at https://youtu.be/KIrCDGhS10o|Computer Graphics Forum 2021|Raphael Sulzer et al.|
|**2021-07-09**|**[Prior-Guided Multi-View 3D Head Reconstruction](https://arxiv.org/abs/2107.04277)**|13 pages, 14 figures|Received by IEEE Transactions on Multimedia (2021)|Xueying Wang et al.|
|**2021-07-05**|**[TransformerFusion: Monocular RGB Scene Reconstruction using Transformers](https://arxiv.org/abs/2107.02191)**|Video: https://youtu.be/LIpTKYfKSqw|None|Aljaž Božič et al.|
|**2021-06-18**|**[Deep Learning for Multi-View Stereo via Plane Sweep: A Survey](https://arxiv.org/abs/2106.15328)**|None|None|Qingtian Zhu et al.|
|**2021-04-30**|**[Deep Multi-View Stereo gone wild](https://arxiv.org/abs/2104.15119)**|Accepted to 3DV2021|None|François Darmon et al.|
|**2021-04-29**|**[The Temporal Opportunist: Self-Supervised Multi-Frame Monocular Depth](https://arxiv.org/abs/2104.14540)**|CVPR 2021|None|Jamie Watson et al.|
|**2021-04-27**|**[MVS2D: Efficient Multi-view Stereo via Attention-Driven 2D Convolutions](https://arxiv.org/abs/2104.13325)**|Our code is released at https://github.com/zhenpeiyang/MVS2D|None|Zhenpei Yang et al.|
|**2021-04-21**|**[Real-time dense 3D Reconstruction from monocular video data captured by low-cost UAVs](https://arxiv.org/abs/2104.10515)**|8 pages, 4 figures|None|Max Hermann et al.|
|**2021-04-16**|**[Data-Driven 3D Reconstruction of Dressed Humans From Sparse Views](https://arxiv.org/abs/2104.08013)**|Presented at 3DV 2021. Code is released at https://gitlab.inria.fr/pzins/data-driven-3d-reconstruction-of-dressed-humans-from-sparse-views/|3DV 2021|Pierre Zins et al.|
|**2021-04-14**|**[Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes](https://arxiv.org/abs/2104.06935)**|IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2021|IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2021|Julian Chibane et al.|
|**2021-04-13**|**[PHI-MVS: Plane Hypothesis Inference Multi-view Stereo for Large-Scale Scene Reconstruction](https://arxiv.org/abs/2104.06165)**|None|None|Shang Sun et al.|
|**2021-04-12**|**[Self-supervised Multi-view Stereo via Effective Co-Segmentation and Data-Augmentation](https://arxiv.org/abs/2104.05374)**|This paper is accepted by AAAI-21 with a Distinguished Paper Award|None|Hongbin Xu et al.|
|**2021-04-07**|**[Self-supervised Learning of Depth Inference for Multi-view Stereo](https://arxiv.org/abs/2104.02972)**|CVPR 2021|None|Jiayu Yang et al.|
|**2021-03-29**|**[MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo](https://arxiv.org/abs/2103.15595)**|Project Page: https://apchenstu.github.io/mvsnerf/ Code:https://github.com/apchenstu/mvsnerf|None|Anpei Chen et al.|
|**2021-03-27**|**[Learning Efficient Photometric Feature Transform for Multi-view Stereo](https://arxiv.org/abs/2103.14794)**|None|None|Kaizhang Kang et al.|
|**2021-03-26**|**[DDR-Net: Learning Multi-Stage Multi-View Stereo With Dynamic Depth Range](https://arxiv.org/abs/2103.14275)**|None|None|Puyuan Yi et al.|
|**2020-12-18**|**[Boosting Monocular Depth Estimation with Lightweight 3D Point Fusion](https://arxiv.org/abs/2012.10296)**|10 pages, 9 figures|None|Lam Huynh et al.|
|**2020-12-06**|**[Shape From Tracing: Towards Reconstructing 3D Object Geometry and SVBRDF Material from Images via Differentiable Path Tracing](https://arxiv.org/abs/2012.03939)**|Will be published at 3DV 2020|None|Purvi Goel et al.|
|**2020-12-03**|**[DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal Fusion](https://arxiv.org/abs/2012.02177)**|CVPR 2021|None|Arda Düzçeker et al.|
|**2020-12-02**|**[PatchmatchNet: Learned Multi-View Patchmatch Stereo](https://arxiv.org/abs/2012.01411)**|None|None|Fangjinhua Wang et al.|
|**2020-12-02**|**[A Photogrammetry-based Framework to Facilitate Image-based Modeling and Automatic Camera Tracking](https://arxiv.org/abs/2012.01044)**|None|In Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 1: GRAPP, 106-112, 2021|Sebastian Bullinger et al.|
|**2020-12-01**|**[Facetwise Mesh Refinement for Multi-View Stereo](https://arxiv.org/abs/2012.00564)**|Accepted as Oral ICPR2020|None|Andrea Romanoni, Matteo Matteucci|
|**2020-11-30**|**[How Good MVSNets Are at Depth Fusion](https://arxiv.org/abs/2011.14761)**|7 pages, 6 figures, 1 table. Accepted to ICMV 2020|None|Oleg Voynov et al.|
|**2020-11-29**|**[RGBD-Net: Predicting color and depth images for novel views synthesis](https://arxiv.org/abs/2011.14398)**|19 pages, 15 figures. Code will be available at: https://github.com/phongnhhn92/RGBDNet|None|Phong Nguyen-Ha et al.|
|**2020-11-26**|**[Multi-view Depth Estimation using Epipolar Spatio-Temporal Networks](https://arxiv.org/abs/2011.13118)**|None|None|Xiaoxiao Long et al.|
|**2020-11-25**|**[Attention Aware Cost Volume Pyramid Based Multi-view Stereo Network for 3D Reconstruction](https://arxiv.org/abs/2011.12722)**|None|None|Anzhu Yu et al.|
|**2020-11-24**|**[MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments from a Single Moving Camera](https://arxiv.org/abs/2011.11814)**|CVPR 2021, Project page with video can be found under https://vision.in.tum.de/research/monorec. 14 pages, 10 figures, 5 tables|Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021, pp. 6112-6122|Felix Wimbauer et al.|
|**2020-11-20**|**[RidgeSfM: Structure from Motion via Robust Pairwise Matching Under Depth Uncertainty](https://arxiv.org/abs/2011.10359)**|Presenting at 3DV 2020. Source code released at https://github.com/facebookresearch/RidgeSfM|None|Benjamin Graham, David Novotny|
|**2020-11-18**|**[Dehazing Cost Volume for Deep Multi-view Stereo in Scattering Media with Airlight and Scattering Coefficient Estimation](https://arxiv.org/abs/2011.09114)**|14 pages, extended version of our ACCV2020 paper|None|Yuki Fujimura et al.|
|**2020-11-14**|**[Stable View Synthesis](https://arxiv.org/abs/2011.07233)**|Published at CVPR 2021, https://youtu.be/gqgXIY09htI|None|Gernot Riegler, Vladlen Koltun|
|**2020-11-02**|**[SLAM in the Field: An Evaluation of Monocular Mapping and Localization on Challenging Dynamic Agricultural Environment](https://arxiv.org/abs/2011.01122)**|accepted to WACV 2021, acknowledgment added|None|Fangwen Shu et al.|
|**2020-10-23**|**[BP-MVSNet: Belief-Propagation-Layers for Multi-View-Stereo](https://arxiv.org/abs/2010.12436)**|accepted at 3DV 2020|None|Christian Sormann et al.|
|**2020-10-17**|**[MeshMVS: Multi-View Stereo Guided Mesh Reconstruction](https://arxiv.org/abs/2010.08682)**|None|None|Rakesh Shrestha et al.|
|**2020-10-15**|**[Empty Cities: a Dynamic-Object-Invariant Space for Visual SLAM](https://arxiv.org/abs/2010.07646)**|None|None|Berta Bescos et al.|
|**2020-10-02**|**[Image-based underwater 3D reconstruction for Cultural Heritage: from image collection to 3D. Critical steps and considerations](https://arxiv.org/abs/2010.00928)**|Pre-submission version of the manuscript|None|Dimitrios Skarlatos, Panagiotis Agrafiotis|
|**2020-09-28**|**[Learning to Adapt Multi-View Stereo by Self-Supervision](https://arxiv.org/abs/2009.13278)**|19 pages, including supplementary, accepted and presented in BMVC 2020|None|Arijit Mallick et al.|
|**2020-09-07**|**[Improved Modeling of 3D Shapes with Multi-view Depth Maps](https://arxiv.org/abs/2009.03298)**|None|None|Kamal Gupta et al.|
|**2020-08-19**|**[DeepHandMesh: A Weakly-supervised Deep Encoder-Decoder Framework for High-fidelity Hand Mesh Modeling](https://arxiv.org/abs/2008.08213)**|Published at ECCV 2020 (Oral)|None|Gyeongsik Moon et al.|
|**2020-08-18**|**[Visibility-aware Multi-view Stereo Network](https://arxiv.org/abs/2008.07928)**|Accepted to BMVC 2020|None|Jingyang Zhang et al.|
|**2020-07-21**|**[Dense Hybrid Recurrent Multi-view Stereo Net with Dynamic Consistency Checking](https://arxiv.org/abs/2007.10872)**|Accepted by ECCV2020 as Spotlight|ECCV2020|Jianfeng Yan et al.|
|**2020-07-17**|**[Polarimetric Multi-View Inverse Rendering](https://arxiv.org/abs/2007.08830)**|Paper accepted in ECCV 2020|None|Jinyu Zhao et al.|
|**2020-07-15**|**[PVSNet: Pixelwise Visibility-Aware Multi-View Stereo Network](https://arxiv.org/abs/2007.07714)**|None|None|Qingshan Xu, Wenbing Tao|
|**2020-07-13**|**[UnRectDepthNet: Self-Supervised Monocular Depth Estimation using a Generic Framework for Handling Common Camera Distortion Models](https://arxiv.org/abs/2007.06676)**|Minor fixes added after IROS 2020 Camera ready submission. IROS 2020 presentation video - https://www.youtube.com/watch?v=3Br2KSWZRrY|None|Varun Ravi Kumar et al.|
|**2020-04-30**|**[M^3VSNet: Unsupervised Multi-metric Multi-view Stereo Network](https://arxiv.org/abs/2005.00363)**|The original top-level version is arXiv:2004.09722v2 but I upload the similar version to arXiv:2005.00363 mistakenly, which is overlapped with arXiv:2004.09722v2. So the submission is to make the two addresses keeping the same version|None|Baichuan Huang et al.|
|**2020-04-26**|**[Learning to Autofocus](https://arxiv.org/abs/2004.12260)**|CVPR 2020|None|Charles Herrmann et al.|
|**2020-04-21**|**[M^3VSNet: Unsupervised Multi-metric Multi-view Stereo Network](https://arxiv.org/abs/2004.09722)**|Welcome to communicate with the author by the repo https://github.com/whubaichuan/M3VSNet|None|Baichuan Huang et al.|
|**2020-04-02**|**[Novel View Synthesis of Dynamic Scenes with Globally Coherent Depths from a Monocular Camera](https://arxiv.org/abs/2004.01294)**|This paper is accepted to CVPR 2020|None|Jae Shin Yoon et al.|
|**2020-03-29**|**[Fast-MVSNet: Sparse-to-Dense Multi-View Stereo With Learned Propagation and Gauss-Newton Refinement](https://arxiv.org/abs/2003.13017)**|Accepted by CVPR2020|None|Zehao Yu, Shenghua Gao|
|**2020-03-27**|**[Deep 3D Capture: Geometry and Reflectance from Sparse Multi-View Images](https://arxiv.org/abs/2003.12642)**|Accepted to CVPR 2020|None|Sai Bi et al.|
|**2020-03-19**|**[DELTAS: Depth Estimation by Learning Triangulation And densification of Sparse points](https://arxiv.org/abs/2003.08933)**|ECCV 2020|None|Ayan Sinha et al.|
|**2020-03-02**|**[A-TVSNet: Aggregated Two-View Stereo Network for Multi-View Stereo Depth Estimation](https://arxiv.org/abs/2003.00711)**|None|None|Sizhang Dai, Weibing Huang|
|**2020-03-02**|**[A Novel Recurrent Encoder-Decoder Structure for Large-Scale Multi-view Stereo Reconstruction from An Open Aerial Dataset](https://arxiv.org/abs/2003.00637)**|None|None|Jin Liu, Shunping Ji|
|**2020-02-21**|**[Leveraging Photogrammetric Mesh Models for Aerial-Ground Feature Point Matching Toward Integrated 3D Reconstruction](https://arxiv.org/abs/2002.09085)**|Accepted for publication in ISPRS Journal of Photogrammetry and Remote Sensing|None|Qing Zhu et al.|
|**2020-01-22**|**[Active Perception with A Monocular Camera for Multiscopic Vision](https://arxiv.org/abs/2001.08212)**|8 pages|None|Weihao Yuan et al.|
|**2020-01-21**|**[Depth Completion Using a View-constrained Deep Prior](https://arxiv.org/abs/2001.07791)**|None|None|Pallabi Ghosh et al.|
|**2019-12-26**|**[Learning Inverse Depth Regression for Multi-View Stereo with Correlation Cost Volume](https://arxiv.org/abs/1912.11746)**|Accepted by AAAI-2020|None|Qingshan Xu, Wenbing Tao|
|**2019-12-26**|**[Planar Prior Assisted PatchMatch Multi-View Stereo](https://arxiv.org/abs/1912.11744)**|Accepted by AAAI-2020|None|Qingshan Xu, Wenbing Tao|
|**2019-12-13**|**[Cascade Cost Volume for High-Resolution Multi-View Stereo and Stereo Matching](https://arxiv.org/abs/1912.06378)**|Accepted by CVPR2020 Oral|None|Xiaodong Gu et al.|
|**2019-12-06**|**[Pyramid Multi-view Stereo Net with Self-adaptive View Aggregation](https://arxiv.org/abs/1912.03001)**|Accepted by ECCV2020 as a Poster|ECCV2020|Hongwei Yi et al.|
|**2019-12-03**|**[Joint Graph-based Depth Refinement and Normal Estimation](https://arxiv.org/abs/1912.01306)**|None|None|Mattia Rossi et al.|
|**2019-12-01**|**[DeepC-MVS: Deep Confidence Prediction for Multi-View Stereo Reconstruction](https://arxiv.org/abs/1912.00439)**|changes in V3: re-worked confidence prediction scheme, re-organized text, updated experiments; changes in V2: a reference was updated|None|Andreas Kuhn et al.|
|**2019-11-27**|**[Deep Stereo using Adaptive Thin Volume Representation with Uncertainty Awareness](https://arxiv.org/abs/1911.12012)**|Accepted to CVPR 2020 (Oral)|None|Shuo Cheng et al.|
|**2019-11-24**|**[Normal Assisted Stereo Depth Estimation](https://arxiv.org/abs/1911.10444)**|None|None|Uday Kusupati et al.|
|**2019-11-22**|**[BlendedMVS: A Large-scale Dataset for Generalized Multi-view Stereo Networks](https://arxiv.org/abs/1911.10127)**|Accepted to CVPR2020|None|Yao Yao et al.|
|**2019-10-18**|**[Eye in the Sky: Drone-Based Object Tracking and 3D Localization](https://arxiv.org/abs/1910.08259)**|Accepted to ACMMM2019|None|Haotian Zhang et al.|
|**2019-10-07**|**[Leveraging Vision Reconstruction Pipelines for Satellite Imagery](https://arxiv.org/abs/1910.02989)**|Project Page: https://kai-46.github.io/VisSat/|None|Kai Zhang et al.|
|**2019-09-06**|**[Self-supervised Dense 3D Reconstruction from Monocular Endoscopic Video](https://arxiv.org/abs/1909.03101)**|None|None|Xingtong Liu et al.|
|**2019-08-30**|**[MVS^2: Deep Unsupervised Multi-view Stereo with Multi-View Symmetry](https://arxiv.org/abs/1908.11526)**|Accepted by International Conference on 3D Vision (3DV 2019) as ORAL presentation|None|Yuchao Dai et al.|
|**2019-08-23**|**[Multi-Spectral Visual Odometry without Explicit Stereo Matching](https://arxiv.org/abs/1908.08814)**|None|None|Weichen Dai et al.|
|**2019-08-17**|**[OmniMVS: End-to-End Learning for Omnidirectional Stereo Matching](https://arxiv.org/abs/1908.06257)**|Accepted by ICCV 2019|None|Changhee Won et al.|
|**2019-08-12**|**[Point-Based Multi-View Stereo Network](https://arxiv.org/abs/1908.04422)**|Accepted as ICCV 2019 oral presentation|None|Rui Chen et al.|
|**2019-08-04**|**[Adversarial View-Consistent Learning for Monocular Depth Estimation](https://arxiv.org/abs/1908.01301)**|BMVC 2019 Spotlight|None|Yixuan Liu et al.|
|**2019-06-20**|**[3D Instance Segmentation via Multi-Task Metric Learning](https://arxiv.org/abs/1906.08650)**|None|None|Jean Lahoud et al.|
|**2019-06-03**|**[Y-GAN: A Generative Adversarial Network for Depthmap Estimation from Multi-camera Stereo Images](https://arxiv.org/abs/1906.00932)**|Accepted for Presentation at the ICML 2019 LatinX in AI Research Workshop|None|Miguel Alonso Jr|
|**2019-05-21**|**[Mesh-based Camera Pairs Selection and Occlusion-Aware Masking for Mesh Refinement](https://arxiv.org/abs/1905.08502)**|Accepted for publication in Pattern Recognition Letters|None|Andrea Romanoni, Matteo Matteucci|
|**2019-04-25**|**[Learning the Depths of Moving People by Watching Frozen People](https://arxiv.org/abs/1904.11111)**|CVPR 2019 (Oral)|None|Zhengqi Li et al.|
|**2019-04-17**|**[Render4Completion: Synthesizing Multi-View Depth Maps for 3D Shape Completion](https://arxiv.org/abs/1904.08366)**|ICCV 2019 workshop on Geometry meets Deep Learning|None|Tao Hu et al.|
|**2019-04-17**|**[Multi-Scale Geometric Consistency Guided Multi-View Stereo](https://arxiv.org/abs/1904.08103)**|Accepted by CVPR2019|None|Qingshan Xu, Wenbing Tao|
|**2019-03-26**|**[TAPA-MVS: Textureless-Aware PAtchMatch Multi-View Stereo](https://arxiv.org/abs/1903.10929)**|None|None|Andrea Romanoni, Matteo Matteucci|
|**2019-03-12**|**[Image Classification base on PCA of Multi-view Deep Representation](https://arxiv.org/abs/1903.04814)**|None|None|Yaoqi Sun et al.|
|**2019-02-27**|**[Shallow Water Bathymetry Mapping from UAV Imagery based on Machine Learning](https://arxiv.org/abs/1902.10733)**|8 pages, 9 figures|Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLII-2/W10, 9-16, 2019|Panagiotis Agrafiotis et al.|
|**2019-02-27**|**[Recurrent MVSNet for High-resolution Multi-view Stereo Depth Inference](https://arxiv.org/abs/1902.10556)**|Accepted by CVPR2019|None|Yao Yao et al.|
|**2019-02-20**|**[Dense Depth Estimation in Monocular Endoscopy with Self-supervised Learning Methods](https://arxiv.org/abs/1902.07766)**|Accepted to IEEE Transactions on Medical Imaging|None|Xingtong Liu et al.|
|**2019-01-12**|**[NRMVS: Non-Rigid Multi-View Stereo](https://arxiv.org/abs/1901.03910)**|None|None|Matthias Innmann et al.|
|**2018-12-21**|**[Wireless Software Synchronization of Multiple Distributed Cameras](https://arxiv.org/abs/1812.09366)**|Main: 9 pages, 10 figures. Supplemental: 3 pages, 5 figures|None|Sameer Ansari et al.|
|**2018-11-26**|**[IGNOR: Image-guided Neural Object Rendering](https://arxiv.org/abs/1811.10720)**|Video: https://youtu.be/s79HG9yn7QM|None|Justus Thies et al.|
|**2018-11-05**|**[A Differential Volumetric Approach to Multi-View Photometric Stereo](https://arxiv.org/abs/1811.01984)**|None|None|Fotios Logothetis et al.|
|**2018-09-28**|**[Extrinsic camera calibration method and its performance evaluation](https://arxiv.org/abs/1809.11073)**|arXiv admin note: text overlap with arXiv:1809.11066|None|Jacek Komorowski, Przemyslaw Rokita|
|**2018-09-28**|**[Face Recognition Based on Sequence of Images](https://arxiv.org/abs/1809.11069)**|None|None|Jacek Komorowski, Przemyslaw Rokita|
|**2018-09-24**|**[Towards Automated Post-Earthquake Inspections with Deep Learning-based Condition-Aware Models](https://arxiv.org/abs/1809.09195)**|None|None|Vedhus Hoskere et al.|
|**2018-07-16**|**[Learning and Matching Multi-View Descriptors for Registration of Point Clouds](https://arxiv.org/abs/1807.05653)**|None|None|Lei Zhou et al.|
|**2018-06-29**|**[Action Recognition for Depth Video using Multi-view Dynamic Images](https://arxiv.org/abs/1806.11269)**|accepted by Information Sciences|None|Yang Xiao et al.|
|**2018-06-25**|**[Self-supervised Learning for Dense Depth Estimation in Monocular Endoscopy](https://arxiv.org/abs/1806.09521)**|11 pages, 5 figures|None|Xingtong Liu et al.|
|**2018-05-17**|**[Recurrent Neural Network for Learning DenseDepth and Ego-Motion from Video](https://arxiv.org/abs/1805.06558)**|None|None|Rui Wang et al.|
|**2018-04-23**|**[Deep cross-domain building extraction for selective depth estimation from oblique aerial imagery](https://arxiv.org/abs/1804.08302)**|Accepted in the ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Science|ISPRS Ann. Photogramm. Remote Sens. Spatial Inf. Sci., IV-1, 125-132, 2018|Boitumelo Ruf et al.|
|**2018-04-14**|**[Physics-driven Fire Modeling from Multi-view Images](https://arxiv.org/abs/1804.05261)**|None|None|Garoe Dorta et al.|
|**2018-04-02**|**[DeepMVS: Learning Multi-view Stereopsis](https://arxiv.org/abs/1804.00650)**|CVPR 2018. Project page: https://phuang17.github.io/DeepMVS/ Code: https://github.com/phuang17/DeepMVS|None|Po-Han Huang et al.|
|**2018-04-02**|**[MegaDepth: Learning Single-View Depth Prediction from Internet Photos](https://arxiv.org/abs/1804.00607)**|updated paper for 'MegaDepth: Learning Single-View Depth Prediction from Internet Photos', CVPR, 2018|None|Zhengqi Li, Noah Snavely|
|**2018-03-22**|**[Prioritized Multi-View Stereo Depth Map Generation Using Confidence Prediction](https://arxiv.org/abs/1803.08323)**|This paper was accepted to ISPRS Journal of Photogrammetry and Remote Sensing (https://www.journals.elsevier.com/isprs-journal-of-photogrammetry-and-remote-sensing) on March 21, 2018. The official version will be made available on ScienceDirect (https://www.sciencedirect.com)|None|Christian Mostegel et al.|
|**2018-03-21**|**[Robust Depth Estimation from Auto Bracketed Images](https://arxiv.org/abs/1803.07702)**|To appear in CVPR 2018. Total 9 pages|None|Sunghoon Im et al.|
|**2018-01-17**|**[Multi-View Stereo 3D Edge Reconstruction](https://arxiv.org/abs/1801.05606)**|Accepted for WACV 2018|None|Andrea Bignoli et al.|
|**2018-01-04**|**[A Large Dataset for Improving Patch Matching](https://arxiv.org/abs/1801.01466)**|None|None|Rahul Mitra et al.|
|**2017-11-28**|**[Super-Resolution for Overhead Imagery Using DenseNets and Adversarial Learning](https://arxiv.org/abs/1711.10312)**|9 pages, 9 figures, WACV 2018 submission|None|Marc Bosch et al.|
|**2017-09-22**|**[High-Resolution Shape Completion Using Deep Neural Networks for Global Structure and Local Geometry Inference](https://arxiv.org/abs/1709.07599)**|8 pages paper, 11 pages supplementary material, ICCV spotlight paper|None|Xiaoguang Han et al.|
|**2017-09-18**|**[Joint Estimation of Camera Pose, Depth, Deblurring, and Super-Resolution from a Blurred Image Sequence](https://arxiv.org/abs/1709.05745)**|accepted to ICCV 2017|None|Haesol Park, Kyoung Mu Lee|
|**2017-08-25**|**[Stereo DSO: Large-Scale Direct Sparse Visual Odometry with Stereo Cameras](https://arxiv.org/abs/1708.07878)**|ICCV 2017|None|Rui Wang et al.|
|**2017-05-25**|**[Plan3D: Viewpoint and Trajectory Optimization for Aerial Multi-View Stereo Reconstruction](https://arxiv.org/abs/1705.09314)**|31 pages, 12 figures, 9 tables|None|Benjamin Hepp et al.|
|**2017-05-02**|**[Active Image-based Modeling with a Toy Drone](https://arxiv.org/abs/1705.01010)**|To be published on International Conference on Robotics and Automation 2018, Brisbane, Australia. Project Page: https://huangrui815.github.io/active-image-based-modeling/ The author's personal page: http://www.sfu.ca/~rha55/|None|Rui Huang et al.|
|**2017-05-02**|**[Scalable Surface Reconstruction from Point Clouds with Extreme Scale and Density Diversity](https://arxiv.org/abs/1705.00949)**|This paper was accepted to the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017. The copyright was transfered to IEEE (ieee.org). The official version of the paper will be made available on IEEE Xplore (R) (ieeexplore.ieee.org). This version of the paper also contains the supplementary material, which will not appear IEEE Xplore (R)|None|Christian Mostegel et al.|
|**2017-01-24**|**[Improved Descriptors for Patch Matching and Reconstruction](https://arxiv.org/abs/1701.06854)**|9 pages, ICCV Workshop on Compact and Efficient Feature Representation and Learning (CEFRL), 2017|None|Rahul Mitra et al.|
|**2016-11-22**|**[Single-View and Multi-View Depth Fusion](https://arxiv.org/abs/1611.07245)**|Accepted for publication in IEEE Robotics and Automation Letters|None|José M. Fácil et al.|
|**2016-10-14**|**[Recurrent 3D Attentional Networks for End-to-End Active Object Recognition](https://arxiv.org/abs/1610.04308)**|None|None|Min Liu et al.|
|**2016-09-21**|**[Production-Level Facial Performance Capture Using Deep Convolutional Neural Networks](https://arxiv.org/abs/1609.06536)**|Final SCA 2017 version|None|Samuli Laine et al.|
|**2016-09-05**|**[Efficient Volumetric Fusion of Airborne and Street-Side Data for Urban Reconstruction](https://arxiv.org/abs/1609.01345)**|To appear in ICPR 2016|None|András Bódis-Szomorú et al.|
|**2016-05-06**|**[UAV-based Autonomous Image Acquisition with Multi-View Stereo Quality Assurance by Confidence Prediction](https://arxiv.org/abs/1605.01923)**|This paper was accepted to the 7th International Workshop on Computer Vision in Vehicle Technology (CVVT 2016) and will appear in IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2016. The copyright was transferred to IEEE (ieee.org). The paper will be available on IEEE Xplore(ieeexplore.ieee.org). This version of the paper also contains the supplementary material|None|Christian Mostegel et al.|
|**2016-04-21**|**[Automatic 3D Reconstruction of Manifold Meshes via Delaunay Triangulation and Mesh Sweeping](https://arxiv.org/abs/1604.06258)**|in IEEE Winter Conference on Applications of Computer Vision (WACV) 2016|None|Andrea Romanoni et al.|
|**2016-04-11**|**[Semantic 3D Reconstruction with Continuous Regularization and Ray Potentials Using a Visibility Consistency Constraint](https://arxiv.org/abs/1604.02885)**|Accepted as a spotlight oral paper by CVPR 2016. Code at https://github.com/nsavinov/ray_potentials/|None|Nikolay Savinov et al.|
|**2015-05-03**|**[Detail-preserving and Content-aware Variational Multi-view Stereo Reconstruction](https://arxiv.org/abs/1505.00389)**|14 pages,16 figures. Submitted to IEEE Transaction on image processing|None|Zhaoxin Li et al.|
|**2015-03-16**|**[PiMPeR: Piecewise Dense 3D Reconstruction from Multi-View and Multi-Illumination Images](https://arxiv.org/abs/1503.04598)**|None|None|Reza Sabzevari et al.|

## Depth Estimation

Query: abs:'Depth Estimation' AND cat:'cs.CV'

|Date|Title|Comments|Journal|Authors|
|---|---|---|---|---|
|**2025-08-07**|**[Propagating Sparse Depth via Depth Foundation Model for Out-of-Distribution Depth Completion](https://arxiv.org/abs/2508.04984)**|Accepted by IEEE TIP|None|Shenglun Chen et al.|
|**2025-08-06**|**[Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens](https://arxiv.org/abs/2508.04928)**|None|None|Suchisrit Gangopadhyay et al.|
|**2025-08-06**|**[OmniDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment](https://arxiv.org/abs/2508.04611)**|ICCV 2025 Highlight|IEEE/CVF International Conference on Computer Vision (ICCV), 2025|Tongfan Guan et al.|
|**2025-08-06**|**[Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline](https://arxiv.org/abs/2508.04597)**|IROS 2025|None|Linqing Zhao et al.|
|**2025-08-06**|**[MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction](https://arxiv.org/abs/2508.04297)**|This work is accepted by ICCV 2025|None|Yaopeng Lou et al.|
|**2025-08-06**|**[DET-GS: Depth- and Edge-Aware Regularization for High-Fidelity 3D Gaussian Splatting](https://arxiv.org/abs/2508.04099)**|None|None|Zexu Huang et al.|
|**2025-08-05**|**[Monocular Depth Estimation with Global-Aware Discretization and Local Context Modeling](https://arxiv.org/abs/2508.03186)**|None|None|Heng Wu et al.|
|**2025-08-04**|**[Elucidating the Role of Feature Normalization in IJEPA](https://arxiv.org/abs/2508.02829)**|None|None|Adam Colton|
|**2025-08-04**|**[Rethinking Transparent Object Grasping: Depth Completion with Monocular Depth Estimation and Instance Mask](https://arxiv.org/abs/2508.02507)**|None|None|Yaofeng Cheng et al.|
|**2025-08-02**|**[3DRot: 3D Rotation Augmentation for RGB-Based 3D Tasks](https://arxiv.org/abs/2508.01423)**|None|None|Shitian Yang et al.|
|**2025-08-02**|**[A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding](https://arxiv.org/abs/2508.01197)**|IROS 2025 Accepted Paper|None|Zhan Shi et al.|
|**2025-07-30**|**[UAVScenes: A Multi-Modal Dataset for UAVs](https://arxiv.org/abs/2507.22412)**|Accepted by ICCV 2025|None|Sijie Wang et al.|
|**2025-07-29**|**[TESPEC: Temporally-Enhanced Self-Supervised Pretraining for Event Cameras](https://arxiv.org/abs/2508.00913)**|Accepted at IEEE/CVF International Conference on Computer Vision (ICCV) 2025|None|Mohammad Mohammadi et al.|
|**2025-07-29**|**[PanoSplatt3R: Leveraging Perspective Pretraining for Generalized Unposed Wide-Baseline Panorama Reconstruction](https://arxiv.org/abs/2507.21960)**|Accepted to ICCV 2025|None|Jiahui Ren et al.|
|**2025-07-28**|**[Endoscopic Depth Estimation Based on Deep Learning: A Survey](https://arxiv.org/abs/2507.20881)**|None|None|Ke Niu et al.|
|**2025-07-26**|**[UniCT Depth: Event-Image Fusion Based Monocular Depth Estimation with Convolution-Compensated ViT Dual SA Block](https://arxiv.org/abs/2507.19948)**|Accepted by IJCAI 2025 (International Joint Conference on Artificial Intelligence)|None|Luoxi Jing et al.|
|**2025-07-25**|**[Event-Based De-Snowing for Autonomous Driving](https://arxiv.org/abs/2507.20901)**|None|None|Manasi Muglikar et al.|
|**2025-07-24**|**[Towards Scalable Spatial Intelligence via 2D-to-3D Data Lifting](https://arxiv.org/abs/2507.18678)**|ICCV 2025 (Highlight)|None|Xingyu Miao et al.|
|**2025-07-24**|**[DepthDark: Robust Monocular Depth Estimation for Low-Light Environments](https://arxiv.org/abs/2507.18243)**|Accepted by ACM MM 2025 conference|None|Longjian Zeng et al.|
|**2025-07-24**|**[BokehDiff: Neural Lens Blur with One-Step Diffusion](https://arxiv.org/abs/2507.18060)**|Accepted by ICCV 2025|None|Chengxuan Zhu et al.|
|**2025-07-23**|**[Monocular Semantic Scene Completion via Masked Recurrent Networks](https://arxiv.org/abs/2507.17661)**|ICCV 2025; 15 pages, 10 figures, 6 tables; Code at https://github.com/alanWXZ/MonoMRN|None|Xuzhi Wang et al.|
|**2025-07-22**|**[SDGOCC: Semantic and Depth-Guided Bird's-Eye View Transformation for 3D Multimodal Occupancy Prediction](https://arxiv.org/abs/2507.17083)**|accepted by CVPR2025|None|Zaipeng Duan et al.|
|**2025-07-21**|**[DAViD: Data-efficient and Accurate Vision Models from Synthetic Data](https://arxiv.org/abs/2507.15365)**|Accepted at ICCV 2025|None|Fatemeh Saleh et al.|
|**2025-07-21**|**[BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?](https://arxiv.org/abs/2507.15321)**|Webpage: https://zhyever.github.io/benchdepth|None|Zhenyu Li et al.|
|**2025-07-20**|**[Region-aware Depth Scale Adaptation with Sparse Measurements](https://arxiv.org/abs/2507.14879)**|None|None|Rizhao Fan et al.|
|**2025-07-20**|**[Training Self-Supervised Depth Completion Using Sparse Measurements and a Single Image](https://arxiv.org/abs/2507.14845)**|None|None|Rizhao Fan et al.|
|**2025-07-19**|**[DCHM: Depth-Consistent Human Modeling for Multiview Detection](https://arxiv.org/abs/2507.14505)**|multi-view detection, sparse-view reconstruction|ICCV`2025|Jiahao Ma et al.|
|**2025-07-19**|**[Motion Segmentation and Egomotion Estimation from Event-Based Normal Flow](https://arxiv.org/abs/2507.14500)**|None|None|Zhiyuan Hua et al.|
|**2025-07-18**|**[Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2507.13857)**|None|None|Max van den Hoven et al.|
|**2025-07-18**|**[Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction](https://arxiv.org/abs/2507.13719)**|None|None|Daniele Pannone et al.|
|**2025-07-17**|**[$π^3$: Scalable Permutation-Equivariant Visual Geometry Learning](https://arxiv.org/abs/2507.13347)**|Project page: https://yyfz.github.io/pi3/|None|Yifan Wang et al.|
|**2025-07-16**|**[Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios](https://arxiv.org/abs/2507.12449)**|7 pages, 6 figures, 4 tables, HSI 2025|None|Van-Hoang-Anh Phan et al.|
|**2025-07-16**|**[Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation](https://arxiv.org/abs/2507.12292)**|13 pages, 4 figures, In International Conference on Image Analysis and Processing|None|Antonio Finocchiaro et al.|
|**2025-07-15**|**[Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation](https://arxiv.org/abs/2507.11540)**|None|None|Zhen Xu et al.|
|**2025-07-15**|**[MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network](https://arxiv.org/abs/2507.11333)**|Accepted by ICCV 2025|None|Jianfei Jiang et al.|
|**2025-07-14**|**[Cameras as Relative Positional Encoding](https://arxiv.org/abs/2507.10496)**|Project Page: https://www.liruilong.cn/prope/|None|Ruilong Li et al.|
|**2025-07-14**|**[Spatial Lifting for Dense Prediction](https://arxiv.org/abs/2507.10222)**|Preprint. Under review|None|Mingzhi Xu, Yizhe Zhang|
|**2025-07-13**|**[Prompt2DEM: High-Resolution DEMs for Urban and Open Environments from Global Prompts Using a Monocular Foundation Model](https://arxiv.org/abs/2507.09681)**|18 pages|None|Osher Rafaeli et al.|
|**2025-07-11**|**[ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way](https://arxiv.org/abs/2507.08679)**|None|None|Rajarshi Roy et al.|
|**2025-07-10**|**[An Embedded Real-time Object Alert System for Visually Impaired: A Monocular Depth Estimation based Approach through Computer Vision](https://arxiv.org/abs/2507.08165)**|None|None|Jareen Anjom et al.|
|**2025-07-10**|**[Tree-Mamba: A Tree-Aware Mamba for Underwater Monocular Depth Estimation](https://arxiv.org/abs/2507.07687)**|None|None|Peixian Zhuang et al.|
|**2025-07-10**|**[HOTA: Hierarchical Overlap-Tiling Aggregation for Large-Area 3D Flood Mapping](https://arxiv.org/abs/2507.07585)**|None|None|Wenfeng Jia et al.|
|**2025-07-08**|**[Beyond Appearance: Geometric Cues for Robust Video Instance Segmentation](https://arxiv.org/abs/2507.05948)**|Accepted by ICCV 2025 Workshop LSVOS|None|Quanzhu Niu et al.|
|**2025-07-07**|**[VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting](https://arxiv.org/abs/2507.05116)**|None|None|Juyi Lin et al.|
|**2025-07-07**|**[Estimating Object Physical Properties from RGB-D Vision and Depth Robot Sensors Using Deep Learning](https://arxiv.org/abs/2507.05029)**|None|None|Ricardo Cardoso, Plinio Moreno|
|**2025-07-06**|**[A View-consistent Sampling Method for Regularized Training of Neural Radiance Fields](https://arxiv.org/abs/2507.04408)**|ICCV 2025 accepted|None|Aoxiang Fan et al.|
|**2025-07-03**|**[From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images](https://arxiv.org/abs/2507.02781)**|None|None|Danrong Zhang et al.|
|**2025-07-02**|**[Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning with Vision Foundation Models](https://arxiv.org/abs/2507.02148)**|None|None|Zijie Cai, Christopher Metzler|
|**2025-07-02**|**[RobuSTereo: Robust Zero-Shot Stereo Matching under Adverse Weather](https://arxiv.org/abs/2507.01653)**|accepted by ICCV25|None|Yuran Wang et al.|
|**2025-07-02**|**[Depth Anything at Any Condition](https://arxiv.org/abs/2507.01634)**|None|None|Boyuan Sun et al.|
|**2025-07-02**|**[DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation](https://arxiv.org/abs/2507.01603)**|Accepted by ICCV 2025|None|Yue-Jiang Dong et al.|
|**2025-07-01**|**[Evaluating Robustness of Monocular Depth Estimation with Procedural Scene Perturbations](https://arxiv.org/abs/2507.00981)**|Fixing display of figure on Safari browsers|None|Jack Nugent et al.|
|**2025-06-30**|**[OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2506.23565)**|Accepted by ICCV2025|None|Mingqian Ji et al.|
|**2025-06-25**|**[THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion](https://arxiv.org/abs/2506.20877)**|None|None|Calin Teodor Ioan|
|**2025-06-25**|**[StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation](https://arxiv.org/abs/2506.20756)**|Work done in Nov 2024, during an internship at the University of Pennsylvania. Project page: https://stereodiff.github.io/|None|Haodong Li et al.|
|**2025-06-21**|**[Optimization-Free Patch Attack on Stereo Depth Estimation](https://arxiv.org/abs/2506.17632)**|None|None|Hangcheng Liu et al.|
|**2025-06-20**|**[RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking](https://arxiv.org/abs/2506.17119)**|Accepted to IROS 2025|None|Teng Guo, Jingjin Yu|
|**2025-06-20**|**[DepthVanish: Optimizing Adversarial Interval Structures for Stereo-Depth-Invisible Patches](https://arxiv.org/abs/2506.16690)**|None|None|Yun Xing et al.|
|**2025-06-19**|**[EndoMUST: Monocular Depth Estimation for Robotic Endoscopy via End-to-end Multi-step Self-supervised Training](https://arxiv.org/abs/2506.16017)**|Accepted by IROS 2025|None|Liangjing Shao et al.|
|**2025-06-18**|**[RaCalNet: Radar Calibration Network for Sparse-Supervised Metric Depth Estimation](https://arxiv.org/abs/2506.15560)**|10 pages, 7 figures|None|Xingrui Qin et al.|
|**2025-06-17**|**[DiFuse-Net: RGB and Dual-Pixel Depth Estimation using Window Bi-directional Parallax Attention and Cross-modal Transfer Learning](https://arxiv.org/abs/2506.14709)**|Accepted in IROS 2025|None|Kunal Swami et al.|
|**2025-06-16**|**[Test3R: Learning to Reconstruct 3D at Test Time](https://arxiv.org/abs/2506.13750)**|None|None|Yuheng Yuan et al.|
|**2025-06-16**|**[Multiview Geometric Regularization of Gaussian Splatting for Accurate Radiance Fields](https://arxiv.org/abs/2506.13508)**|Accepted to Computer Graphics Forum (EGSR 2025)|None|Jungeon Kim et al.|
|**2025-06-16**|**[Self-Supervised Enhancement for Depth from a Lightweight ToF Sensor with Monocular Images](https://arxiv.org/abs/2506.13444)**|accepted by IROS 2025|None|Laiyan Ding et al.|
|**2025-06-16**|**[TR2M: Transferring Monocular Relative Depth to Metric Depth with Language Descriptions and Scale-Oriented Contrast](https://arxiv.org/abs/2506.13387)**|None|None|Beilei Cui et al.|
|**2025-06-15**|**[3D Hand Mesh-Guided AI-Generated Malformed Hand Refinement with Hand Pose Transformation via Diffusion Model](https://arxiv.org/abs/2506.12680)**|None|None|Chen-Bin Feng et al.|
|**2025-06-12**|**[Leveraging 6DoF Pose Foundation Models For Mapping Marine Sediment Burial](https://arxiv.org/abs/2506.10386)**|None|None|Jerry Yan et al.|
|**2025-06-11**|**[MSSDF: Modality-Shared Self-supervised Distillation for High-Resolution Multi-modal Remote Sensing Image Learning](https://arxiv.org/abs/2506.09327)**|None|None|Tong Wang et al.|
|**2025-06-10**|**[AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models](https://arxiv.org/abs/2506.09082)**|First two authors contribute equally|None|Zheda Mai et al.|
|**2025-06-09**|**[Jamais Vu: Exposing the Generalization Gap in Supervised Semantic Correspondence](https://arxiv.org/abs/2506.08220)**|None|None|Octave Mariotti et al.|
|**2025-06-09**|**[Hidden in plain sight: VLMs overlook their visual representations](https://arxiv.org/abs/2506.08008)**|Project page: https://hidden-plain-sight.github.io/|None|Stephanie Fu et al.|
|**2025-06-09**|**[EgoM2P: Egocentric Multimodal Multitask Pretraining](https://arxiv.org/abs/2506.07886)**|Accepted by ICCV 2025|None|Gen Li et al.|
|**2025-06-09**|**[Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images](https://arxiv.org/abs/2506.07740)**|None|None|Yingping Liang et al.|
|**2025-06-07**|**[Dark Channel-Assisted Depth-from-Defocus from a Single Image](https://arxiv.org/abs/2506.06643)**|None|None|Moushumi Medhi, Rajiv Ranjan Sahay|
|**2025-06-06**|**[NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces](https://arxiv.org/abs/2506.05815)**|NTIRE Workshop Challenge Report, CVPR 2025|None|Pierluigi Zama Ramirez et al.|
|**2025-06-06**|**[Token Transforming: A Unified and Training-Free Token Compression Framework for Vision Transformer Acceleration](https://arxiv.org/abs/2506.05709)**|None|None|Fanhu Zeng et al.|
|**2025-06-06**|**[Aerial Multi-View Stereo via Adaptive Depth Range Inference and Normal Cues](https://arxiv.org/abs/2506.05655)**|IEEE TGRS 2025|None|Yimei Liu et al.|
|**2025-06-05**|**[Structure-Aware Radar-Camera Depth Estimation](https://arxiv.org/abs/2506.05008)**|None|None|Fuyi Zhang et al.|
|**2025-06-05**|**[Generating Synthetic Stereo Datasets using 3D Gaussian Splatting and Expert Knowledge Transfer](https://arxiv.org/abs/2506.04908)**|None|None|Filip Slezak et al.|
|**2025-06-05**|**[Toward Better SSIM Loss for Unsupervised Monocular Depth Estimation](https://arxiv.org/abs/2506.04758)**|12 pages,4 figures|International Conference on Image and Graphics. Cham: Springer Nature Switzerland, 2023: 81-92|Yijun Cao et al.|
|**2025-06-04**|**[JointSplat: Probabilistic Joint Flow-Depth Optimization for Sparse-View Gaussian Splatting](https://arxiv.org/abs/2506.03872)**|None|None|Yang Xiao et al.|
|**2025-06-03**|**[ViT-Split: Unleashing the Power of Vision Foundation Models via Efficient Splitting Heads](https://arxiv.org/abs/2506.03433)**|The project is available: https://jackyfl.github.io/vitsplit.github.io/|None|Yifan Li et al.|
|**2025-06-02**|**[E3D-Bench: A Benchmark for End-to-End 3D Geometric Foundation Models](https://arxiv.org/abs/2506.01933)**|Project Page: https://e3dbench.github.io/|None|Wenyan Cong et al.|
|**2025-06-01**|**[Perceptual Inductive Bias Is What You Need Before Contrastive Learning](https://arxiv.org/abs/2506.01201)**|CVPR 2025. Tianqin Li and Junru Zhao contributed equally to this work. Due to a formatting error during the CVPR submission, the equal contribution note was omitted in the official proceedings. This arXiv version corrects that oversight. The author order follows alphabetical order by last name|None|Tianqin Li et al.|
|**2025-05-31**|**[XYZ-IBD: A High-precision Bin-picking Dataset for Object 6D Pose Estimation Capturing Real-world Industrial Complexity](https://arxiv.org/abs/2506.00599)**|None|None|Junwen Huang et al.|
|**2025-05-30**|**[Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization](https://arxiv.org/abs/2505.24249)**|None|None|Qingyao Tian et al.|
|**2025-05-29**|**[Bridging Geometric and Semantic Foundation Models for Generalized Monocular Depth Estimation](https://arxiv.org/abs/2505.23400)**|None|None|Sanggyun Ma et al.|
|**2025-05-29**|**[GeoMan: Temporally Consistent Human Geometry Estimation using Image-to-Video Diffusion](https://arxiv.org/abs/2505.23085)**|Project page: https://research.nvidia.com/labs/dair/geoman|None|Gwanghyun Kim et al.|
|**2025-05-28**|**[MR.NAVI: Mixed-Reality Navigation Assistant for the Visually Impaired](https://arxiv.org/abs/2506.05369)**|None|None|Nicolas Pfitzer et al.|
|**2025-05-27**|**[Object Concepts Emerge from Motion](https://arxiv.org/abs/2505.21635)**|None|None|Haoqian Liang et al.|
|**2025-05-27**|**[Occlusion Boundary and Depth: Mutual Enhancement via Multi-Task Learning](https://arxiv.org/abs/2505.21231)**|7 pages, 4 tables, 4 figures|None|Lintao Xu et al.|
|**2025-05-27**|**[Robust Video-Based Pothole Detection and Area Estimation for Intelligent Vehicles with Depth Map and Kalman Smoothing](https://arxiv.org/abs/2505.21049)**|None|None|Dehao Wang et al.|
|**2025-05-26**|**[SpikeStereoNet: A Brain-Inspired Framework for Stereo Depth Estimation from Spike Streams](https://arxiv.org/abs/2505.19487)**|None|None|Zhuoheng Gao et al.|
|**2025-05-23**|**[EvidenceMoE: A Physics-Guided Mixture-of-Experts with Evidential Critics for Advancing Fluorescence Light Detection and Ranging in Scattering Media](https://arxiv.org/abs/2505.21532)**|18 pages, 4 figures|None|Ismail Erbas et al.|
|**2025-05-23**|**[Repurposing Marigold for Zero-Shot Metric Depth Estimation via Defocus Blur Cues](https://arxiv.org/abs/2505.17358)**|None|None|Chinmay Talegaonkar et al.|
|**2025-05-22**|**[MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation](https://arxiv.org/abs/2505.16602)**|None|None|Bohan Zhou et al.|
|**2025-05-22**|**[BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World](https://arxiv.org/abs/2505.16154)**|None|None|Ji Guo et al.|
|**2025-05-20**|**[M3Depth: Wavelet-Enhanced Depth Estimation on Mars via Mutual Boosting of Dual-Modal Data](https://arxiv.org/abs/2505.14159)**|None|None|Junjie Li et al.|
|**2025-05-20**|**[Multi-Label Stereo Matching for Transparent Scene Depth Estimation](https://arxiv.org/abs/2505.14008)**|None|None|Zhidan Liu et al.|
|**2025-05-19**|**[Event-Driven Dynamic Scene Depth Completion](https://arxiv.org/abs/2505.13279)**|9 pages|None|Zhiqiang Yan et al.|
|**2025-05-19**|**[DB3D-L: Depth-aware BEV Feature Transformation for Accurate 3D Lane Detection](https://arxiv.org/abs/2505.13266)**|None|None|Yehao Liu et al.|
|**2025-05-19**|**[3D Visual Illusion Depth Estimation](https://arxiv.org/abs/2505.13061)**|Project: https://github.com/YaoChengTang/3D-Visual-Illusion-Depth-Estimation|None|Chengtang Yao et al.|
|**2025-05-19**|**[IA-MVS: Instance-Focused Adaptive Depth Sampling for Multi-View Stereo](https://arxiv.org/abs/2505.12714)**|None|None|Yinzhe Wang et al.|
|**2025-05-18**|**[Always Clear Depth: Robust Monocular Depth Estimation under Adverse Weather](https://arxiv.org/abs/2505.12199)**|None|None|Kui Jiang et al.|
|**2025-05-17**|**[MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos](https://arxiv.org/abs/2505.11868)**|None|None|Hongyi Zhou et al.|
|**2025-05-16**|**[SurgPose: Generalisable Surgical Instrument Pose Estimation using Zero-Shot Learning and Stereo Vision](https://arxiv.org/abs/2505.11439)**|To be published in 2025 International Conference on Robotics and Automation (ICRA)|None|Utsav Rai et al.|
|**2025-05-15**|**[Depth Anything with Any Prior](https://arxiv.org/abs/2505.10565)**|Home page: https://prior-depth-anything.github.io/|None|Zehan Wang et al.|
|**2025-05-14**|**[Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis](https://arxiv.org/abs/2505.09358)**|Journal extension of our CVPR 2024 paper, featuring new tasks, improved efficiency, high-resolution capabilities, and enhanced accessibility|None|Bingxin Ke et al.|
|**2025-05-13**|**[Boosting Zero-shot Stereo Matching using Large-scale Mixed Images Sources in the Real World](https://arxiv.org/abs/2505.08607)**|None|None|Yuran Wang et al.|
|**2025-05-10**|**[ElectricSight: 3D Hazard Monitoring for Power Lines Using Low-Cost Sensors](https://arxiv.org/abs/2505.06573)**|None|None|Xingchen Li et al.|
|**2025-05-09**|**[Camera-Only Bird's Eye View Perception: A Neural Approach to LiDAR-Free Environmental Mapping for Autonomous Vehicles](https://arxiv.org/abs/2505.06113)**|None|None|Anupkumar Bochare|
|**2025-05-07**|**[MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection](https://arxiv.org/abs/2505.04594)**|None|None|Zhihao Zhang et al.|
|**2025-05-06**|**[LiftFeat: 3D Geometry-Aware Local Feature Matching](https://arxiv.org/abs/2505.03422)**|Accepted at ICRA 2025|None|Yepeng Liu et al.|
|**2025-05-05**|**[VGLD: Visually-Guided Linguistic Disambiguation for Monocular Depth Scale Recovery](https://arxiv.org/abs/2505.02704)**|19 pages, conference|None|Bojin Wu, Jing Chen|
|**2025-05-05**|**[DELTA: Dense Depth from Events and LiDAR using Transformer's Attention](https://arxiv.org/abs/2505.02593)**|Accepted for the CVPR 2025 Workshop on Event-based Vision. For the project page, see https://vbrebion.github.io/DELTA/|None|Vincent Brebion et al.|
|**2025-05-03**|**[PosePilot: Steering Camera Pose for Generative World Models with Self-supervised Depth](https://arxiv.org/abs/2505.01729)**|Accepted at IEEE/RSJ IROS 2025|None|Bu Jin et al.|
|**2025-05-02**|**[LMDepth: Lightweight Mamba-based Monocular Depth Estimation for Real-World Deployment](https://arxiv.org/abs/2505.00980)**|None|None|Jiahuan Long, Xin Zhou|
|**2025-05-01**|**[JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers](https://arxiv.org/abs/2505.00482)**|Accepted to IEEE/CVF International Conference on Computer Vision (ICCV) 2025. Project page: https://byungki-k.github.io/JointDiT/ Code: https://github.com/ByungKi-K/JointDiT-code|None|Kwon Byung-Ki et al.|
|**2025-04-30**|**[HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation](https://arxiv.org/abs/2504.21650)**|Project Homepage: https://zhouhyocean.github.io/holotime/ Code: https://github.com/PKU-YuanGroup/HoloTime|None|Haiyang Zhou et al.|
|**2025-04-30**|**[eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes](https://arxiv.org/abs/2504.21562)**|None|None|Henry John Krumb, Anirban Mukhopadhyay|
|**2025-04-29**|**[Large-scale visual SLAM for in-the-wild videos](https://arxiv.org/abs/2504.20496)**|fix the overview figure|None|Shuo Sun et al.|
|**2025-04-28**|**[Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video](https://arxiv.org/abs/2504.19819)**|None|None|Hoang Chuong Nguyen et al.|
|**2025-04-27**|**[Leveraging Multi-Modal Saliency and Fusion for Gaze Target Detection](https://arxiv.org/abs/2504.19271)**|accepted at NeurIPS 2023 Gaze Meets ML Workshop|None|Athul M. Mathew et al.|
|**2025-04-26**|**[Depth as Points: Center Point-based Depth Estimation](https://arxiv.org/abs/2504.18773)**|Depth Esitimation, Key-points, Virtual Datasets, Autonomous Driving|None|Zhiheng Tu et al.|
|**2025-04-25**|**[LaRI: Layered Ray Intersections for Single-view 3D Geometric Reasoning](https://arxiv.org/abs/2504.18424)**|Project page: https://ruili3.github.io/lari|None|Rui Li et al.|
|**2025-04-25**|**[Dense Geometry Supervision for Underwater Depth Estimation](https://arxiv.org/abs/2504.18233)**|None|None|Wenxiang Gua, Lin Qia|
|**2025-04-25**|**[LiDAR-Guided Monocular 3D Object Detection for Long-Range Railway Monitoring](https://arxiv.org/abs/2504.18203)**|Accepted for the Data-Driven Learning for Intelligent Vehicle Applications Workshop at the 36th IEEE Intelligent Vehicles Symposium (IV) 2025|None|Raul David Dominguez Sanchez et al.|
|**2025-04-24**|**[The Fourth Monocular Depth Estimation Challenge](https://arxiv.org/abs/2504.17787)**|To appear in CVPRW2025|None|Anton Obukhov et al.|
|**2025-04-24**|**[Occlusion-Aware Self-Supervised Monocular Depth Estimation for Weak-Texture Endoscopic Images](https://arxiv.org/abs/2504.17582)**|None|None|Zebo Huang, Yinghui Wang|
|**2025-04-23**|**[PPS-Ctrl: Controllable Sim-to-Real Translation for Colonoscopy Depth Estimation](https://arxiv.org/abs/2504.17067)**|None|None|Xinqi Xiong et al.|
|**2025-04-22**|**[DERD-Net: Learning Depth from Event-based Ray Densities](https://arxiv.org/abs/2504.15863)**|13 pages, 3 figures, 14 tables. Project page: https://github.com/tub-rip/DERD-Net|None|Diego de Oliveira Hitzges et al.|
|**2025-04-21**|**[VistaDepth: Frequency Modulation with Bias Reweighting for Enhanced Far-range Depth Estimation](https://arxiv.org/abs/2504.15095)**|None|None|Mingxia Zhan et al.|
|**2025-04-21**|**[MonoTher-Depth: Enhancing Thermal Depth Estimation via Confidence-Aware Distillation](https://arxiv.org/abs/2504.16127)**|8 Pages; The code will be available at https://github.com/ZuoJiaxing/monother_depth|IEEE Robotics and Automation Letters (RA-L), 2025|Xingxing Zuo et al.|
|**2025-04-20**|**[Seurat: From Moving Points to Depth](https://arxiv.org/abs/2504.14687)**|CVPR 2025 Highlight. Project page: https://seurat-cvpr.github.io|None|Seokju Cho et al.|
|**2025-04-18**|**[Occlusion-Ordered Semantic Instance Segmentation](https://arxiv.org/abs/2504.14054)**|None|None|Soroosh Baselizadeh et al.|
|**2025-04-17**|**[Perception Encoder: The best visual embeddings are not at the output of the network](https://arxiv.org/abs/2504.13181)**|Updated refs, fixed typos, and added new COCO SotA: 66.0 val mAP! Code, models, and data at https://github.com/facebookresearch/perception_models|None|Daniel Bolya et al.|
|**2025-04-17**|**[TSGS: Improving Gaussian Splatting for Transparent Surface Reconstruction via Normal and De-lighting Priors](https://arxiv.org/abs/2504.12799)**|Project page: https://longxiang-ai.github.io/TSGS/|None|Mingwei Li et al.|
|**2025-04-17**|**[Privacy-Preserving Operating Room Workflow Analysis using Digital Twins](https://arxiv.org/abs/2504.12552)**|None|None|Alejandra Perez et al.|
|**2025-04-16**|**[Metric-Solver: Sliding Anchored Metric Depth Estimation from a Single Image](https://arxiv.org/abs/2504.12103)**|Our project page: https://tele-ai.github.io/MetricSolver/|None|Tao Wen et al.|
|**2025-04-16**|**[TacoDepth: Towards Efficient Radar-Camera Depth Estimation with One-stage Fusion](https://arxiv.org/abs/2504.11773)**|Accepted by CVPR 2025 (Oral Presentation)|None|Yiran Wang et al.|
|**2025-04-15**|**[Aligning Generative Denoising with Discriminative Objectives Unleashes Diffusion for Visual Perception](https://arxiv.org/abs/2504.11457)**|ICLR 2025|ICLR 2025|Ziqi Pang et al.|
|**2025-04-15**|**[DeepWheel: Generating a 3D Synthetic Wheel Dataset for Design and Performance Evaluation](https://arxiv.org/abs/2504.11347)**|28 pages, 18 figures. Not yet submitted to a journal or conference|None|Soyoung Yoo, Namwoo Kang|
|**2025-04-13**|**[TextSplat: Text-Guided Semantic Fusion for Generalizable Gaussian Splatting](https://arxiv.org/abs/2504.09588)**|None|None|Zhicong Wu et al.|
|**2025-04-12**|**[Text To 3D Object Generation For Scalable Room Assembly](https://arxiv.org/abs/2504.09328)**|Published at the ICLR 2025 Workshop on Synthetic Data|None|Sonia Laguna et al.|
|**2025-04-11**|**[Cut-and-Splat: Leveraging Gaussian Splatting for Synthetic Data Generation](https://arxiv.org/abs/2504.08473)**|Accepted at the International Conference on Robotics, Computer Vision and Intelligent Systems 2025 (ROBOVIS)|None|Bram Vanherle et al.|
|**2025-04-10**|**[Geo4D: Leveraging Video Generators for Geometric 4D Scene Reconstruction](https://arxiv.org/abs/2504.07961)**|16 pages, 5 figures, Project page: https://geo4d.github.io/|None|Zeren Jiang et al.|
|**2025-04-09**|**[FlashDepth: Real-time Streaming Video Depth Estimation at 2K Resolution](https://arxiv.org/abs/2504.07093)**|None|None|Gene Chou et al.|
|**2025-04-07**|**[Stereo-LiDAR Fusion by Semi-Global Matching With Discrete Disparity-Matching Cost and Semidensification](https://arxiv.org/abs/2504.05148)**|8 pages, 8 figures, 7 tables|in IEEE Robotics and Automation Letters, vol. 10, no. 5, pp. 4548-4555, May 2025|Yasuhiro Yao et al.|
|**2025-04-04**|**[3D Scene Understanding Through Local Random Access Sequence Modeling](https://arxiv.org/abs/2504.03875)**|Project webpage: https://neuroailab.github.io/projects/lras_3d/|None|Wanhee Lee et al.|
|**2025-04-04**|**[RingMoE: Mixture-of-Modality-Experts Multi-Modal Foundation Models for Universal Remote Sensing Image Interpretation](https://arxiv.org/abs/2504.03166)**|None|None|Hanbo Bi et al.|
|**2025-04-02**|**[FreSca: Scaling in Frequency Space Enhances Diffusion Models](https://arxiv.org/abs/2504.02154)**|Project page: https://wikichao.github.io/FreSca/|None|Chao Huang et al.|
|**2025-04-02**|**[Toward Real-world BEV Perception: Depth Uncertainty Estimation via Gaussian Splatting](https://arxiv.org/abs/2504.01957)**|Accepted to CVPR'25. https://hcis-lab.github.io/GaussianLSS/|None|Shu-Wei Lu et al.|
|**2025-04-02**|**[DEPTHOR: Depth Enhancement from a Practical Light-Weight dToF Sensor and RGB Image](https://arxiv.org/abs/2504.01596)**|16 pages, 15 figures, 7 tables|None|Jijun Xiang et al.|
|**2025-04-01**|**[Monocular and Generalizable Gaussian Talking Head Animation](https://arxiv.org/abs/2504.00665)**|Accepted by CVPR 2025|None|Shengjie Gong et al.|
|**2025-03-31**|**[ExScene: Free-View 3D Scene Reconstruction with Gaussian Splatting from a Single Image](https://arxiv.org/abs/2503.23881)**|ICME 2025|None|Tianyi Gong et al.|
|**2025-03-31**|**[Detail-aware multi-view stereo network for depth estimation](https://arxiv.org/abs/2503.23684)**|None|None|Haitao Tian et al.|
|**2025-03-30**|**[Blurry-Edges: Photon-Limited Depth Estimation from Defocused Boundaries](https://arxiv.org/abs/2503.23606)**|Accepted to CVPR 2025. Project page: https://blurry-edges.qiguo.org/|None|Wei Xu et al.|
|**2025-03-30**|**[Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model](https://arxiv.org/abs/2503.23502)**|Project page: https://vita-epfl.github.io/DFI-OmniStereo-website/|None|Jannik Endres et al.|
|**2025-03-28**|**[SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations](https://arxiv.org/abs/2503.22462)**|Accepted to CVPR 2025. Poster: https://cvpr.thecvf.com/virtual/2025/poster/32799|None|Krispin Wandel, Hesheng Wang|
|**2025-03-28**|**[EndoLRMGS: Complete Endoscopic Scene Reconstruction combining Large Reconstruction Modelling and Gaussian Splatting](https://arxiv.org/abs/2503.22437)**|None|None|Xu Wang et al.|
|**2025-03-28**|**[MVSAnywhere: Zero-Shot Multi-View Stereo](https://arxiv.org/abs/2503.22430)**|CVPR 2025|None|Sergio Izquierdo et al.|
|**2025-03-28**|**[One Look is Enough: Seamless Patchwise Refinement for Zero-Shot Monocular Depth Estimation on High-Resolution Images](https://arxiv.org/abs/2503.22351)**|ICCV 2025 (camera-ready version). [Project page](https://kaist-viclab.github.io/One-Look-is-Enough_site)|None|Byeongjun Kwon, Munchurl Kim|
|**2025-03-28**|**[Intrinsic Image Decomposition for Robust Self-supervised Monocular Depth Estimation on Reflective Surfaces](https://arxiv.org/abs/2503.22209)**|Accepted at AAAI 2025|None|Wonhyeok Choi et al.|
|**2025-03-28**|**[Deep Depth Estimation from Thermal Image: Dataset, Benchmark, and Challenges](https://arxiv.org/abs/2503.22060)**|MS^2 dataset: https://sites.google.com/view/multi-spectral-stereo-dataset, Source code: https://github.com/UkcheolShin/SupDepth4Thermal|None|Ukcheol Shin, Jinsun Park|
|**2025-03-27**|**[A Unified Image-Dense Annotation Generation Model for Underwater Scenes](https://arxiv.org/abs/2503.21771)**|Accepted by CVPR 2025. The code is available at https://github.com/HongkLin/TIDE|None|Hongkai Lin et al.|
|**2025-03-27**|**[ICG-MVSNet: Learning Intra-view and Cross-view Relationships for Guidance in Multi-View Stereo](https://arxiv.org/abs/2503.21525)**|None|None|Yuxi Hu et al.|
|**2025-03-26**|**[Synthetic-to-Real Self-supervised Robust Depth Estimation via Learning with Motion and Structure Priors](https://arxiv.org/abs/2503.20211)**|None|None|Weilong Yan et al.|
|**2025-03-26**|**[Omnidirectional Depth-Aided Occupancy Prediction based on Cylindrical Voxel for Autonomous Driving](https://arxiv.org/abs/2504.01023)**|None|None|Chaofan Wu et al.|
|**2025-03-25**|**[FUSE: Label-Free Image-Event Joint Monocular Depth Estimation via Frequency-Decoupled Alignment and Degradation-Robust Fusion](https://arxiv.org/abs/2503.19739)**|8 pages, 6 figures|None|Pihai Sun et al.|
|**2025-03-24**|**[StableGS: A Floater-Free Framework for 3D Gaussian Splatting](https://arxiv.org/abs/2503.18458)**|None|None|Luchao Wang et al.|
|**2025-03-24**|**[PDDM: Pseudo Depth Diffusion Model for RGB-PD Semantic Segmentation Based in Complex Indoor Scenes](https://arxiv.org/abs/2503.18393)**|None|None|Xinhua Xu et al.|
|**2025-03-21**|**[Radar-Guided Polynomial Fitting for Metric Depth Estimation](https://arxiv.org/abs/2503.17182)**|None|None|Patrick Rim et al.|
|**2025-03-21**|**[AnimatePainter: A Self-Supervised Rendering Framework for Reconstructing Painting Process](https://arxiv.org/abs/2503.17029)**|None|None|Junjie Hu et al.|
|**2025-03-21**|**[Distilling Monocular Foundation Model for Fine-grained Depth Completion](https://arxiv.org/abs/2503.16970)**|None|None|Yingping Liang et al.|
|**2025-03-20**|**[QuartDepth: Post-Training Quantization for Real-Time Depth Estimation on the Edge](https://arxiv.org/abs/2503.16709)**|Accepted by CVPR 2025|None|Xuan Shen et al.|
|**2025-03-20**|**[A Recipe for Generating 3D Worlds From a Single Image](https://arxiv.org/abs/2503.16611)**|None|None|Katja Schwarz et al.|
|**2025-03-20**|**[Learning to Efficiently Adapt Foundation Models for Self-Supervised Endoscopic 3D Scene Reconstruction from Any Cameras](https://arxiv.org/abs/2503.15917)**|None|None|Beilei Cui et al.|
|**2025-03-20**|**[Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation](https://arxiv.org/abs/2503.15905)**|None|None|Jiyuan Wang et al.|
|**2025-03-19**|**[TULIP: Towards Unified Language-Image Pretraining](https://arxiv.org/abs/2503.15485)**|(v2) Clarified fine-tuning process, updated appendix|None|Zineng Tang et al.|
|**2025-03-19**|**[EgoDTM: Towards 3D-Aware Egocentric Video-Language Pretraining](https://arxiv.org/abs/2503.15470)**|Code will be released at: https://github.com/xuboshen/EgoDTM|None|Boshen Xu et al.|
|**2025-03-19**|**[USAM-Net: A U-Net-based Network for Improved Stereo Correspondence and Scene Depth Estimation using Features from a Pre-trained Image Segmentation network](https://arxiv.org/abs/2503.14950)**|None|None|Joseph Emmanuel DL Dayo, Prospero C. Naval Jr|
|**2025-03-18**|**[Vision-Language Embodiment for Monocular Depth Estimation](https://arxiv.org/abs/2503.16535)**|None|None|Jinchang Zhang, Guoyu Lu|
|**2025-03-18**|**[Multi-view Reconstruction via SfM-guided Monocular Depth Estimation](https://arxiv.org/abs/2503.14483)**|CVPR 2025. Project page: https://zju3dv.github.io/murre/|None|Haoyu Guo et al.|
|**2025-03-18**|**[DUNE: Distilling a Universal Encoder from Heterogeneous 2D and 3D Teachers](https://arxiv.org/abs/2503.14405)**|Accepted to CVPR-2025. Project page: https://europe.naverlabs.com/dune|None|Mert Bulent Sariyildiz et al.|
|**2025-03-18**|**[3D Densification for Multi-Map Monocular VSLAM in Endoscopy](https://arxiv.org/abs/2503.14346)**|None|None|X. Anadón et al.|
|**2025-03-17**|**[MonoCT: Overcoming Monocular 3D Detection Domain Shift with Consistent Teacher Models](https://arxiv.org/abs/2503.13743)**|ICRA2025|None|Johannes Meier et al.|
|**2025-03-17**|**[Improving Geometric Consistency for 360-Degree Neural Radiance Fields in Indoor Scenarios](https://arxiv.org/abs/2503.13710)**|None|Proc. VISAPP 2025|Iryna Repinetska et al.|
|**2025-03-17**|**[FlexWorld: Progressively Expanding 3D Scenes for Flexiable-View Synthesis](https://arxiv.org/abs/2503.13265)**|None|None|Luxi Chen et al.|
|**2025-03-17**|**[MM-Spatial: Exploring 3D Spatial Understanding in Multimodal LLMs](https://arxiv.org/abs/2503.13111)**|None|None|Erik Daxberger et al.|
|**2025-03-17**|**[TransDiff: Diffusion-Based Method for Manipulating Transparent Objects Using a Single RGB-D Image](https://arxiv.org/abs/2503.12779)**|Accepted by ICRA 2025|None|Haoxiao Wang et al.|
|**2025-03-16**|**[UniVG: A Generalist Diffusion Model for Unified Image Generation and Editing](https://arxiv.org/abs/2503.12652)**|None|None|Tsu-Jui Fu et al.|
|**2025-03-16**|**[Deblur Gaussian Splatting SLAM](https://arxiv.org/abs/2503.12572)**|None|None|Francesco Girlanda et al.|
|**2025-03-14**|**[VGGT: Visual Geometry Grounded Transformer](https://arxiv.org/abs/2503.11651)**|CVPR 2025, Project Page: https://vgg-t.github.io/|None|Jianyuan Wang et al.|
|**2025-03-14**|**[Seeing and Seeing Through the Glass: Real and Synthetic Data for Multi-Layer Depth Estimation](https://arxiv.org/abs/2503.11633)**|None|None|Hongyu Wen et al.|
|**2025-03-14**|**[Simulating Dual-Pixel Images From Ray Tracing For Depth Estimation](https://arxiv.org/abs/2503.11213)**|None|None|Fengchen He et al.|
|**2025-03-13**|**[Flow-NeRF: Joint Learning of Geometry, Poses, and Dense Flow within Unified Neural Representations](https://arxiv.org/abs/2503.10464)**|None|None|Xunzhi Zheng, Dan Xu|
|**2025-03-12**|**[WonderVerse: Extendable 3D Scene Generation with Video Generative Models](https://arxiv.org/abs/2503.09160)**|None|None|Hao Feng et al.|
|**2025-03-11**|**[Language-Depth Navigated Thermal and Visible Image Fusion](https://arxiv.org/abs/2503.08676)**|None|None|Jinchang Zhang et al.|
|**2025-03-11**|**[CL-MVSNet: Unsupervised Multi-view Stereo with Dual-level Contrastive Learning](https://arxiv.org/abs/2503.08219)**|Accpetd by ICCV2023|None|Kaiqiang Xiong et al.|
|**2025-03-10**|**[SIRE: SE(3) Intrinsic Rigidity Embeddings](https://arxiv.org/abs/2503.07739)**|None|None|Cameron Smith et al.|
|**2025-03-10**|**[LBM: Latent Bridge Matching for Fast Image-to-Image Translation](https://arxiv.org/abs/2503.07535)**|None|None|Clément Chadebec et al.|
|**2025-03-10**|**[Endo-FASt3r: Endoscopic Foundation model Adaptation for Structure from motion](https://arxiv.org/abs/2503.07204)**|None|None|Mona Sheikh Zeinoddin et al.|
|**2025-03-09**|**[LightMotion: A Light and Tuning-free Method for Simulating Camera Motion in Video Generation](https://arxiv.org/abs/2503.06508)**|18 pages in total|None|Quanjian Song et al.|
|**2025-03-08**|**[Towards Ambiguity-Free Spatial Foundation Model: Rethinking and Decoupling Depth Ambiguity](https://arxiv.org/abs/2503.06014)**|32 pages, 31 figures, github repo: https://github.com/Xiaohao-Xu/Ambiguity-in-Space|None|Xiaohao Xu et al.|
|**2025-03-07**|**[TomatoScanner: phenotyping tomato fruit based on only RGB image](https://arxiv.org/abs/2503.05568)**|12 pages, 37 figures. Codes and datasets are open-sourced in https://github.com/AlexTraveling/TomatoScanner|None|Xiaobei Zhao et al.|
|**2025-03-06**|**[A Novel Solution for Drone Photogrammetry with Low-overlap Aerial Images using Monocular Depth Estimation](https://arxiv.org/abs/2503.04513)**|None|None|Jiageng Zhong et al.|
|**2025-03-06**|**[H3O: Hyper-Efficient 3D Occupancy Prediction with Heterogeneous Supervision](https://arxiv.org/abs/2503.04059)**|ICRA 2025|None|Yunxiao Shi et al.|
|**2025-03-05**|**[Task-Agnostic Attacks Against Vision Foundation Models](https://arxiv.org/abs/2503.03842)**|None|None|Brian Pulfer et al.|
|**2025-03-03**|**[MUSt3R: Multi-view Network for Stereo 3D Reconstruction](https://arxiv.org/abs/2503.01661)**|Accepted at CVPR 2025|None|Yohann Cabon et al.|
|**2025-03-02**|**[Bridging Spectral-wise and Multi-spectral Depth Estimation via Geometry-guided Contrastive Learning](https://arxiv.org/abs/2503.00793)**|Accepted at ICRA 2025, Github link: https://github.com/UkcheolShin/BridgeMultiSpectralDepth|None|Ukcheol Shin et al.|
|**2025-02-28**|**[EndoPBR: Material and Lighting Estimation for Photorealistic Surgical Simulations via Physically-based Rendering](https://arxiv.org/abs/2502.20669)**|10 pages, 3 figures|None|John J. Han, Jie Ying Wu|
|**2025-02-27**|**[UniDepthV2: Universal Monocular Metric Depth Estimation Made Simpler](https://arxiv.org/abs/2502.20110)**|arXiv admin note: substantial text overlap with arXiv:2403.18913|None|Luigi Piccinelli et al.|
|**2025-02-26**|**[Distill Any Depth: Distillation Creates a Stronger Monocular Depth Estimator](https://arxiv.org/abs/2502.19204)**|project page: https://distill-any-depth-official.github.io/|None|Xiankang He et al.|
|**2025-02-21**|**[RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes](https://arxiv.org/abs/2502.15633)**|ICRA 2025|None|Sicheng Yu et al.|
|**2025-02-20**|**[Monocular Depth Estimation and Segmentation for Transparent Object with Iterative Semantic and Geometric Fusion](https://arxiv.org/abs/2502.14616)**|Accepted by ICRA(2025). The code is accessible through: https://github.com/L-J-Yuan/MODEST|None|Jiangyuan Liu et al.|
|**2025-02-20**|**[Self-supervised Monocular Depth Estimation Robust to Reflective Surface Leveraged by Triplet Mining](https://arxiv.org/abs/2502.14573)**|Accepted at ICLR 2025|None|Wonhyeok Choi et al.|
|**2025-02-20**|**[OrchardDepth: Precise Metric Depth Estimation of Orchard Scene from Monocular Camera Images](https://arxiv.org/abs/2502.14279)**|10 pages, 5 figures, Australasian Conference on Robotics and Automation, ACRA, 2024|None|Zhichao Zheng et al.|
|**2025-02-18**|**[SHADeS: Self-supervised Monocular Depth Estimation Through Non-Lambertian Image Decomposition](https://arxiv.org/abs/2502.12994)**|None|None|Rema Daher et al.|
|**2025-02-17**|**[Deep Neural Networks for Accurate Depth Estimation with Latent Space Features](https://arxiv.org/abs/2502.11777)**|None|Yasir, S.M.; Ahn, H. Deep Neural Networks for Accurate Depth Estimation with Latent Space Features. Biomimetics 2024, 9, 747|Siddiqui Muhammad Yasir, Hyunsik Ahn|
|**2025-02-16**|**[Adjust Your Focus: Defocus Deblurring From Dual-Pixel Images Using Explicit Multi-Scale Cross-Correlation](https://arxiv.org/abs/2502.11002)**|Accepted in CVIP 2023|None|Kunal Swami|
|**2025-02-14**|**[RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control](https://arxiv.org/abs/2502.10059)**|Accepted by ICCV 2025|None|Teng Li et al.|
|**2025-02-13**|**[SteROI-D: System Design and Mapping for Stereo Depth Inference on Regions of Interest](https://arxiv.org/abs/2502.09528)**|Accepted as a full paper by the 2025 EDGE AI FOUNDATION Austin|None|Jack Erhardt et al.|
|**2025-02-13**|**[CoL3D: Collaborative Learning of Single-view Depth and Camera Intrinsics for Metric 3D Shape Recovery](https://arxiv.org/abs/2502.08902)**|Accepted at ICRA 2025|None|Chenghao Zhang et al.|
|**2025-02-11**|**[Learning Inverse Laplacian Pyramid for Progressive Depth Completion](https://arxiv.org/abs/2502.07289)**|None|None|Kun Wang et al.|
|**2025-02-10**|**[From Image to Video: An Empirical Study of Diffusion Representations](https://arxiv.org/abs/2502.07001)**|None|None|Pedro Vélez et al.|
|**2025-02-09**|**[Revisiting Gradient-based Uncertainty for Monocular Depth Estimation](https://arxiv.org/abs/2502.05964)**|Accepted to TPAMI|None|Julia Hornauer et al.|
|**2025-02-04**|**[DOC-Depth: A novel approach for dense depth ground truth generation](https://arxiv.org/abs/2502.02144)**|Preprint. Code and dataset available on the project page : https://simondemoreau.github.io/DOC-Depth/|None|Simon de Moreau et al.|
|**2025-02-01**|**[Leveraging Stable Diffusion for Monocular Depth Estimation via Image Semantic Encoding](https://arxiv.org/abs/2502.01666)**|None|None|Jingming Xia et al.|
|**2025-02-01**|**[MonoDINO-DETR: Depth-Enhanced Monocular 3D Object Detection Using a Vision Foundation Model](https://arxiv.org/abs/2502.00315)**|8 pages, 8 figures|None|Jihyeok Kim et al.|
|**2025-01-30**|**[Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric Diffusion](https://arxiv.org/abs/2501.18804)**|Project page: https://mvgd.github.io|None|Vitor Guizilini et al.|
|**2025-01-25**|**[Snapshot Compressed Imaging Based Single-Measurement Computer Vision for Videos](https://arxiv.org/abs/2501.15122)**|None|None|Fengpu Pan et al.|
|**2025-01-24**|**[Rethinking Encoder-Decoder Flow Through Shared Structures](https://arxiv.org/abs/2501.14535)**|None|None|Frederik Laboyrie et al.|
|**2025-01-23**|**[IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models](https://arxiv.org/abs/2501.13920)**|75 pages, 73 figures, Evaluation scripts: https://github.com/jylei16/Imagine-e|None|Jiayi Lei et al.|
|**2025-01-23**|**[PromptMono: Cross Prompting Attention for Self-Supervised Monocular Depth Estimation in Challenging Environments](https://arxiv.org/abs/2501.13796)**|10 pages|None|Changhao Wang et al.|
|**2025-01-22**|**[Enhancing Monocular Depth Estimation with Multi-Source Auxiliary Tasks](https://arxiv.org/abs/2501.12824)**|Paper accepted at WACV 2025|WACV 2025|Alessio Quercia et al.|
|**2025-01-21**|**[Video Depth Anything: Consistent Depth Estimation for Super-Long Videos](https://arxiv.org/abs/2501.12375)**|Project page: https://videodepthanything.github.io/|None|Sili Chen et al.|
|**2025-01-21**|**[Fast Underwater Scene Reconstruction using Multi-View Stereo and Physical Imaging](https://arxiv.org/abs/2501.11884)**|None|None|Shuyi Hu, Qi Liu|
|**2025-01-21**|**[Survey on Monocular Metric Depth Estimation](https://arxiv.org/abs/2501.11841)**|None|None|Jiuling Zhang|
|**2025-01-19**|**[RDG-GS: Relative Depth Guidance with Gaussian Splatting for Real-time Sparse-View 3D Rendering](https://arxiv.org/abs/2501.11102)**|24 pages, 12 figures|None|Chenlu Zhan et al.|
|**2025-01-17**|**[Zero-Shot Monocular Scene Flow Estimation in the Wild](https://arxiv.org/abs/2501.10357)**|Project Website: https://research.nvidia.com/labs/lpr/zero_msf//|None|Yiqing Liang et al.|
|**2025-01-17**|**[One-D-Piece: Image Tokenizer Meets Quality-Controllable Compression](https://arxiv.org/abs/2501.10064)**|Our Project Page: https://turingmotors.github.io/one-d-piece-tokenizer|None|Keita Miwa et al.|
|**2025-01-17**|**[Multi-Modal Attention Networks for Enhanced Segmentation and Depth Estimation of Subsurface Defects in Pulse Thermography](https://arxiv.org/abs/2501.09994)**|Pulse thermography, infrared thermography, defect segmentation, multi-modal networks, attention mechanism|None|Mohammed Salah et al.|
|**2025-01-17**|**[FoundationStereo: Zero-Shot Stereo Matching](https://arxiv.org/abs/2501.09898)**|CVPR 2025|None|Bowen Wen et al.|
|**2025-01-16**|**[DEFOM-Stereo: Depth Foundation Model Based Stereo Matching](https://arxiv.org/abs/2501.09466)**|https://insta360-research-team.github.io/DEFOM-Stereo/|CVPR 2025|Hualie Jiang et al.|
|**2025-01-15**|**[BloomScene: Lightweight Structured 3D Gaussian Splatting for Crossmodal Scene Generation](https://arxiv.org/abs/2501.10462)**|None|None|Xiaolu Hou et al.|
|**2025-01-15**|**[ZeroStereo: Zero-shot Stereo Matching from Single Images](https://arxiv.org/abs/2501.08654)**|Accepted to ICCV 2025|None|Xianqi Wang et al.|
|**2025-01-15**|**[MonSter: Marry Monodepth to Stereo Unleashes Power](https://arxiv.org/abs/2501.08643)**|None|None|Junda Cheng et al.|
|**2025-01-14**|**[A Critical Synthesis of Uncertainty Quantification and Foundation Models in Monocular Depth Estimation](https://arxiv.org/abs/2501.08188)**|None|None|Steven Landgraf et al.|
|**2025-01-14**|**[Revisiting Birds Eye View Perception Models with Frozen Foundation Models: DINOv2 and Metric3Dv2](https://arxiv.org/abs/2501.08118)**|Accepted for publication at the Electronic Imaging - Autonomous Vehicles and Machines Connference 2025|None|Seamie Hayes et al.|
|**2025-01-13**|**[RePoseD: Efficient Relative Pose Estimation With Known Depth Information](https://arxiv.org/abs/2501.07742)**|18 pages|None|Yaqing Ding et al.|
|**2025-01-13**|**[Matching-Free Depth Recovery from Structured Light](https://arxiv.org/abs/2501.07113)**|13 pages, 10 figures|None|Zhuohang Yu et al.|
|**2025-01-09**|**[Relative Pose Estimation through Affine Corrections of Monocular Depth Priors](https://arxiv.org/abs/2501.05446)**|CVPR 2025 (Highlight)|None|Yifan Yu et al.|
|**2025-01-09**|**[$DPF^*$: improved Depth Potential Function for scale-invariant sulcal depth estimation](https://arxiv.org/abs/2501.05436)**|GA and JL contributed equally to this work|None|Maxime Dieudonné et al.|
|**2025-01-09**|**[A Systematic Literature Review on Deep Learning-based Depth Estimation in Computer Vision](https://arxiv.org/abs/2501.05147)**|None|None|Ali Rohan et al.|
|**2025-01-07**|**[AuxDepthNet: Real-Time Monocular 3D Object Detection with Depth-Sensitive Features](https://arxiv.org/abs/2501.03700)**|None|None|Ruochen Zhang et al.|
|**2025-01-05**|**[DepthMaster: Taming Diffusion Models for Monocular Depth Estimation](https://arxiv.org/abs/2501.02576)**|11 pages, 6 figures, 6 tables|None|Ziyang Song et al.|
|**2025-01-05**|**[Depth Any Camera: Zero-Shot Metric Depth Estimation from Any Camera](https://arxiv.org/abs/2501.02464)**|None|None|Yuliang Guo et al.|
|**2025-01-03**|**[SafeAug: Safety-Critical Driving Data Augmentation from Naturalistic Datasets](https://arxiv.org/abs/2501.02143)**|None|None|Zhaobin Mo et al.|
|**2025-01-03**|**[IGAF: Incremental Guided Attention Fusion for Depth Super-Resolution](https://arxiv.org/abs/2501.01723)**|None|Sensors 2025, 25, 24|Athanasios Tragakis et al.|
|**2025-01-02**|**[TexAVi: Generating Stereoscopic VR Video Clips from Text Descriptions](https://arxiv.org/abs/2501.01156)**|Co-authors do not consent to publishing on Arxiv|TexAVi: Generating Stereoscopic VR Video Clips from Text Descriptions, 2024 IEEE International Conference on Computer Vision and Machine Intelligence (CVMI), Prayagraj, India, 2024, pp. 1-6|Vriksha Srihari et al.|
|**2025-01-02**|**[PatchRefiner V2: Fast and Lightweight Real-Domain High-Resolution Metric Depth Estimation](https://arxiv.org/abs/2501.01121)**|None|None|Zhenyu Li et al.|
|**2024-12-30**|**[FPGA-based Acceleration of Neural Network for Image Classification using Vitis AI](https://arxiv.org/abs/2412.20974)**|None|None|Zhengdong Li et al.|
|**2024-12-29**|**[DPBridge: Latent Diffusion Bridge for Dense Prediction](https://arxiv.org/abs/2412.20506)**|None|None|Haorui Ji et al.|
|**2024-12-29**|**[MetricDepth: Enhancing Monocular Depth Estimation with Deep Metric Learning](https://arxiv.org/abs/2412.20390)**|None|None|Chunpu Liu et al.|
|**2024-12-28**|**[Multi-Modality Driven LoRA for Adverse Condition Depth Estimation](https://arxiv.org/abs/2412.20162)**|None|None|Guanglei Yang et al.|
|**2024-12-28**|**[DepthMamba with Adaptive Fusion](https://arxiv.org/abs/2412.19964)**|None|None|Zelin Meng, Zhichen Wang|
|**2024-12-26**|**[An End-to-End Depth-Based Pipeline for Selfie Image Rectification](https://arxiv.org/abs/2412.19189)**|None|None|Ahmed Alhawwary et al.|
|**2024-12-26**|**[Revisiting Monocular 3D Object Detection with Depth Thickness Field](https://arxiv.org/abs/2412.19165)**|None|None|Qiude Zhang et al.|
|**2024-12-26**|**[MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo](https://arxiv.org/abs/2412.19130)**|7 pages, 6 figures, submitted to IEEE ICRA 2025|None|Byeonggwon Lee et al.|
|**2024-12-26**|**[Learning Monocular Depth from Events via Egomotion Compensation](https://arxiv.org/abs/2412.19067)**|9 pages, 3 figures|None|Haitao Meng et al.|
|**2024-12-24**|**[RSGaussian:3D Gaussian Splatting with LiDAR for Aerial Remote Sensing Novel View Synthesis](https://arxiv.org/abs/2412.18380)**|None|None|Yiling Yao et al.|
|**2024-12-20**|**[LiRCDepth: Lightweight Radar-Camera Depth Estimation via Knowledge Distillation and Uncertainty Guidance](https://arxiv.org/abs/2412.16380)**|Accepted by ICASSP 2025|None|Huawei Sun et al.|
|**2024-12-19**|**[Flowing from Words to Pixels: A Noise-Free Framework for Cross-Modality Evolution](https://arxiv.org/abs/2412.15213)**|CVPR 2025 camera-ready version. Project page: https://cross-flow.github.io/|None|Qihao Liu et al.|
|**2024-12-19**|**[Scaling 4D Representations](https://arxiv.org/abs/2412.15212)**|None|None|João Carreira et al.|
|**2024-12-18**|**[A Simple yet Effective Test-Time Adaptation for Zero-Shot Monocular Metric Depth Estimation](https://arxiv.org/abs/2412.14103)**|None|None|Rémi Marsal et al.|
|**2024-12-18**|**[Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation](https://arxiv.org/abs/2412.14015)**|CVPR 2025, Project page: https://PromptDA.github.io/|None|Haotong Lin et al.|
|**2024-12-18**|**[Marigold-DC: Zero-Shot Monocular Depth Completion with Guided Diffusion](https://arxiv.org/abs/2412.13389)**|None|None|Massimiliano Viola et al.|
|**2024-12-17**|**[Dyn-HaMR: Recovering 4D Interacting Hand Motion from a Dynamic Camera](https://arxiv.org/abs/2412.12861)**|Project page is available at https://dyn-hamr.github.io/|None|Zhengdi Yu et al.|
|**2024-12-17**|**[PromptDet: A Lightweight 3D Object Detection Framework with LiDAR Prompts](https://arxiv.org/abs/2412.12460)**|Accepted by AAAI 2025|None|Kun Guo, Qiang Ling|
|**2024-12-16**|**[V-MIND: Building Versatile Monocular Indoor 3D Detector with Diverse 2D Annotations](https://arxiv.org/abs/2412.11412)**|WACV 2025|None|Jin-Cheng Jhang et al.|
|**2024-12-16**|**[Depth-Centric Dehazing and Depth-Estimation from Real-World Hazy Driving Video](https://arxiv.org/abs/2412.11395)**|Accepted by AAAI 20205, Project page: https://fanjunkai1.github.io/projectpage/DCL/index.html|None|Junkai Fan et al.|
|**2024-12-15**|**[ViPOcc: Leveraging Visual Priors from Vision Foundation Models for Single-View 3D Occupancy Prediction](https://arxiv.org/abs/2412.11210)**|accepted to AAAI25|None|Yi Feng et al.|
|**2024-12-14**|**[MAL: Cluster-Masked and Multi-Task Pretraining for Enhanced xLSTM Vision Performance](https://arxiv.org/abs/2412.10730)**|None|None|Wenjun Huang, Jianguo Hu|
|**2024-12-12**|**[Stereo4D: Learning How Things Move in 3D from Internet Stereo Videos](https://arxiv.org/abs/2412.09621)**|CVPR 2025 Camera Ready; Data released|None|Linyi Jin et al.|
|**2024-12-12**|**[T-SVG: Text-Driven Stereoscopic Video Generation](https://arxiv.org/abs/2412.09323)**|5 pages, 4 figures|None|Qiao Jin et al.|
|**2024-12-12**|**[Cross-View Completion Models are Zero-shot Correspondence Estimators](https://arxiv.org/abs/2412.09072)**|Project Page: https://cvlab-kaist.github.io/ZeroCo/|None|Honggyu An et al.|
|**2024-12-11**|**[Utilizing Multi-step Loss for Single Image Reflection Removal](https://arxiv.org/abs/2412.08582)**|6 pages, 6 figures, IEEE AICCSA 2024|None|Abdelrahman Elnenaey, Marwan Torki|
|**2024-12-11**|**[Dense Depth from Event Focal Stack](https://arxiv.org/abs/2412.08120)**|Accepted at WACV2025|None|Kenta Horikawa et al.|
|**2024-12-10**|**[Diffusion-Based Attention Warping for Consistent 3D Scene Editing](https://arxiv.org/abs/2412.07984)**|None|None|Eyal Gomel, Lior Wolf|
|**2024-12-10**|**[Balancing Shared and Task-Specific Representations: A Hybrid Approach to Depth-Aware Video Panoptic Segmentation](https://arxiv.org/abs/2412.07966)**|Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2025. Code and trained models are available at: https://research.khws.io/multiformer|None|Kurt H. W. Stolle|
|**2024-12-09**|**[SphereUFormer: A U-Shaped Transformer for Spherical 360 Perception](https://arxiv.org/abs/2412.06968)**|None|None|Yaniv Benny, Lior Wolf|
|**2024-12-09**|**[Driv3R: Learning Dense 4D Reconstruction for Autonomous Driving](https://arxiv.org/abs/2412.06777)**|Code is available at: https://github.com/Barrybarry-Smith/Driv3R|None|Xin Fei et al.|
|**2024-12-09**|**[MAtCha Gaussians: Atlas of Charts for High-Quality Geometry and Photorealism From Sparse Views](https://arxiv.org/abs/2412.06767)**|Project Webpage: https://anttwo.github.io/matcha/|None|Antoine Guédon et al.|
|**2024-12-09**|**[Omni-Scene: Omni-Gaussian Representation for Ego-Centric Sparse-View Scene Reconstruction](https://arxiv.org/abs/2412.06273)**|Accepted by CVPR2025|None|Dongxu Wei et al.|
|**2024-12-09**|**[Event fields: Capturing light fields at high speed, resolution, and dynamic range](https://arxiv.org/abs/2412.06191)**|None|None|Ziyuan Qu et al.|
|**2024-12-08**|**[GVDepth: Zero-Shot Monocular Depth Estimation for Ground Vehicles based on Probabilistic Cue Fusion](https://arxiv.org/abs/2412.06080)**|Project website: https://gvdepth.github.io/|None|Karlo Koledic et al.|
|**2024-12-08**|**[Prism: Semi-Supervised Multi-View Stereo with Monocular Structure Priors](https://arxiv.org/abs/2412.05771)**|11 pages, 6 figures, 3 tables|None|Alex Rich et al.|
|**2024-12-07**|**[LATTE: Learning to Think with Vision Specialists](https://arxiv.org/abs/2412.05479)**|None|None|Zixian Ma et al.|
|**2024-12-06**|**[SimC3D: A Simple Contrastive 3D Pretraining Framework Using RGB Images](https://arxiv.org/abs/2412.05274)**|None|None|Jiahua Dong et al.|
|**2024-12-06**|**[PanoDreamer: Optimization-Based Single Image to 360 3D Scene With Diffusion](https://arxiv.org/abs/2412.04827)**|Project page: https://people.engr.tamu.edu/nimak/Papers/PanoDreamer, Code: https://github.com/avinashpaliwal/PanoDreamer|None|Avinash Paliwal et al.|
|**2024-12-05**|**[LAA-Net: A Physical-prior-knowledge Based Network for Robust Nighttime Depth Estimation](https://arxiv.org/abs/2412.04666)**|None|None|Kebin Peng et al.|
|**2024-12-05**|**[MegaSaM: Accurate, Fast, and Robust Structure and Motion from Casual Dynamic Videos](https://arxiv.org/abs/2412.04463)**|Project page: https://mega-sam.github.io/|None|Zhengqi Li et al.|
|**2024-12-05**|**[MT3DNet: Multi-Task learning Network for 3D Surgical Scene Reconstruction](https://arxiv.org/abs/2412.03928)**|1. Notation Update: Added * for equal contribution, ensuring proper attribution. 2. Subsection Fix: Removed the `subsection` tag for Section 3.1 (no 3.2 existed), maintaining content but fixing hierarchy. 3. Text Additions: Added lines in Section 5 and Subsection 4.2 for clarity, with references for better context|None|Mithun Parab et al.|
|**2024-12-04**|**[Perception Tokens Enhance Visual Reasoning in Multimodal Language Models](https://arxiv.org/abs/2412.03548)**|None|None|Mahtab Bigverdi et al.|
|**2024-12-04**|**[Dense Scene Reconstruction from Light-Field Images Affected by Rolling Shutter](https://arxiv.org/abs/2412.03518)**|None|None|Hermes McGriff et al.|
|**2024-12-04**|**[MultiGO: Towards Multi-level Geometry Learning for Monocular 3D Textured Human Reconstruction](https://arxiv.org/abs/2412.03103)**|None|None|Gangjian Zhang et al.|
|**2024-12-04**|**[Align3R: Aligned Monocular Depth Estimation for Dynamic Videos](https://arxiv.org/abs/2412.03079)**|Project Page: https://igl-hkust.github.io/Align3R.github.io/|None|Jiahao Lu et al.|
|**2024-12-03**|**[Single-Shot Metric Depth from Focused Plenoptic Cameras](https://arxiv.org/abs/2412.02386)**|8 pages (6 for text + 2 for references), 6 figures, 2 tables. Accepted at IEEE ICRA 2025|None|Blanca Lasheras-Hernandez et al.|
|**2024-12-03**|**[Dual Exposure Stereo for Extended Dynamic Range 3D Imaging](https://arxiv.org/abs/2412.02351)**|None|None|Juhyung Choi et al.|
|**2024-12-03**|**[Amodal Depth Anything: Amodal Depth Estimation in the Wild](https://arxiv.org/abs/2412.02336)**|None|None|Zhenyu Li et al.|
|**2024-12-03**|**[GSGTrack: Gaussian Splatting-Guided Object Pose Tracking from RGB Videos](https://arxiv.org/abs/2412.02267)**|None|None|Zhiyuan Chen et al.|
|**2024-12-02**|**[Mutli-View 3D Reconstruction using Knowledge Distillation](https://arxiv.org/abs/2412.02039)**|6 pages, 10 figures|None|Aditya Dutt et al.|
|**2024-12-02**|**[STATIC : Surface Temporal Affine for TIme Consistency in Video Monocular Depth Estimation](https://arxiv.org/abs/2412.01090)**|None|None|Sunghun Yang et al.|
|**2024-12-01**|**[FiffDepth: Feed-forward Transformation of Diffusion-Based Generators for Detailed Depth Estimation](https://arxiv.org/abs/2412.00671)**|8 pages, 7 figures|None|Yunpeng Bai, Qixing Huang|
|**2024-11-29**|**[SpaRC: Sparse Radar-Camera Fusion for 3D Object Detection](https://arxiv.org/abs/2411.19860)**|18 pages, 11 figures|None|Philipp Wolters et al.|
|**2024-11-29**|**[MonoPP: Metric-Scaled Self-Supervised Monocular Depth Estimation by Planar-Parallax Geometry in Automotive Applications](https://arxiv.org/abs/2411.19717)**|Accepted at WACV 25, project page: https://mono-pp.github.io/|None|Gasser Elazab et al.|
|**2024-11-29**|**[Gaussian Splashing: Direct Volumetric Rendering Underwater](https://arxiv.org/abs/2411.19588)**|None|None|Nir Mualem et al.|
|**2024-11-28**|**[AGS-Mesh: Adaptive Gaussian Splatting and Meshing with Geometric Priors for Indoor Room Reconstruction Using Smartphones](https://arxiv.org/abs/2411.19271)**|None|None|Xuqian Ren et al.|
|**2024-11-28**|**[Video Depth without Video Models](https://arxiv.org/abs/2411.19189)**|Project page: rollingdepth.github.io|None|Bingxin Ke et al.|
|**2024-11-28**|**[360Recon: An Accurate Reconstruction Method Based on Depth Fusion from 360 Images](https://arxiv.org/abs/2411.19102)**|None|None|Zhongmiao Yan et al.|
|**2024-11-27**|**[Helvipad: A Real-World Dataset for Omnidirectional Stereo Depth Estimation](https://arxiv.org/abs/2411.18335)**|Accepted to CVPR 2025. Project page: https://vita-epfl.github.io/Helvipad|None|Mehdi Zayene et al.|
|**2024-11-27**|**[SharpDepth: Sharpening Metric Depth Predictions Using Diffusion Distillation](https://arxiv.org/abs/2411.18229)**|Uncompressed version can be found in https://drive.google.com/file/d/1MG4-d_xDERVBCRfLDolNLnMLLuqd7qRz|None|Duc-Hai Pham et al.|
|**2024-11-26**|**[Low-rank Adaptation-based All-Weather Removal for Autonomous Navigation](https://arxiv.org/abs/2411.17814)**|Project page: https://sudraj2002.github.io/loraapage/|None|Sudarshan Rajagopalan, Vishal M. Patel|
|**2024-11-26**|**[Spatially Visual Perception for End-to-End Robotic Learning](https://arxiv.org/abs/2411.17458)**|8 pages, 5 figures|None|Travis Davies et al.|
|**2024-11-26**|**[DepthCues: Evaluating Monocular Depth Perception in Large Vision Models](https://arxiv.org/abs/2411.17385)**|Accepted to CVPR 2025. Project page: https://danier97.github.io/depthcues/|None|Duolikun Danier et al.|
|**2024-11-26**|**[Boost 3D Reconstruction using Diffusion-based Monocular Camera Calibration](https://arxiv.org/abs/2411.17240)**|None|None|Junyuan Deng et al.|
|**2024-11-25**|**[MonoGSDF: Exploring Monocular Geometric Cues for Gaussian Splatting-Guided Implicit Surface Reconstruction](https://arxiv.org/abs/2411.16898)**|None|None|Kunyi Li et al.|
|**2024-11-25**|**[Generative Omnimatte: Learning to Decompose Video into Layers](https://arxiv.org/abs/2411.16683)**|CVPR 2025. Project page: https://gen-omnimatte.github.io/|None|Yao-Chih Lee et al.|
|**2024-11-25**|**[One Diffusion to Generate Them All](https://arxiv.org/abs/2411.16318)**|CVPR 2025; two first authors contribute equally|None|Duong H. Le et al.|
|**2024-11-24**|**[Gaussian Scenes: Pose-Free Sparse-View Scene Reconstruction using Depth-Enhanced Diffusion Priors](https://arxiv.org/abs/2411.15966)**|Project page is available at https://gaussianscenes.github.io/|None|Soumava Paul et al.|
|**2024-11-24**|**[PriorDiffusion: Leverage Language Prior in Diffusion Models for Monocular Depth Estimation](https://arxiv.org/abs/2411.16750)**|None|None|Ziyao Zeng et al.|
|**2024-11-21**|**[Baking Gaussian Splatting into Diffusion Denoiser for Fast and Scalable Single-stage Image-to-3D Generation and Reconstruction](https://arxiv.org/abs/2411.14384)**|ICCV 2025; A novel one-stage 3DGS-based diffusion for 3D object generation and scene reconstruction from a single view in ~6 seconds|None|Yuanhao Cai et al.|
|**2024-11-21**|**[StereoCrafter-Zero: Zero-Shot Stereo Video Generation with Noisy Restart](https://arxiv.org/abs/2411.14295)**|None|None|Jian Shi et al.|
|**2024-11-20**|**[DATAP-SfM: Dynamic-Aware Tracking Any Point for Robust Structure from Motion in the Wild](https://arxiv.org/abs/2411.13291)**|None|None|Weicai Ye et al.|
|**2024-11-20**|**[SURDS: Benchmarking Spatial Understanding and Reasoning in Driving Scenarios with Vision Language Models](https://arxiv.org/abs/2411.13112)**|None|None|Xianda Guo et al.|
|**2024-11-18**|**[Towards Degradation-Robust Reconstruction in Generalizable NeRF](https://arxiv.org/abs/2411.11691)**|None|None|Chan Ho Park et al.|
|**2024-11-18**|**[MGNiceNet: Unified Monocular Geometric Scene Understanding](https://arxiv.org/abs/2411.11466)**|None|Proceedings of the Asian Conference on Computer Vision (ACCV), 2024, pp. 1502-1519|Markus Schön et al.|
|**2024-11-18**|**[The ADUULM-360 Dataset -- A Multi-Modal Dataset for Depth Estimation in Adverse Weather](https://arxiv.org/abs/2411.11455)**|2024 IEEE International Conference on Intelligent Transportation Systems (ITSC)|None|Markus Schön et al.|
|**2024-11-18**|**[GPS-Gaussian+: Generalizable Pixel-wise 3D Gaussian Splatting for Real-Time Human-Scene Rendering from Sparse Views](https://arxiv.org/abs/2411.11363)**|Journal extension of CVPR 2024,Project page:https://yaourtb.github.io/GPS-Gaussian+|None|Boyao Zhou et al.|
|**2024-11-18**|**[Scalable Autoregressive Monocular Depth Estimation](https://arxiv.org/abs/2411.11361)**|Accepted by CVPR2025|None|Jinhong Wang et al.|
|**2024-11-16**|**[MetricGold: Leveraging Text-To-Image Latent Diffusion Models for Metric Depth Estimation](https://arxiv.org/abs/2411.10886)**|None|None|Ansh Shah, K Madhava Krishna|
|**2024-11-16**|**[EVT: Efficient View Transformation for Multi-Modal 3D Object Detection](https://arxiv.org/abs/2411.10715)**|Accepted to ICCV 2025|None|Yongjin Lee et al.|
|**2024-11-15**|**[SPARS3R: Semantic Prior Alignment and Regularization for Sparse 3D Reconstruction](https://arxiv.org/abs/2411.12592)**|None|None|Yutao Tang et al.|
|**2024-11-15**|**[Efficient Depth Estimation for Unstable Stereo Camera Systems on AR Glasses](https://arxiv.org/abs/2411.10013)**|12 pages, 11 figures. Accepted to CVPR 2024|None|Yongfan Liu, Hyoukjun Kwon|
|**2024-11-14**|**[Architect: Generating Vivid and Interactive 3D Scenes with Hierarchical 2D Inpainting](https://arxiv.org/abs/2411.09823)**|None|None|Yian Wang et al.|
|**2024-11-14**|**[Mono2Stereo: Monocular Knowledge Transfer for Enhanced Stereo Matching](https://arxiv.org/abs/2411.09151)**|8 pages, 6 figures|None|Yuran Wang et al.|
|**2024-11-13**|**[OSMLoc: Single Image-Based Visual Localization in OpenStreetMap with Fused Geometric and Semantic Guidance](https://arxiv.org/abs/2411.08665)**|16 pages, technical report|None|Youqi Liao et al.|
|**2024-11-12**|**[Scaling Properties of Diffusion Models for Perceptual Tasks](https://arxiv.org/abs/2411.08034)**|None|None|Rahul Ravishankar et al.|
|**2024-11-11**|**[$SE(3)$ Equivariant Ray Embeddings for Implicit Multi-View Depth Estimation](https://arxiv.org/abs/2411.07326)**|Accepted at NeurIPS 2024|None|Yinshuang Xu et al.|
|**2024-11-08**|**[SimpleBEV: Improved LiDAR-Camera Fusion Architecture for 3D Object Detection](https://arxiv.org/abs/2411.05292)**|None|None|Yun Zhao et al.|
|**2024-11-07**|**[D$^3$epth: Self-Supervised Depth Estimation with Dynamic Mask in Dynamic Scenes](https://arxiv.org/abs/2411.04826)**|Open sourced|None|Siyu Chen et al.|
|**2024-11-06**|**[Revisiting Disparity from Dual-Pixel Images: Physics-Informed Lightweight Depth Estimation](https://arxiv.org/abs/2411.04714)**|Accepted to IEEE Winter Conference on Applications of Computer Vision (WACV) 2025|None|Teppei Kurita et al.|
|**2024-11-06**|**[Adaptive Stereo Depth Estimation with Multi-Spectral Images Across All Lighting Conditions](https://arxiv.org/abs/2411.03638)**|None|None|Zihan Qin et al.|
|**2024-11-04**|**[FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training](https://arxiv.org/abs/2411.02229)**|Accepted by NeurIPS2024|None|Ruihong Yin et al.|
|**2024-11-04**|**[Improving Domain Generalization in Self-supervised Monocular Depth Estimation via Stabilized Adversarial Training](https://arxiv.org/abs/2411.02149)**|Accepted to ECCV 2024|None|Yuanqi Yao et al.|
|**2024-11-04**|**[PMPNet: Pixel Movement Prediction Network for Monocular Depth Estimation in Dynamic Scenes](https://arxiv.org/abs/2411.04227)**|None|None|Kebin Peng et al.|
|**2024-11-01**|**[MultiDepth: Multi-Sample Priors for Refining Monocular Metric Depth Estimations in Indoor Scenes](https://arxiv.org/abs/2411.01048)**|None|None|Sanghyun Byun et al.|
|**2024-11-01**|**[On Deep Learning for Geometric and Semantic Scene Understanding Using On-Vehicle 3D LiDAR](https://arxiv.org/abs/2411.00600)**|PhD thesis (Durham University, Computer Science), 149 pages (the 2024 BMVA Sullivan Doctoral Thesis Prize runner-up). Includes published content from arXiv:2407.10159 (ECCV 2024 ORAL), arXiv:2303.11203 (CVPR 2023), and arXiv:2406.10068 (3DV 2021), with minor revisions to the examined version: https://etheses.dur.ac.uk/15738/|None|Li Li|
|**2024-10-31**|**[Optical Lens Attack on Monocular Depth Estimation for Autonomous Driving](https://arxiv.org/abs/2411.00192)**|28 pages. arXiv admin note: substantial text overlap with arXiv:2409.17376|None|Ce Zhou et al.|
|**2024-10-31**|**[ImOV3D: Learning Open-Vocabulary Point Clouds 3D Object Detection from Only 2D Images](https://arxiv.org/abs/2410.24001)**|Accepted by NeurIPS 2024. Code link https://github.com/yangtiming/ImOV3D|NeurIPS 2024|Timing Yang et al.|
|**2024-10-29**|**[Active Event Alignment for Monocular Distance Estimation](https://arxiv.org/abs/2410.22280)**|None|IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2025|Nan Cai, Pia Bideau|
|**2024-10-29**|**[PF3plat: Pose-Free Feed-Forward 3D Gaussian Splatting](https://arxiv.org/abs/2410.22128)**|Accepted by ICML'25|None|Sunghwan Hong et al.|
|**2024-10-27**|**[Unlocking Comics: The AI4VA Dataset for Visual Understanding](https://arxiv.org/abs/2410.20459)**|ECCV 2024 Workshop Proceedings|None|Peter Grönquist et al.|
|**2024-10-27**|**[Depth Attention for Robust RGB Tracking](https://arxiv.org/abs/2410.20395)**|Oral Acceptance at the Asian Conference on Computer Vision (ACCV) 2024, Hanoi, Vietnam|None|Yu Liu et al.|
|**2024-10-25**|**[MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors](https://arxiv.org/abs/2410.19590)**|None|None|Fanqi Pu et al.|
|**2024-10-24**|**[Segmentation-aware Prior Assisted Joint Global Information Aggregated 3D Building Reconstruction](https://arxiv.org/abs/2410.18433)**|None|None|Hongxin Peng et al.|
|**2024-10-23**|**[UnCLe: Benchmarking Unsupervised Continual Learning for Depth Completion](https://arxiv.org/abs/2410.18074)**|Preprint|None|Xien Chen et al.|
|**2024-10-21**|**[TIPS: Text-Image Pretraining with Spatial awareness](https://arxiv.org/abs/2410.16512)**|ICLR2025 camera-ready + appendix|None|Kevis-Kokitsi Maninis et al.|
|**2024-10-21**|**[YOLO11 and Vision Transformers based 3D Pose Estimation of Immature Green Fruits in Commercial Apple Orchards for Robotic Thinning](https://arxiv.org/abs/2410.19846)**|24 Pages, 13 Figures, 1 Table|None|Ranjan Sapkota, Manoj Karkee|
|**2024-10-19**|**[DCDepth: Progressive Monocular Depth Estimation in Discrete Cosine Domain](https://arxiv.org/abs/2410.14980)**|Accepted by NeurIPS-2024|None|Kun Wang et al.|
|**2024-10-17**|**[DepthSplat: Connecting Gaussian Splatting and Depth](https://arxiv.org/abs/2410.13862)**|CVPR 2025, Project page: https://haofeixu.github.io/depthsplat/, Code: https://github.com/cvg/depthsplat|None|Haofei Xu et al.|
|**2024-10-16**|**[DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning](https://arxiv.org/abs/2410.12501)**|5 pages, 6 figures, ICASSP2025|None|Jiabao Wei, Zhiyuan Ma|
|**2024-10-15**|**[Enhanced Encoder-Decoder Architecture for Accurate Monocular Depth Estimation](https://arxiv.org/abs/2410.11610)**|None|None|Dabbrata Das et al.|
|**2024-10-15**|**[CVCP-Fusion: On Implicit Depth Estimation for 3D Bounding Box Prediction](https://arxiv.org/abs/2410.11211)**|7 pages, 5 figures. arXiv admin note: text overlap with arXiv:2205.02833 by other authors|Curieux Academic Journal Part 2 Issue 43 (2024), pp. 626-634|Pranav Gupta et al.|
|**2024-10-14**|**[When Does Perceptual Alignment Benefit Vision Representations?](https://arxiv.org/abs/2410.10817)**|S.S. and S.F. contributed equally. Website: percep-align.github.io|None|Shobhita Sundaram et al.|
|**2024-10-14**|**[Depth Any Video with Scalable Synthetic Data](https://arxiv.org/abs/2410.10815)**|Project Page: https://depthanyvideo.github.io/|None|Honghui Yang et al.|
|**2024-10-09**|**[Surgical Depth Anything: Depth Estimation for Surgical Scenes using Foundation Models](https://arxiv.org/abs/2410.07434)**|None|None|Ange Lou et al.|
|**2024-10-09**|**[Structure-Centric Robust Monocular Depth Estimation via Knowledge Distillation](https://arxiv.org/abs/2410.06982)**|To be published in Asian Conference on Computer Vision 2024|None|Runze Chen et al.|
|**2024-10-09**|**[Analysis of different disparity estimation techniques on aerial stereo image datasets](https://arxiv.org/abs/2410.06711)**|None|None|Ishan Narayan, Shashi Poddar|
|**2024-10-08**|**[Vision Transformer based Random Walk for Group Re-Identification](https://arxiv.org/abs/2410.05808)**|6 pages|None|Guoqing Zhang et al.|
|**2024-10-08**|**[CUBE360: Learning Cubic Field Representation for Monocular 360 Depth Estimation for Virtual Reality](https://arxiv.org/abs/2410.05735)**|None|None|Wenjie Chang et al.|
|**2024-10-04**|**[Refinement of Monocular Depth Maps via Multi-View Differentiable Rendering](https://arxiv.org/abs/2410.03861)**|9.5 pages main paper + 3 pages of references + 1.5 pages appendix|None|Laura Fink et al.|
|**2024-10-03**|**[RSA: Resolving Scale Ambiguities in Monocular Depth Estimators through Language Descriptions](https://arxiv.org/abs/2410.02924)**|None|None|Ziyao Zeng et al.|
|**2024-10-02**|**[Depth Pro: Sharp Monocular Metric Depth in Less Than a Second](https://arxiv.org/abs/2410.02073)**|Published at ICLR 2025. Code and weights available at https://github.com/apple/ml-depth-pro|None|Aleksei Bochkovskii et al.|
|**2024-10-01**|**[Towards Full-parameter and Parameter-efficient Self-learning For Endoscopic Camera Depth Estimation](https://arxiv.org/abs/2410.00979)**|WiCV @ ECCV 2024|None|Shuting Zhao et al.|
|**2024-10-01**|**[Drone Stereo Vision for Radiata Pine Branch Detection and Distance Measurement: Utilizing Deep Learning and YOLO Integration](https://arxiv.org/abs/2410.00503)**|None|None|Yida Lin et al.|
|**2024-10-01**|**[Seamless Augmented Reality Integration in Arthroscopy: A Pipeline for Articular Reconstruction and Guidance](https://arxiv.org/abs/2410.00386)**|8 pages, with 2 additional pages as the supplementary. Accepted by AE-CAI 2024|None|Hongchao Shu et al.|
|**2024-09-30**|**[CCDepth: A Lightweight Self-supervised Depth Estimation Network with Enhanced Interpretability](https://arxiv.org/abs/2409.19933)**|None|None|Xi Zhang et al.|
|**2024-09-30**|**[EndoDepth: A Benchmark for Assessing Robustness in Endoscopic Depth Prediction](https://arxiv.org/abs/2409.19930)**|None|None|Ivan Reyes-Amezcua et al.|
|**2024-09-29**|**[fCOP: Focal Length Estimation from Category-level Object Priors](https://arxiv.org/abs/2409.19641)**|None|None|Xinyue Zhang et al.|
|**2024-09-26**|**[Self-supervised Monocular Depth Estimation with Large Kernel Attention](https://arxiv.org/abs/2409.17895)**|The paper is under consideration at 2025 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)|None|Xuezhi Xiang et al.|
|**2024-09-26**|**[Self-Distilled Depth Refinement with Noisy Poisson Fusion](https://arxiv.org/abs/2409.17880)**|Accepted by NeurIPS 2024|None|Jiaqi Li et al.|
|**2024-09-26**|**[ViewpointDepth: A New Dataset for Monocular Depth Estimation Under Viewpoint Shifts](https://arxiv.org/abs/2409.17851)**|None|None|Aurel Pjetri et al.|
|**2024-09-26**|**[Event-based Stereo Depth Estimation: A Survey](https://arxiv.org/abs/2409.17680)**|28 pages, 24 figures, 7 tables. Project page: https://github.com/tub-rip/EventStereoSurvey|IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2025|Suman Ghosh, Guillermo Gallego|
|**2024-09-26**|**[CAMOT: Camera Angle-aware Multi-Object Tracking](https://arxiv.org/abs/2409.17533)**|https://gitlab.com/felixlimanta/camot|WACV 2024|Felix Limanta et al.|
|**2024-09-25**|**[Parameter-efficient Bayesian Neural Networks for Uncertainty-aware Depth Estimation](https://arxiv.org/abs/2409.17085)**|Presented at UnCV Workshop at ECCV'24|None|Richard D. Paul et al.|
|**2024-09-25**|**[EventHDR: from Event to High-Speed HDR Videos and Beyond](https://arxiv.org/abs/2409.17029)**|TPAMI 2024|None|Yunhao Zou et al.|
|**2024-09-24**|**[MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling](https://arxiv.org/abs/2409.16160)**|Project Page: https://menyifang.github.io/projects/MIMO/index.html|None|Yifang Men et al.|
|**2024-09-24**|**[Benchmarking Robustness of Endoscopic Depth Estimation with Synthetically Corrupted Data](https://arxiv.org/abs/2409.16063)**|To appear at the Simulation and Synthesis in Medical Imaging (SASHIMI) workshop at MICCAI 2024|None|An Wang et al.|
|**2024-09-23**|**[FisheyeDepth: A Real Scale Self-Supervised Depth Estimation Model for Fisheye Camera](https://arxiv.org/abs/2409.15054)**|None|ICRA 2025 IEEE International Conference on Robotics and Automation|Guoyang Zhao et al.|
|**2024-09-23**|**[DepthART: Monocular Depth Estimation as Autoregressive Refinement Task](https://arxiv.org/abs/2409.15010)**|None|None|Bulat Gabdullin et al.|
|**2024-09-23**|**[Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network](https://arxiv.org/abs/2409.15006)**|None|None|Sijia Du et al.|
|**2024-09-23**|**[GroCo: Ground Constraint for Metric Self-Supervised Monocular Depth](https://arxiv.org/abs/2409.14850)**|None|None|Aurélien Cecille et al.|
|**2024-09-23**|**[Robust and Flexible Omnidirectional Depth Estimation with Multiple 360-degree Cameras](https://arxiv.org/abs/2409.14766)**|None|None|Ming Li et al.|
|**2024-09-21**|**[@Bench: Benchmarking Vision-Language Models for Human-centered Assistive Technology](https://arxiv.org/abs/2409.14215)**|Accepted by WACV 2025, project page: https://junweizheng93.github.io/publications/ATBench/ATBench.html|None|Xin Jiang et al.|
|**2024-09-20**|**[DAP-LED: Learning Degradation-Aware Priors with CLIP for Joint Low-light Enhancement and Deblurring](https://arxiv.org/abs/2409.13496)**|None|None|Ling Wang et al.|
|**2024-09-20**|**[CVT-Occ: Cost Volume Temporal Fusion for 3D Occupancy Prediction](https://arxiv.org/abs/2409.13430)**|Accepted to ECCV 2024|None|Zhangchen Ye et al.|
|**2024-09-18**|**[Panoptic-Depth Forecasting](https://arxiv.org/abs/2409.12008)**|None|None|Juana Valeria Hurtado et al.|
|**2024-09-17**|**[Fine-Tuning Image-Conditional Diffusion Models is Easier than You Think](https://arxiv.org/abs/2409.11355)**|WACV 2025 Oral. Project page at https://vision.rwth-aachen.de/diffusion-e2e-ft|None|Gonzalo Martin Garcia et al.|
|**2024-09-15**|**[GRIN: Zero-Shot Metric Depth with Pixel-Level Diffusion](https://arxiv.org/abs/2409.09896)**|None|None|Vitor Guizilini et al.|
|**2024-09-15**|**[Towards Single-Lens Controllable Depth-of-Field Imaging via Depth-Aware Point Spread Functions](https://arxiv.org/abs/2409.09754)**|Accepted to IEEE Transactions on Computational Imaging (TCI). The source code and the established dataset will be publicly available at https://github.com/XiaolongQian/DCDI|None|Xiaolong Qian et al.|
|**2024-09-13**|**[PrimeDepth: Efficient Monocular Depth Estimation with a Stable Diffusion Preimage](https://arxiv.org/abs/2409.09144)**|None|None|Denis Zavadski et al.|
|**2024-09-13**|**[Precision Aquaculture: An Integrated Computer Vision and IoT Approach for Optimized Tilapia Feeding](https://arxiv.org/abs/2409.08695)**|8 pages, 6 figures, 3 tables, 21th International Conference on Informatics in Control, Automation, and Robotics|None|Rania Hossam et al.|
|**2024-09-12**|**[Depth on Demand: Streaming Dense Depth from a Low Frame Rate Active Sensor](https://arxiv.org/abs/2409.08277)**|Accepted for publication at the European Conference on Computer Vision (ECCV) 2024|None|Andrea Conti et al.|
|**2024-09-12**|**[LED: Light Enhanced Depth Estimation at Night](https://arxiv.org/abs/2409.08031)**|Preprint. Code and dataset available on the project page : https://simondemoreau.github.io/LED/|None|Simon de Moreau et al.|
|**2024-09-12**|**[Real-time Multi-view Omnidirectional Depth Estimation System for Robots and Autonomous Driving on Real Scenes](https://arxiv.org/abs/2409.07843)**|None|None|Ming Li et al.|
|**2024-09-12**|**[Advancing Depth Anything Model for Unsupervised Monocular Depth Estimation in Endoscopy](https://arxiv.org/abs/2409.07723)**|Accepted by IROS2025, 8 pages, 7 figures|None|Bojian Li et al.|
|**2024-09-12**|**[FIReStereo: Forest InfraRed Stereo Dataset for UAS Depth Perception in Visually Degraded Environments](https://arxiv.org/abs/2409.07715)**|Under review in RA-L. The first 2 authors contributed equally|None|Devansh Dhrafani et al.|
|**2024-09-10**|**[EDADepth: Enhanced Data Augmentation for Monocular Depth Estimation](https://arxiv.org/abs/2409.06183)**|None|None|Nischal Khanal, Shivanand Venkanna Sheshappanavar|
|**2024-09-09**|**[EndoOmni: Zero-Shot Cross-Dataset Depth Estimation in Endoscopy by Robust Self-Learning from Noisy Labels](https://arxiv.org/abs/2409.05442)**|None|None|Qingyao Tian et al.|
|**2024-09-08**|**[TanDepth: Leveraging Global DEMs for Metric Monocular Depth Estimation in UAVs](https://arxiv.org/abs/2409.05142)**|None|IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, vol. 18, 2025, pp. 5445-5459|Horatiu Florea, Sergiu Nedevschi|
|**2024-09-06**|**[Introducing a Class-Aware Metric for Monocular Depth Estimation: An Automotive Perspective](https://arxiv.org/abs/2409.04086)**|Accepted at the European Conference on Computer Vision (ECCV) 2024 Workshop on Out Of Distribution Generalization in Computer Vision|None|Tim Bader et al.|
|**2024-09-04**|**[iConFormer: Dynamic Parameter-Efficient Tuning with Input-Conditioned Adaptation](https://arxiv.org/abs/2409.02838)**|None|None|Hayeon Jo et al.|
|**2024-09-04**|**[Skip-and-Play: Depth-Driven Pose-Preserved Image Generation for Any Objects](https://arxiv.org/abs/2409.02653)**|None|None|Kyungmin Jo, Jaegul Choo|
|**2024-09-04**|**[UniTT-Stereo: Unified Training of Transformer for Enhanced Stereo Matching](https://arxiv.org/abs/2409.02545)**|None|None|Soomin Kim et al.|
|**2024-09-04**|**[SG-MIM: Structured Knowledge Guided Efficient Pre-training for Dense Prediction](https://arxiv.org/abs/2409.02513)**|None|None|Sumin Son et al.|
|**2024-09-04**|**[Plane2Depth: Hierarchical Adaptive Plane Guidance for Monocular Depth Estimation](https://arxiv.org/abs/2409.02494)**|14 pages, 12 figures, 8 tables|None|Li Liu et al.|
|**2024-09-04**|**[Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image Indoor Depth by Meta-Initialization](https://arxiv.org/abs/2409.02486)**|IROS 2024. The version supersedes 2305.07269. arXiv admin note: text overlap with arXiv:2305.07269|None|Cho-Ying Wu et al.|
|**2024-09-04**|**[GGS: Generalizable Gaussian Splatting for Lane Switching in Autonomous Driving](https://arxiv.org/abs/2409.02382)**|None|None|Huasong Han et al.|
|**2024-09-03**|**[DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos](https://arxiv.org/abs/2409.02095)**|Project webpage: https://depthcrafter.github.io|None|Wenbo Hu et al.|
|**2024-09-02**|**[GET-UP: GEomeTric-aware Depth Estimation with Radar Points UPsampling](https://arxiv.org/abs/2409.02720)**|Accepted by WACV 2025|None|Huawei Sun et al.|
|**2024-09-02**|**[Large Language Models Can Understanding Depth from Monocular Images](https://arxiv.org/abs/2409.01133)**|None|None|Zhongyi Xia, Tianzhao Wu|
|**2024-08-30**|**[DARES: Depth Anything in Robotic Endoscopic Surgery with Self-supervised Vector-LoRA of the Foundation Model](https://arxiv.org/abs/2408.17433)**|11 pages|None|Mona Sheikh Zeinoddin et al.|
|**2024-08-30**|**[Enhancing Underwater Imaging with 4-D Light Fields: Dataset and Method](https://arxiv.org/abs/2408.17339)**|20 pages, 22 figures|None|Yuji Lin et al.|
|**2024-08-30**|**[Synthetic Lunar Terrain: A Multimodal Open Dataset for Training and Evaluating Neuromorphic Vision Algorithms](https://arxiv.org/abs/2408.16971)**|7 pages, 5 figures, to be published at "International Symposium on Artificial Intelligence, Robotics and Automation in Space, i-SAIRAS, 2024|None|Marcus Märtens et al.|
|**2024-08-29**|**[EvLight++: Low-Light Video Enhancement with an Event Camera: A Large-Scale Real-World Dataset, Novel Method, and More](https://arxiv.org/abs/2408.16254)**|Journal extension based on EvLight (arXiv:2404.00834)|None|Kanghao Chen et al.|
|**2024-08-29**|**[Revisiting 360 Depth Estimation with PanoGabor: A New Fusion Perspective](https://arxiv.org/abs/2408.16227)**|None|None|Zhijie Shen et al.|
|**2024-08-27**|**[Adversarial Manhole: Challenging Monocular Depth Estimation and Semantic Segmentation Models with Patch Attack](https://arxiv.org/abs/2408.14879)**|Accepted for WISA 2024. Code and dataset: https://github.com/naufalso/adversarial-manhole|None|Naufal Suryanto et al.|
|**2024-08-26**|**[NimbleD: Enhancing Self-supervised Monocular Depth Estimation with Pseudo-labels and Large-scale Video Pre-training](https://arxiv.org/abs/2408.14177)**|None|None|Albert Luginov, Muhammad Shahzad|
|**2024-08-26**|**[Pixel-Aligned Multi-View Generation with Depth Guided Decoder](https://arxiv.org/abs/2408.14016)**|None|None|Zhenggang Tang et al.|
|**2024-08-25**|**[TranSplat: Generalizable 3D Gaussian Splatting from Sparse Multi-View Images with Transformers](https://arxiv.org/abs/2408.13770)**|None|None|Chuanrui Zhang et al.|
|**2024-08-25**|**[InSpaceType: Dataset and Benchmark for Reconsidering Cross-Space Type Performance in Indoor Monocular Depth](https://arxiv.org/abs/2408.13708)**|BMVC 2024. This version supersedes 2309.13516|None|Cho-Ying Wu et al.|
|**2024-08-22**|**[Sapiens: Foundation for Human Vision Models](https://arxiv.org/abs/2408.12569)**|ECCV 2024 (Oral)|None|Rawal Khirodkar et al.|
|**2024-08-19**|**[Structure-preserving Image Translation for Depth Estimation in Colonoscopy Video](https://arxiv.org/abs/2408.10153)**|12 pages, 7 figures, accepted at MICCAI 2024|None|Shuxian Wang et al.|
|**2024-08-19**|**[SHARP: Segmentation of Hands and Arms by Range using Pseudo-Depth for Enhanced Egocentric 3D Hand Pose Estimation and Action Recognition](https://arxiv.org/abs/2408.10037)**|Accepted at 27th International Conference on Pattern Recognition (ICPR)|None|Wiktor Mucha et al.|
|**2024-08-19**|**[P3P: Pseudo-3D Pre-training for Scaling 3D Voxel-based Masked Autoencoders](https://arxiv.org/abs/2408.10007)**|Under review. Pre-print|None|Xuechao Chen et al.|
|**2024-08-14**|**[Enhanced Scale-aware Depth Estimation for Monocular Endoscopic Scenes with Geometric Modeling](https://arxiv.org/abs/2408.07266)**|None|None|Ruofeng Wei et al.|
|**2024-08-12**|**[Towards Robust Monocular Depth Estimation in Non-Lambertian Surfaces](https://arxiv.org/abs/2408.06083)**|None|None|Junrui Zhang et al.|
|**2024-08-08**|**[Depth Any Canopy: Leveraging Depth Foundation Models for Canopy Height Estimation](https://arxiv.org/abs/2408.04523)**|Accepted at ECCV 2024 CV4E Workshop|None|Daniele Rege Cambrin et al.|
|**2024-08-07**|**[Focal Depth Estimation: A Calibration-Free, Subject- and Daytime Invariant Approach](https://arxiv.org/abs/2408.03591)**|None|None|Benedikt W. Hosp et al.|
|**2024-08-06**|**[BodySLAM: A Generalized Monocular Visual SLAM Framework for Surgical Applications](https://arxiv.org/abs/2408.03078)**|16 pages, 7 figures|None|G. Manni et al.|
|**2024-08-05**|**[Gaussian Mixture based Evidential Learning for Stereo Matching](https://arxiv.org/abs/2408.02796)**|None|None|Weide Liu et al.|
|**2024-08-05**|**[Lumina-mGPT: Illuminate Flexible Photorealistic Text-to-Image Generation with Multimodal Generative Pretraining](https://arxiv.org/abs/2408.02657)**|Code available at: https://github.com/Alpha-VLLM/Lumina-mGPT|None|Dongyang Liu et al.|
|**2024-08-03**|**[MCPDepth: Omnidirectional Depth Estimation via Stereo Matching from Multi-Cylindrical Panoramas](https://arxiv.org/abs/2408.01653)**|None|None|Feng Qiao et al.|
|**2024-08-02**|**[Embodiment: Self-Supervised Depth Estimation Based on Camera Models](https://arxiv.org/abs/2408.01565)**|None|None|Jinchang Zhang et al.|
|**2024-08-01**|**[MonoMM: A Multi-scale Mamba-Enhanced Network for Real-time Monocular 3D Object Detection](https://arxiv.org/abs/2408.00438)**|None|None|Youjia Fu et al.|
|**2024-08-01**|**[High-Precision Self-Supervised Monocular Depth Estimation with Rich-Resource Prior](https://arxiv.org/abs/2408.00361)**|ECCV2024|None|Wencheng Han, Jianbing Shen|
|**2024-07-31**|**[EMatch: A Unified Framework for Event-based Optical Flow and Stereo Matching](https://arxiv.org/abs/2407.21735)**|None|None|Pengjie Zhang et al.|
|**2024-07-29**|**[BaseBoostDepth: Exploiting Larger Baselines For Self-supervised Monocular Depth Estimation](https://arxiv.org/abs/2407.20437)**|None|None|Kieran Saunders et al.|
|**2024-07-29**|**[Improving 2D Feature Representations by 3D-Aware Fine-Tuning](https://arxiv.org/abs/2407.20229)**|ECCV 2024. Project page: https://ywyue.github.io/FiT3D|None|Yuanwen Yue et al.|
|**2024-07-27**|**[Revisit Self-supervised Depth Estimation with Local Structure-from-Motion](https://arxiv.org/abs/2407.19166)**|None|None|Shengjie Zhu, Xiaoming Liu|
|**2024-07-27**|**[RePLAy: Remove Projective LiDAR Depthmap Artifacts via Exploiting Epipolar Geometry](https://arxiv.org/abs/2407.19154)**|None|None|Shengjie Zhu et al.|
|**2024-07-26**|**[HybridDepth: Robust Metric Depth Fusion by Leveraging Depth from Focus and Single-Image Priors](https://arxiv.org/abs/2407.18443)**|WACV 2025|None|Ashkan Ganj et al.|
|**2024-07-25**|**[BetterDepth: Plug-and-Play Diffusion Refiner for Zero-Shot Monocular Depth Estimation](https://arxiv.org/abs/2407.17952)**|NeurIPS 2024|None|Xiang Zhang et al.|
|**2024-07-25**|**[UMono: Physical Model Informed Hybrid CNN-Transformer Framework for Underwater Monocular Depth Estimation](https://arxiv.org/abs/2407.17838)**|None|None|Jian Wang et al.|
|**2024-07-24**|**[DarSwin-Unet: Distortion Aware Encoder-Decoder Architecture](https://arxiv.org/abs/2407.17328)**|None|None|Akshaya Athwale et al.|
|**2024-07-24**|**[Physical Adversarial Attack on Monocular Depth Estimation via Shape-Varying Patches](https://arxiv.org/abs/2407.17312)**|None|None|Chenxing Zhao et al.|
|**2024-07-23**|**[SINDER: Repairing the Singular Defects of DINOv2](https://arxiv.org/abs/2407.16826)**|ECCV 2024|None|Haoqi Wang et al.|
|**2024-07-23**|**[Diffusion Models for Monocular Depth Estimation: Overcoming Challenging Conditions](https://arxiv.org/abs/2407.16698)**|ECCV 2024. Code: https://github.com/fabiotosi92/Diffusion4RobustDepth Project page: https://diffusion4robustdepth.github.io/|None|Fabio Tosi et al.|
|**2024-07-23**|**[ToDER: Towards Colonoscopy Depth Estimation and Reconstruction with Geometry Constraint Adaptation](https://arxiv.org/abs/2407.16508)**|None|None|Zhenhua Wu et al.|
|**2024-07-19**|**[Mono-ViFI: A Unified Learning Framework for Self-supervised Single- and Multi-frame Monocular Depth Estimation](https://arxiv.org/abs/2407.14126)**|27 pages, accepted by ECCV 2024|None|Jinfeng Liu et al.|
|**2024-07-18**|**[Many Perception Tasks are Highly Redundant Functions of their Input Data](https://arxiv.org/abs/2407.13841)**|None|None|Rahul Ramesh et al.|
|**2024-07-17**|**[Benchmarking Robust Self-Supervised Learning Across Diverse Downstream Tasks](https://arxiv.org/abs/2407.12588)**|Accepted at the ICML 2024 Workshop on Foundation Models in the Wild|None|Antoni Kowalczuk et al.|
|**2024-07-16**|**[Temporally Consistent Stereo Matching](https://arxiv.org/abs/2407.11950)**|ECCV 2024|None|Jiaxi Zeng et al.|
|**2024-07-15**|**[IDOL: Unified Dual-Modal Latent Diffusion for Human-Centric Joint Video-Depth Generation](https://arxiv.org/abs/2407.10937)**|ECCV 2024; project page: https://yhzhai.github.io/idol/|None|Yuanhao Zhai et al.|
|**2024-07-15**|**[OPEN: Object-wise Position Embedding for Multi-view 3D Object Detection](https://arxiv.org/abs/2407.10753)**|Accepted by ECCV 2024|None|Jinghua Hou et al.|
|**2024-07-15**|**[Towards Scale-Aware Full Surround Monodepth with Transformers](https://arxiv.org/abs/2407.10406)**|None|None|Yuchen Yang et al.|
|**2024-07-12**|**[ProDepth: Boosting Self-Supervised Multi-Frame Monocular Depth with Probabilistic Fusion](https://arxiv.org/abs/2407.09303)**|Accepted by ECCV 2024. Project Page: https://sungmin-woo.github.io/prodepth/|None|Sungmin Woo et al.|
|**2024-07-11**|**[ScaleDepth: Decomposing Metric Depth Estimation into Scale Prediction and Relative Depth Estimation](https://arxiv.org/abs/2407.08187)**|14 pages, 11 figure, 13 tables|None|Ruijie Zhu et al.|
|**2024-07-10**|**[Controlling Space and Time with Diffusion Models](https://arxiv.org/abs/2407.07860)**|ICLR 2025, First three authors contributed equally|None|Daniel Watson et al.|
|**2024-07-07**|**[SCIPaD: Incorporating Spatial Clues into Unsupervised Pose-Depth Joint Learning](https://arxiv.org/abs/2407.05283)**|Accepted by IEEE Transactions on Intelligent Vehicles. Code is available at https://mias.group/SCIPaD|None|Yi Feng et al.|
|**2024-07-05**|**[A Physical Model-Guided Framework for Underwater Image Enhancement and Depth Estimation](https://arxiv.org/abs/2407.04230)**|This work has been submitted to the IEEE for possible publication|None|Dazhao Du et al.|
|**2024-07-04**|**[Towards Cross-View-Consistent Self-Supervised Surround Depth Estimation](https://arxiv.org/abs/2407.04041)**|Accepted by IROS2024|None|Laiyan Ding et al.|
|**2024-07-02**|**[Camera-LiDAR Cross-modality Gait Recognition](https://arxiv.org/abs/2407.02038)**|Accepted at ECCV 2024|None|Wenxuan Guo et al.|
|**2024-06-30**|**[CaFNet: A Confidence-Driven Framework for Radar Camera Depth Estimation](https://arxiv.org/abs/2407.00697)**|Accepted by IROS 2024|None|Huawei Sun et al.|
|**2024-06-28**|**[Deep Learning-based Depth Estimation Methods from Monocular Image and Videos: A Comprehensive Survey](https://arxiv.org/abs/2406.19675)**|46 pages, 10 figures, The paper has been accepted for publication in ACM Computing Surveys 2024|None|Uchitha Rajapaksha et al.|
|**2024-06-27**|**[360 in the Wild: Dataset for Depth Prediction and View Synthesis](https://arxiv.org/abs/2406.18898)**|None|None|Kibaek Park et al.|
|**2024-06-27**|**[Dense Monocular Motion Segmentation Using Optical Flow and Pseudo Depth Map: A Zero-Shot Approach](https://arxiv.org/abs/2406.18837)**|For the offical publication, see https://crv.pubpub.org/pub/iunjzl55|Proceedings of the 21st Conference on Robots and Vision (2024)|Yuxiang Huang et al.|
|**2024-06-25**|**[Depth-Guided Semi-Supervised Instance Segmentation](https://arxiv.org/abs/2406.17413)**|12 pages, 6 figures, 4 tables|None|Xin Chen et al.|
|**2024-06-20**|**[Uncertainty and Self-Supervision in Single-View Depth](https://arxiv.org/abs/2406.14226)**|Doctoral thesis|None|Javier Rodriguez-Puigvert|
|**2024-06-19**|**[WaterMono: Teacher-Guided Anomaly Masking and Enhancement Boosting for Robust Underwater Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2406.13344)**|None|None|Yilin Ding et al.|
|**2024-06-18**|**[Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation](https://arxiv.org/abs/2406.12849)**|NeurIPS 2024. Project page: https://albert100121.github.io/Depth-Anywhere/|None|Ning-Hsu Wang, Yu-Lun Liu|
|**2024-06-18**|**[GeoBench: Benchmarking and Analyzing Monocular Geometry Estimation Models](https://arxiv.org/abs/2406.12671)**|Code and Benchmark are available at: https://github.com/aim-uofa/GeoBench|None|Yongtao Ge et al.|
|**2024-06-17**|**[DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features](https://arxiv.org/abs/2406.12095)**|Accepted by Advances in Neural Information Processing Systems (NeurIPS 2024)|None|Letian Wang et al.|
|**2024-06-17**|**[MEDeA: Multi-view Efficient Depth Adjustment](https://arxiv.org/abs/2406.12048)**|None|None|Mikhail Artemyev et al.|
|**2024-06-16**|**[3D Gaze Tracking for Studying Collaborative Interactions in Mixed-Reality Environments](https://arxiv.org/abs/2406.11003)**|9 pages, 8 figures, conference, submitted to ICMI 2024|None|Eduardo Davalos et al.|
|**2024-06-15**|**[GenMM: Geometrically and Temporally Consistent Multimodal Data Generation for Video and LiDAR](https://arxiv.org/abs/2406.10722)**|None|None|Bharat Singh et al.|
|**2024-06-14**|**[The BabyView dataset: High-resolution egocentric videos of infants' and young children's everyday experiences](https://arxiv.org/abs/2406.10447)**|9 pages, 3 figures, 4 tables and Appendix. Published in the Proceedings of the 8th Annual Conference on Cognitive Computational Neuroscience|None|Bria Long et al.|
|**2024-06-14**|**[D-NPC: Dynamic Neural Point Clouds for Non-Rigid View Synthesis from Monocular Video](https://arxiv.org/abs/2406.10078)**|18 pages, 8 figures, 12 tables. Project page: https://moritzkappel.github.io/projects/dnpc/|None|Moritz Kappel et al.|
|**2024-06-14**|**[DurLAR: A High-fidelity 128-channel LiDAR Dataset with Panoramic Ambient and Reflectivity Imagery for Multi-modal Autonomous Driving Applications](https://arxiv.org/abs/2406.10068)**|Accepted by 3DV 2021; 13 pages, 14 figures; Dataset at https://github.com/l1997i/durlar|Proc. Int. Conf. on 3D Vision (3DV 2021)|Li Li et al.|
|**2024-06-14**|**[Self-supervised Monocular Depth Estimation Based on Hierarchical Feature-Guided Diffusion](https://arxiv.org/abs/2406.09782)**|None|None|Runze Liu et al.|
|**2024-06-13**|**[Depth Anything V2](https://arxiv.org/abs/2406.09414)**|Accepted by NeurIPS 2024. Project page: https://depth-anything-v2.github.io|None|Lihe Yang et al.|
|**2024-06-13**|**[WonderWorld: Interactive 3D Scene Generation from a Single Image](https://arxiv.org/abs/2406.09394)**|CVPR 2025. Project website: https://kovenyu.com/WonderWorld/. The first two authors contributed equally|None|Hong-Xing Yu et al.|
|**2024-06-13**|**[Scale-Invariant Monocular Depth Estimation via SSI Depth](https://arxiv.org/abs/2406.09374)**|To appear in Proc. SIGGRAPH, 2024. Project webpage: https://yaksoy.github.io/sidepth/|None|S. Mahdi H. Miangoleh et al.|
|**2024-06-13**|**[Multiple Prior Representation Learning for Self-Supervised Monocular Depth Estimation via Hybrid Transformer](https://arxiv.org/abs/2406.08928)**|28 pages, 12 figures|None|Guodong Sun et al.|
|**2024-06-13**|**[ToSA: Token Selective Attention for Efficient Vision Transformers](https://arxiv.org/abs/2406.08816)**|Accepted at CVPRW 2024|None|Manish Kumar Singh et al.|
|**2024-06-11**|**[Back to the Color: Learning Depth to Specific Color Transformation for Unsupervised Depth Estimation](https://arxiv.org/abs/2406.07741)**|None|None|Yufan Zhu et al.|
|**2024-06-11**|**[PLT-D3: A High-fidelity Dynamic Driving Simulation Dataset for Stereo Depth and Scene Flow](https://arxiv.org/abs/2406.07667)**|None|None|Joshua Tokarsky et al.|
|**2024-06-11**|**[RS-DFM: A Remote Sensing Distributed Foundation Model for Diverse Downstream Tasks](https://arxiv.org/abs/2406.07032)**|None|None|Zhechao Wang et al.|
|**2024-06-10**|**[PatchRefiner: Leveraging Synthetic Data for Real-Domain High-Resolution Monocular Metric Depth Estimation](https://arxiv.org/abs/2406.06679)**|None|None|Zhenyu Li et al.|
|**2024-06-09**|**[Self-supervised Adversarial Training of Monocular Depth Estimation against Physical-World Attacks](https://arxiv.org/abs/2406.05857)**|Accepted in TPAMI'24. Extended from our ICLR'23 publication (arXiv:2301.13487). arXiv admin note: substantial text overlap with arXiv:2301.13487|None|Zhiyuan Cheng et al.|
|**2024-06-09**|**[RefGaussian: Disentangling Reflections from 3D Gaussian Splatting for Realistic Rendering](https://arxiv.org/abs/2406.05852)**|None|None|Rui Zhang et al.|
|**2024-06-07**|**[Normal-guided Detail-Preserving Neural Implicit Function for High-Fidelity 3D Surface Reconstruction](https://arxiv.org/abs/2406.04861)**|Accepted at ACM SIGGRAPH I3D 2025. Published in PACMCGIT journal. Project page with images and code: https://graphics-research-group.github.io/sn-nir|None|Aarya Patel et al.|
|**2024-06-07**|**[UVCPNet: A UAV-Vehicle Collaborative Perception Network for 3D Object Detection](https://arxiv.org/abs/2406.04647)**|None|None|Yuchao Wang et al.|
|**2024-06-06**|**[MambaDepth: Enhancing Long-range Dependency for Self-Supervised Fine-Structured Monocular Depth Estimation](https://arxiv.org/abs/2406.04532)**|None|None|Ionuţ Grigore, Călin-Adrian Popa|
|**2024-06-06**|**[Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image](https://arxiv.org/abs/2406.04343)**|Project page: https://www.robots.ox.ac.uk/~vgg/research/flash3d/|None|Stanislaw Szymanowicz et al.|
|**2024-06-06**|**[Neural Surface Reconstruction from Sparse Views Using Epipolar Geometry](https://arxiv.org/abs/2406.04301)**|None|None|Kaichen Zhou|
|**2024-06-04**|**[VHS: High-Resolution Iterative Stereo Matching with Visual Hull Priors](https://arxiv.org/abs/2406.02552)**|None|None|Markus Plack et al.|
|**2024-06-03**|**[L-MAGIC: Language Model Assisted Generation of Images with Coherence](https://arxiv.org/abs/2406.01843)**|accepted to CVPR 2024|None|Zhipeng Cai et al.|
|**2024-06-03**|**[Learning Temporally Consistent Video Depth from Video Diffusion Priors](https://arxiv.org/abs/2406.01493)**|None|None|Jiahao Shao et al.|
|**2024-06-03**|**[Self-Supervised Geometry-Guided Initialization for Robust Monocular Visual Odometry](https://arxiv.org/abs/2406.00929)**|8 pages. 5 figures. This work has been submitted to the IEEE for possible publication|None|Takayuki Kanai et al.|
|**2024-06-01**|**[MoDGS: Dynamic Gaussian Splatting from Casually-captured Monocular Videos with Depth Priors](https://arxiv.org/abs/2406.00434)**|Accepted as a poster at ICLR. Project page: https://modgs.github.io|None|Qingming Liu et al.|
|**2024-05-30**|**[Uncertainty-guided Optimal Transport in Depth Supervised Sparse-View 3D Gaussian](https://arxiv.org/abs/2405.19657)**|10pages|None|Wei Sun et al.|
|**2024-05-27**|**[Consistency Regularisation for Unsupervised Domain Adaptation in Monocular Depth Estimation](https://arxiv.org/abs/2405.17704)**|Accepted to Conference on Lifelong Learning Agents (CoLLAs) 2024|None|Amir El-Ghoussani et al.|
|**2024-05-27**|**[Benchmarking and Improving Bird's Eye View Perception Robustness in Autonomous Driving](https://arxiv.org/abs/2405.17426)**|TPAMI 2025; 17 pages, 13 figures, 11 tables; Code at this https URL: https://github.com/Daniel-xsy/RoboBEV|None|Shaoyuan Xie et al.|
|**2024-05-27**|**[All-day Depth Completion](https://arxiv.org/abs/2405.17315)**|8 pages, 4 figures|None|Vadim Ezhov et al.|
|**2024-05-27**|**[GenWarp: Single Image to Novel Views with Semantic-Preserving Generative Warping](https://arxiv.org/abs/2405.17251)**|Accepted to NeurIPS 2024 / Project page: https://GenWarp-NVS.github.io|None|Junyoung Seo et al.|
|**2024-05-27**|**[SDL-MVS: View Space and Depth Deformable Learning Paradigm for Multi-View Stereo Reconstruction in Remote Sensing](https://arxiv.org/abs/2405.17140)**|None|None|Yong-Qiang Mao et al.|
|**2024-05-27**|**[DINO-SD: Champion Solution for ICRA 2024 RoboDepth Challenge](https://arxiv.org/abs/2405.17102)**|Outstanding Champion in the RoboDepth Challenge (ICRA24) https://robodrive-24.github.io/|None|Yifan Mao et al.|
|**2024-05-27**|**[A Comparative Study on Multi-task Uncertainty Quantification in Semantic Segmentation and Monocular Depth Estimation](https://arxiv.org/abs/2405.17097)**|This manuscript is an extended version of a previously published conference paper and is currently in review for a journal|None|Steven Landgraf et al.|
|**2024-05-27**|**[DCPI-Depth: Explicitly Infusing Dense Correspondence Prior to Unsupervised Monocular Depth Estimation](https://arxiv.org/abs/2405.16960)**|13 pages, 8 figures|None|Mengtan Zhang et al.|
|**2024-05-27**|**[ContrastAlign: Toward Robust BEV Feature Alignment via Contrastive Learning for Multi-Modal 3D Object Detection](https://arxiv.org/abs/2405.16873)**|None|None|Ziying Song et al.|
|**2024-05-27**|**[Estimating Depth of Monocular Panoramic Image with Teacher-Student Model Fusing Equirectangular and Spherical Representations](https://arxiv.org/abs/2405.16858)**|None|None|Jingguo Liu et al.|
|**2024-05-26**|**[Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians](https://arxiv.org/abs/2405.16544)**|21 pages|None|Erik Sandström et al.|
|**2024-05-24**|**[Transparent Object Depth Completion](https://arxiv.org/abs/2405.15299)**|None|None|Yifan Zhou et al.|
|**2024-05-24**|**[MonoDETRNext: Next-Generation Accurate and Efficient Monocular 3D Object Detector](https://arxiv.org/abs/2405.15176)**|None|None|Pan Liao et al.|
|**2024-05-23**|**[EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting](https://arxiv.org/abs/2405.14959)**|None|None|Jiaxu Wang et al.|
|**2024-05-23**|**[Ghost-Stereo: GhostNet-based Cost Volume Enhancement and Aggregation for Stereo Matching Networks](https://arxiv.org/abs/2405.14520)**|None|None|Xingguang Jiang et al.|
|**2024-05-23**|**[Enhanced Object Tracking by Self-Supervised Auxiliary Depth Estimation Learning](https://arxiv.org/abs/2405.14195)**|None|None|Zhenyu Wei et al.|
|**2024-05-21**|**[Cross-spectral Gated-RGB Stereo Depth Estimation](https://arxiv.org/abs/2405.12759)**|None|None|Samuel Brucker et al.|
|**2024-05-20**|**[Depth Reconstruction with Neural Signed Distance Fields in Structured Light Systems](https://arxiv.org/abs/2405.12006)**|10 pages, 8 figures, accepted by 3DV 2024|None|Rukun Qiao et al.|
|**2024-05-20**|**[Depth Prompting for Sensor-Agnostic Depth Estimation](https://arxiv.org/abs/2405.11867)**|Accepted at CVPR 2024|None|Jin-Hwi Park et al.|
|**2024-05-19**|**[CRF360D: Monocular 360 Depth Estimation via Spherical Fully-Connected CRFs](https://arxiv.org/abs/2405.11564)**|None|None|Zidong Cao, Lin Wang|
|**2024-05-18**|**[Dusk Till Dawn: Self-supervised Nighttime Stereo Depth Estimation using Visual Foundation Models](https://arxiv.org/abs/2405.11158)**|The paper is published at ICRA 2024|None|Madhu Vankadari et al.|
|**2024-05-17**|**[Accurate Training Data for Occupancy Map Prediction in Automated Driving Using Evidence Theory](https://arxiv.org/abs/2405.10575)**|None|None|Jonas Kälble et al.|
|**2024-05-16**|**[Towards Task-Compatible Compressible Representations](https://arxiv.org/abs/2405.10244)**|Published in ICME Workshops 2024|None|Anderson de Andrade, Ivan Bajić|
|**2024-05-16**|**[KPNDepth: Depth Estimation of Lane Images under Complex Rainy Environment](https://arxiv.org/abs/2405.09964)**|None|None|Zhengxu Shi|
|**2024-05-14**|**[CLIP with Quality Captions: A Strong Pretraining for Vision Tasks](https://arxiv.org/abs/2405.08911)**|None|None|Pavan Kumar Anasosalu Vasu et al.|
|**2024-05-14**|**[The RoboDrive Challenge: Drive Anytime Anywhere in Any Condition](https://arxiv.org/abs/2405.08816)**|ICRA 2024; 32 pages, 24 figures, 5 tables; Code at https://robodrive-24.github.io/|None|Lingdong Kong et al.|
|**2024-05-13**|**[SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling](https://arxiv.org/abs/2405.07847)**|Accepted to IEEE Transactions on Robotics (T-RO). For project page and code, please find https://jarrome.github.io/SceneFactory/|None|Yijun Yuan et al.|
|**2024-05-10**|**[Ensuring UAV Safety: A Vision-only and Real-time Framework for Collision Avoidance Through Object Detection, Tracking, and Distance Estimation](https://arxiv.org/abs/2405.06749)**|accepted at ICUAS 2024|None|Vasileios Karampinis et al.|
|**2024-05-10**|**[MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization](https://arxiv.org/abs/2405.06241)**|Accepted by IEEE Robotics and Automation Letters|None|Pengcheng Zhu et al.|
|**2024-05-06**|**[A Construct-Optimize Approach to Sparse View Synthesis without Camera Pose](https://arxiv.org/abs/2405.03659)**|None|None|Kaiwen Jiang et al.|
|**2024-05-03**|**[M${^2}$Depth: Self-supervised Two-Frame Multi-camera Metric Depth Estimation](https://arxiv.org/abs/2405.02004)**|None|None|Yingshuang Zou et al.|
|**2024-05-02**|**[Domain-Transferred Synthetic Data Generation for Improving Monocular Depth Estimation](https://arxiv.org/abs/2405.01113)**|None|None|Seungyeop Lee et al.|
|**2024-05-01**|**[Depth Priors in Removal Neural Radiance Fields](https://arxiv.org/abs/2405.00630)**|17 pages|None|Zhihao Guo, Peng Wang|
|**2024-04-30**|**[Invisible Stitch: Generating Smooth 3D Scenes with Depth Inpainting](https://arxiv.org/abs/2404.19758)**|Project page: https://research.paulengstler.com/invisible-stitch/|None|Paul Engstler et al.|
|**2024-04-30**|**[Masked Spatial Propagation Network for Sparsity-Adaptive Depth Refinement](https://arxiv.org/abs/2404.19294)**|None|None|Jinyoung Jun et al.|
|**2024-04-29**|**[Simple-RF: Regularizing Sparse Input Radiance Fields with Simpler Solutions](https://arxiv.org/abs/2404.19015)**|The source code for our model can be found on our project page: https://nagabhushansn95.github.io/publications/2024/Simple-RF.html. Extension of arXiv:2309.03955|None|Nagabhushan Somraj et al.|
|**2024-04-27**|**[Underwater Variable Zoom: Depth-Guided Perception Network for Underwater Image Enhancement](https://arxiv.org/abs/2404.17883)**|None|None|Zhixiong Huang et al.|
|**2024-04-26**|**[A Novel Spike Transformer Network for Depth Estimation from Event Cameras via Cross-modality Knowledge Distillation](https://arxiv.org/abs/2404.17335)**|16 pages|None|Xin Zhang et al.|
|**2024-04-25**|**[The Third Monocular Depth Estimation Challenge](https://arxiv.org/abs/2404.16831)**|To appear in CVPRW2024|None|Jaime Spencer et al.|
|**2024-04-25**|**[MonoPCC: Photometric-invariant Cycle Constraint for Monocular Depth Estimation of Endoscopic Images](https://arxiv.org/abs/2404.16571)**|14 pages, 12 figures|None|Zhiwei Wang et al.|
|**2024-04-25**|**[Promoting CNNs with Cross-Architecture Knowledge Distillation for Efficient Monocular Depth Estimation](https://arxiv.org/abs/2404.16386)**|None|None|Zhimeng Zheng et al.|
|**2024-04-23**|**[SGFormer: Spherical Geometry Transformer for 360 Depth Estimation](https://arxiv.org/abs/2404.14979)**|None|None|Junsong Zhang et al.|
|**2024-04-23**|**[Mining Supervision for Dynamic Regions in Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2404.14908)**|Accepted to CVPR2024|None|Hoang Chuong Nguyen et al.|
|**2024-04-22**|**[Self-Supervised Monocular Depth Estimation in the Dark: Towards Data Distribution Compensation](https://arxiv.org/abs/2404.13854)**|Accepted by IJCAI2024|None|Haolin Yang et al.|
|**2024-04-21**|**[GScream: Learning 3D Geometry and Feature Consistent Gaussian Splatting for Object Removal](https://arxiv.org/abs/2404.13679)**|Project Page: https://w-ted.github.io/publications/gscream|None|Yuxin Wang et al.|
|**2024-04-20**|**[High-fidelity Endoscopic Image Synthesis by Utilizing Depth-guided Neural Surfaces](https://arxiv.org/abs/2404.13437)**|None|None|Baoru Huang et al.|
|**2024-04-18**|**[SPIdepth: Strengthened Pose Information for Self-supervised Monocular Depth Estimation](https://arxiv.org/abs/2404.12501)**|None|None|Mykola Lavreniuk|
|**2024-04-18**|**[BLINK: Multimodal Large Language Models Can See but Not Perceive](https://arxiv.org/abs/2404.12390)**|Multimodal Benchmark, Project Url: https://zeyofu.github.io/blink/, ECCV 2024|None|Xingyu Fu et al.|
|**2024-04-17**|**[How to deal with glare for improved perception of Autonomous Vehicles](https://arxiv.org/abs/2404.10992)**|14 pages, 9 figures, Accepted IEEE TIV|None|Muhammad Z. Alam et al.|
|**2024-04-15**|**[Digging into contrastive learning for robust depth estimation with diffusion models](https://arxiv.org/abs/2404.09831)**|Accept by ACM MM 2024, Camera Ready Version|None|Jiyuan Wang et al.|
|**2024-04-15**|**[Virtually Enriched NYU Depth V2 Dataset for Monocular Depth Estimation: Do We Need Artificial Augmentation?](https://arxiv.org/abs/2404.09469)**|None|Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 6177-6186, 2024|Dmitry Ignatov et al.|
|**2024-04-14**|**[In My Perspective, In My Hands: Accurate Egocentric 2D Hand Pose and Action Recognition](https://arxiv.org/abs/2404.09308)**|Accepted at: The 18th IEEE International Conference on Automatic Face and Gesture Recognition|None|Wiktor Mucha, Martin Kampel|
|**2024-04-12**|**[Into the Fog: Evaluating Robustness of Multiple Object Tracking](https://arxiv.org/abs/2404.10534)**|None|BMVC 2024|Nadezda Kirillova et al.|
|**2024-04-12**|**[On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation](https://arxiv.org/abs/2404.08540)**|Accepted to CVPR 2024. Project webpage: https://agneetchatterjee.com/robustness_depth_lang/|None|Agneet Chatterjee et al.|
|**2024-04-11**|**[Depth Estimation using Weighted-loss and Transfer Learning](https://arxiv.org/abs/2404.07686)**|None|None|Muhammad Adeel Hafeez et al.|
|**2024-04-11**|**[GLID: Pre-training a Generalist Encoder-Decoder Vision Model](https://arxiv.org/abs/2404.07603)**|CVPR 2024|None|Jihao Liu et al.|
|**2024-04-11**|**[Implicit and Explicit Language Guidance for Diffusion-based Visual Perception](https://arxiv.org/abs/2404.07600)**|Accepted by IEEE TMM|None|Hefeng Wang et al.|
|**2024-04-11**|**[Stereo-LiDAR Depth Estimation with Deformable Propagation and Learned Disparity-Depth Conversion](https://arxiv.org/abs/2404.07545)**|Accepted in ICRA 2024. 8 pages, 6 figures|None|Ang Li et al.|
|**2024-04-10**|**[Self-supervised Monocular Depth Estimation on Water Scenes via Specular Reflection Prior](https://arxiv.org/abs/2404.07176)**|16 pages, 8 figures|None|Zhengyang Lu, Ying Chen|
|**2024-04-10**|**[MonoSelfRecon: Purely Self-Supervised Explicit Generalizable 3D Reconstruction of Indoor Scenes from Monocular RGB Views](https://arxiv.org/abs/2404.06753)**|None|None|Runfa Li et al.|
|**2024-04-09**|**[RoadBEV: Road Surface Reconstruction in Bird's Eye View](https://arxiv.org/abs/2404.06605)**|Accepted by IEEE TITS https://ieeexplore.ieee.org/document/10618926|None|Tong Zhao et al.|
|**2024-04-09**|**[ZeST: Zero-Shot Material Transfer from a Single Image](https://arxiv.org/abs/2404.06425)**|Project Page: https://ttchengab.github.io/zest|None|Ta-Ying Cheng et al.|
|**2024-04-09**|**[Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences](https://arxiv.org/abs/2404.06337)**|None|Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024|Axel Barroso-Laguna et al.|
|**2024-04-09**|**[Enhanced Radar Perception via Multi-Task Learning: Towards Refined Data for Sensor Fusion Applications](https://arxiv.org/abs/2404.06165)**|Accepted by IEEE Intelligent Vehicles Symposium (IV 2024)|None|Huawei Sun et al.|
|**2024-04-09**|**[Incremental Joint Learning of Depth, Pose and Implicit Scene Representation on Monocular Camera in Large-scale Scenes](https://arxiv.org/abs/2404.06050)**|None|None|Tianchen Deng et al.|
|**2024-04-06**|**[HawkDrive: A Transformer-driven Visual Perception System for Autonomous Driving in Night Scene](https://arxiv.org/abs/2404.04653)**|Accepted by IEEE IV 2024|None|Ziang Guo et al.|
|**2024-04-06**|**[Co-Occ: Coupling Explicit Feature Fusion with Volume Rendering Regularization for Multi-Modal 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2404.04561)**|Accepted by IEEE Robotics and Automation Letters (RA-L)|IEEE Robotics and Automation Letters, Volume 9 Issue 6, 5687 - 5694, June 2024|Jingyi Pan et al.|
|**2024-04-05**|**[SpatialTracker: Tracking Any 2D Pixels in 3D Space](https://arxiv.org/abs/2404.04319)**|Accepted to CVPR 2024 (selected as highlight paper). Project page: https://henry123-boy.github.io/SpaTracker/|None|Yuxi Xiao et al.|
|**2024-04-04**|**[Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning](https://arxiv.org/abs/2404.03658)**|CVPR 2024. Project page: https://ruili3.github.io/kyn|None|Rui Li et al.|
|**2024-04-04**|**[MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation](https://arxiv.org/abs/2404.03656)**|Project page: https://mvd-fusion.github.io/|None|Hanzhe Hu et al.|
|**2024-04-04**|**[WorDepth: Variational Language Prior for Monocular Depth Estimation](https://arxiv.org/abs/2404.03635)**|None|None|Ziyao Zeng et al.|
|**2024-04-04**|**[Adaptive Discrete Disparity Volume for Self-supervised Monocular Depth Estimation](https://arxiv.org/abs/2404.03190)**|None|None|Jianwei Ren|
|**2024-04-04**|**[MonoCD: Monocular 3D Object Detection with Complementary Depths](https://arxiv.org/abs/2404.03181)**|Accepted to CVPR 2024|None|Longfei Yan et al.|
|**2024-04-02**|**[CHOSEN: Contrastive Hypothesis Selection for Multi-View Depth Refinement](https://arxiv.org/abs/2404.02225)**|None|None|Di Qiu et al.|
|**2024-04-02**|**[Improving Bird's Eye View Semantic Segmentation by Task Decomposition](https://arxiv.org/abs/2404.01925)**|Accepted by CVPR 2024|None|Tianhao Zhao et al.|
|**2024-04-01**|**[BadPart: Unified Black-box Adversarial Patch Attacks against Pixel-wise Regression Tasks](https://arxiv.org/abs/2404.00924)**|Paper accepted at ICML 2024|None|Zhiyuan Cheng et al.|
|**2024-04-01**|**[MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements](https://arxiv.org/abs/2404.00923)**|Project Webpage: https://vita-group.github.io/MM3DGS-SLAM|None|Lisong C. Sun et al.|
|**2024-03-31**|**[OmniSDF: Scene Reconstruction using Omnidirectional Signed Distance Functions and Adaptive Binoctrees](https://arxiv.org/abs/2404.00678)**|None|Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2024|Hakyeong Kim et al.|
|**2024-03-30**|**[The Devil is in the Edges: Monocular Depth Estimation with Edge-aware Consistency Fusion](https://arxiv.org/abs/2404.00373)**|17 pages, 19 figures|None|Pengzhi Li et al.|
|**2024-03-30**|**[Reusable Architecture Growth for Continual Stereo Matching](https://arxiv.org/abs/2404.00360)**|Extended version of CVPR 2022 paper "Continual Stereo Matching of Continuous Driving Scenes with Growing Architecture" - Accepted to TPAMI in 2024|None|Chenghao Zhang et al.|
|**2024-03-30**|**[MaGRITTe: Manipulative and Generative 3D Realization from Image, Topview and Text](https://arxiv.org/abs/2404.00345)**|Project Page: https://hara012.github.io/MaGRITTe-project|None|Takayuki Hara, Tatsuya Harada|
|**2024-03-29**|**[VSRD: Instance-Aware Volumetric Silhouette Rendering for Weakly Supervised 3D Object Detection](https://arxiv.org/abs/2404.00149)**|CVPR 2024|None|Zihua Liu et al.|
|**2024-03-29**|**[NeSLAM: Neural Implicit Mapping and Self-Supervised Feature Tracking With Depth Completion and Denoising](https://arxiv.org/abs/2403.20034)**|None|None|Tianchen Deng et al.|
|**2024-03-28**|**[GlORIE-SLAM: Globally Optimized RGB-only Implicit Encoding Point Cloud SLAM](https://arxiv.org/abs/2403.19549)**|None|None|Ganlin Zhang et al.|
|**2024-03-28**|**[CoherentGS: Sparse Novel View Synthesis with Coherent 3D Gaussians](https://arxiv.org/abs/2403.19495)**|ECCV2024, Project page: https://people.engr.tamu.edu/nimak/Papers/CoherentGS, Code: https://github.com/avinashpaliwal/CoherentGS|None|Avinash Paliwal et al.|
|**2024-03-28**|**[FlowDepth: Decoupling Optical Flow for Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2403.19294)**|None|None|Yiyang Sun et al.|
|**2024-03-28**|**[Neural Fields for 3D Tracking of Anatomy and Surgical Instruments in Monocular Laparoscopic Video Clips](https://arxiv.org/abs/2403.19265)**|None|None|Beerend G. A. Gerats et al.|
|**2024-03-27**|**[UniDepth: Universal Monocular Metric Depth Estimation](https://arxiv.org/abs/2403.18913)**|None|None|Luigi Piccinelli et al.|
|**2024-03-27**|**[ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation](https://arxiv.org/abs/2403.18807)**|IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2024|None|Suraj Patni et al.|
|**2024-03-27**|**[ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place Recognition](https://arxiv.org/abs/2403.18762)**|8 pages, 11 figures, conference|None|Weidong Xie et al.|
|**2024-03-27**|**[$\mathrm{F^2Depth}$: Self-supervised Indoor Monocular Depth Estimation via Optical Flow Consistency and Feature Map Synthesis](https://arxiv.org/abs/2403.18443)**|None|None|Xiaotong Guo et al.|
|**2024-03-26**|**[Track Everything Everywhere Fast and Robustly](https://arxiv.org/abs/2403.17931)**|project page: https://timsong412.github.io/FastOmniTrack/|None|Yunzhou Song et al.|
|**2024-03-26**|**[Leveraging Near-Field Lighting for Monocular Depth Estimation from Endoscopy Videos](https://arxiv.org/abs/2403.17915)**|Accepted to ECCV 2024. 27 pages, 8 tables, 8 figures. Updated to include reference to clinical dataset|None|Akshay Paruchuri et al.|
|**2024-03-26**|**[DN-Splatter: Depth and Normal Priors for Gaussian Splatting and Meshing](https://arxiv.org/abs/2403.17822)**|To be published in 2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|None|Matias Turkulainen et al.|
|**2024-03-26**|**[Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving](https://arxiv.org/abs/2403.17301)**|Accepted by CVPR 2024|None|Junhao Zheng et al.|
|**2024-03-25**|**[Spike-NeRF: Neural Radiance Field Based On Spike Camera](https://arxiv.org/abs/2403.16410)**|This paper is accepted by ICME2024|None|Yijia Guo et al.|
|**2024-03-25**|**[Elite360D: Towards Efficient 360 Depth Estimation via Semantic- and Distance-Aware Bi-Projection Fusion](https://arxiv.org/abs/2403.16376)**|8 pages, accepted by CVPR2024|None|Hao Ai, Lin Wang|
|**2024-03-24**|**[Configurable Holography: Towards Display and Scene Adaptation](https://arxiv.org/abs/2405.01558)**|11 pages, 9 figures|None|Yicheng Zhan et al.|
|**2024-03-23**|**[Depth Estimation fusing Image and Radar Measurements with Uncertain Directions](https://arxiv.org/abs/2403.15787)**|Accepted to IJCNN 2024 (International Joint Conference on Neural Networks)|None|Masaya Kotani et al.|
|**2024-03-22**|**[Language-Based Depth Hints for Monocular Depth Estimation](https://arxiv.org/abs/2403.15551)**|8 pages, 1 figure. Work originally done in June 2022|None|Dylan Auty, Krystian Mikolajczyk|
|**2024-03-22**|**[Metric3Dv2: A Versatile Monocular Geometric Foundation Model for Zero-shot Metric Depth and Surface Normal Estimation](https://arxiv.org/abs/2404.15506)**|Our project page is at https://JUGGHM.github.io/Metric3Dv2. Accpeted to TPAMI. arXiv admin note: text overlap with arXiv:2307.10984|IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 46, no. 12, pp. 10579-10596, 2024|Mu Hu et al.|
|**2024-03-21**|**[Learning to Project for Cross-Task Knowledge Distillation](https://arxiv.org/abs/2403.14494)**|BMVC 2024|None|Dylan Auty et al.|
|**2024-03-20**|**[DepthFM: Fast Monocular Depth Estimation with Flow Matching](https://arxiv.org/abs/2403.13788)**|AAAI 2025, Project Page: https://github.com/CompVis/depth-fm|None|Ming Gui et al.|
|**2024-03-19**|**[When Do We Not Need Larger Vision Models?](https://arxiv.org/abs/2403.13043)**|Code: https://github.com/bfshi/scaling_on_scales|None|Baifeng Shi et al.|
|**2024-03-19**|**[FutureDepth: Learning to Predict the Future Improves Video Depth Estimation](https://arxiv.org/abs/2403.12953)**|ECCV 2024|None|Rajeev Yasarla et al.|
|**2024-03-19**|**[Geometric Constraints in Deep Learning Frameworks: A Survey](https://arxiv.org/abs/2403.12431)**|Published at ACM Surveys|ACM Computing Surveys, 2025|Vibhas K Vats, David J Crandall|
|**2024-03-18**|**[GraphBEV: Towards Robust BEV Feature Alignment for Multi-Modal 3D Object Detection](https://arxiv.org/abs/2403.11848)**|None|None|Ziying Song et al.|
|**2024-03-18**|**[SSAP: A Shape-Sensitive Adversarial Patch for Comprehensive Disruption of Monocular Depth Estimation in Autonomous Navigation Applications](https://arxiv.org/abs/2403.11515)**|arXiv admin note: text overlap with arXiv:2303.01351|None|Amira Guesmi et al.|
|**2024-03-17**|**[Bilateral Propagation Network for Depth Completion](https://arxiv.org/abs/2403.11270)**|Accepted by CVPR 2024|None|Jie Tang et al.|
|**2024-03-15**|**[SwinMTL: A Shared Architecture for Simultaneous Depth Estimation and Semantic Segmentation from Monocular Camera Images](https://arxiv.org/abs/2403.10662)**|None|None|Pardis Taghavi et al.|
|**2024-03-15**|**[Robust Shape Fitting for 3D Scene Abstraction](https://arxiv.org/abs/2403.10452)**|Accepted for publication in Transactions on Pattern Analysis and Machine Intelligence (PAMI). arXiv admin note: substantial text overlap with arXiv:2105.02047|None|Florian Kluger et al.|
|**2024-03-15**|**[Region-aware Distribution Contrast: A Novel Approach to Multi-Task Partially Supervised Learning](https://arxiv.org/abs/2403.10252)**|None|None|Meixuan Li et al.|
|**2024-03-14**|**[Improving Distant 3D Object Detection Using 2D Box Supervision](https://arxiv.org/abs/2403.09230)**|Accepted by CVPR 2024|None|Zetong Yang et al.|
|**2024-03-13**|**[SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model](https://arxiv.org/abs/2403.08556)**|Accepted by ACM MultiMedia 24, Project Page: xuefeng-cvr.github.io/SM4Depth|None|Yihao Liu et al.|
|**2024-03-13**|**[METER: a mobile vision transformer architecture for monocular depth estimation](https://arxiv.org/abs/2403.08368)**|None|IEEE Transactions on Circuits and Systems for Video Technology, 2023|L. Papa et al.|
|**2024-03-12**|**[Q-SLAM: Quadric Representations for Monocular SLAM](https://arxiv.org/abs/2403.08125)**|Conference on Robot Learning (CoRL 2024)|None|Chensheng Peng et al.|
|**2024-03-12**|**[Adaptive Fusion of Single-View and Multi-View Depth for Autonomous Driving](https://arxiv.org/abs/2403.07535)**|Accepted to CVPR 2024|None|JunDa Cheng et al.|
|**2024-03-12**|**[D4D: An RGBD diffusion model to boost monocular depth estimation](https://arxiv.org/abs/2403.07516)**|None|None|L. Papa et al.|
|**2024-03-12**|**[SGE: Structured Light System Based on Gray Code with an Event Camera](https://arxiv.org/abs/2403.07326)**|None|Opt. Express 32, 46044-46061 (2024)|Xingyu Lu et al.|
|**2024-03-11**|**[Confidence-Aware RGB-D Face Recognition via Virtual Depth Synthesis](https://arxiv.org/abs/2403.06529)**|9 pages, 5 figures|None|Zijian Chen et al.|
|**2024-03-09**|**[DO3D: Self-supervised Learning of Decomposed Object-aware 3D Motion and Depth from Monocular Videos](https://arxiv.org/abs/2403.05895)**|24 pages, 14 figures, Tech Report|None|Xiuzhe Wu et al.|
|**2024-03-08**|**[OccFusion: Depth Estimation Free Multi-sensor Fusion for 3D Occupancy Prediction](https://arxiv.org/abs/2403.05329)**|None|None|Ji Zhang et al.|
|**2024-03-08**|**[Stealing Stable Diffusion Prior for Robust Monocular Depth Estimation](https://arxiv.org/abs/2403.05056)**|None|None|Yifan Mao et al.|
|**2024-03-06**|**[Multi-task Learning for Real-time Autonomous Driving Leveraging Task-adaptive Attention Generator](https://arxiv.org/abs/2403.03468)**|Accepted at ICRA 2024|None|Wonhyeok Choi et al.|
|**2024-03-06**|**[Scene Depth Estimation from Traditional Oriental Landscape Paintings](https://arxiv.org/abs/2403.03408)**|None|None|Sungho Kang et al.|
|**2024-03-04**|**[Scalable Vision-Based 3D Object Detection and Monocular Depth Estimation for Autonomous Driving](https://arxiv.org/abs/2403.02037)**|HKUST PhD Thesis; https://github.com/Owen-Liuyuxuan/visionfactory|None|Yuxuan Liu|
|**2024-03-04**|**[DD-VNB: A Depth-based Dual-Loop Framework for Real-time Visually Navigated Bronchoscopy](https://arxiv.org/abs/2403.01683)**|None|2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)|Qingyao Tian et al.|
|**2024-03-03**|**[Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV](https://arxiv.org/abs/2403.01569)**|None|None|Jaime Spencer et al.|
|**2024-03-03**|**[Pyramid Feature Attention Network for Monocular Depth Prediction](https://arxiv.org/abs/2403.01440)**|6 pages, 5 figures|None|Yifang Xu et al.|
|**2024-03-03**|**[Depth Estimation Algorithm Based on Transformer-Encoder and Feature Fusion](https://arxiv.org/abs/2403.01370)**|ICAACE2024|None|Linhan Xia et al.|
|**2024-03-02**|**[Depth Information Assisted Collaborative Mutual Promotion Network for Single Image Dehazing](https://arxiv.org/abs/2403.01105)**|ACCEPT BY CVPR2024|None|Yafei Zhang et al.|
|**2024-02-29**|**[PCDepth: Pattern-based Complementary Learning for Monocular Depth Estimation by Best of Both Worlds](https://arxiv.org/abs/2402.18925)**|Under Review|None|Haotian Liu et al.|
|**2024-02-28**|**[CFDNet: A Generalizable Foggy Stereo Matching Network with Contrastive Feature Distillation](https://arxiv.org/abs/2402.18181)**|None|IEEE International Conference on Robotics and Automation (ICRA2024)|Zihua Liu et al.|
|**2024-02-28**|**[Self-Supervised Spatially Variant PSF Estimation for Aberration-Aware Depth-from-Defocus](https://arxiv.org/abs/2402.18175)**|None|International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2024|Zhuofeng Wu et al.|
|**2024-02-27**|**[A Vanilla Multi-Task Framework for Dense Visual Prediction Solution to 1st VCL Challenge -- Multi-Task Robustness Track](https://arxiv.org/abs/2402.17319)**|Technical Report|None|Zehui Chen et al.|
|**2024-02-22**|**[GAM-Depth: Self-Supervised Indoor Depth Estimation Leveraging a Gradient-Aware Mask and Semantic Constraints](https://arxiv.org/abs/2402.14354)**|To be published in 2024 IEEE International Conference on Robotics and Automation (ICRA)|None|Anqi Cheng et al.|
|**2024-02-22**|**[TIE-KD: Teacher-Independent and Explainable Knowledge Distillation for Monocular Depth Estimation](https://arxiv.org/abs/2402.14340)**|13 pages, 8 figures, under review for a journal|Image and Vision Computing, 148 (2024), 105110|Sangwon Choi et al.|
|**2024-02-21**|**[Zero-BEV: Zero-shot Projection of Any First-Person Modality to BEV Maps](https://arxiv.org/abs/2402.13848)**|None|None|Gianluca Monaci et al.|
|**2024-02-19**|**[An Endoscopic Chisel: Intraoperative Imaging Carves 3D Anatomical Models](https://arxiv.org/abs/2402.11840)**|None|None|Jan Emily Mangulabnan et al.|
|**2024-02-19**|**[Unveiling the Depths: A Multi-Modal Fusion Framework for Challenging Scenarios](https://arxiv.org/abs/2402.11826)**|None|None|Jialei Xu et al.|
|**2024-02-19**|**[SDGE: Stereo Guided Depth Estimation for 360$^\circ$ Camera Sets](https://arxiv.org/abs/2402.11791)**|None|None|Jialei Xu et al.|
|**2024-02-18**|**[MAL: Motion-Aware Loss with Temporal and Distillation Hints for Self-Supervised Depth Estimation](https://arxiv.org/abs/2402.11507)**|Accepted by ICRA 2024; Project homepage: https://yuejiangdong.github.io/MotionAwareLoss/|None|Yue-Jiang Dong et al.|
|**2024-02-16**|**[Efficient Multi-task Uncertainties for Joint Semantic Segmentation and Monocular Depth Estimation](https://arxiv.org/abs/2402.10580)**|17 pages, 5 figures, 10 tables, submitted to peer-reviewed journal|None|Steven Landgraf et al.|
|**2024-02-15**|**[X-maps: Direct Depth Lookup for Event-based Structured Light Systems](https://arxiv.org/abs/2402.10061)**|Accepted at the CVPR 2023 Workshop on Event-based Vision: https://tub-rip.github.io/eventvision2023/|2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Vancouver, BC, Canada, 2023, pp. 4007-4015|Wieland Morgenstern et al.|
|**2024-02-14**|**[Depth-aware Volume Attention for Texture-less Stereo Matching](https://arxiv.org/abs/2402.08931)**|10 pages, 6 figures|None|Tong Zhao et al.|
|**2024-02-09**|**[Hybridnet for depth estimation and semantic segmentation](https://arxiv.org/abs/2402.06539)**|2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018|None|Dalila Sánchez-Escobedo et al.|
|**2024-02-08**|**[Adaptive Surface Normal Constraint for Geometric Estimation from Monocular Images](https://arxiv.org/abs/2402.05869)**|Accepted by TPAMI. arXiv admin note: substantial text overlap with arXiv:2103.15483|None|Xiaoxiao Long et al.|
|**2024-02-07**|**[Toward Accurate Camera-based 3D Object Detection via Cascade Depth Estimation and Calibration](https://arxiv.org/abs/2402.04883)**|Accepted to ICRA2024|None|Chaoqun Wang et al.|
|**2024-02-06**|**[Energy-based Domain-Adaptive Segmentation with Depth Guidance](https://arxiv.org/abs/2402.03795)**|None|None|Jinjing Zhu et al.|
|**2024-02-06**|**[MoD-SLAM: Monocular Dense Mapping for Unbounded 3D Scene Reconstruction](https://arxiv.org/abs/2402.03762)**|None|None|Heng Zhou et al.|
|**2024-02-05**|**[An Inpainting-Infused Pipeline for Attire and Background Replacement](https://arxiv.org/abs/2402.03501)**|None|None|Felipe Rodrigues Perche-Mahlow et al.|
|**2024-02-05**|**[CLIP Can Understand Depth](https://arxiv.org/abs/2402.03251)**|None|None|Dunam Kim, Seokju Lee|
|**2024-02-03**|**[Decomposition-based and Interference Perception for Infrared and Visible Image Fusion in Complex Scenes](https://arxiv.org/abs/2402.02096)**|None|None|Xilai Li et al.|
|**2024-02-03**|**[RIDERS: Radar-Infrared Depth Estimation for Robust Sensing](https://arxiv.org/abs/2402.02067)**|13 pages, 13 figures|None|Han Li et al.|
|**2024-02-02**|**[Robust Inverse Graphics via Probabilistic Inference](https://arxiv.org/abs/2402.01915)**|ICML submission. Reworked main body, new appendix figures|None|Tuan Anh Le et al.|
|**2024-02-02**|**[Convolution kernel adaptation to calibrated fisheye](https://arxiv.org/abs/2402.01456)**|Previously presented at BMVC: https://proceedings.bmvc2023.org/721/|None|Bruno Berenguel-Baeta et al.|
|**2024-02-01**|**[Diffusion-based Light Field Synthesis](https://arxiv.org/abs/2402.00575)**|11 pages,9 figures|None|Ruisheng Gao et al.|
|**2024-01-29**|**[Depth Anything in Medical Images: A Comparative Study](https://arxiv.org/abs/2401.16600)**|10 pages, 2 figures, 3 tables|None|John J. Han et al.|
|**2024-01-29**|**[Endo-4DGS: Endoscopic Monocular Scene Reconstruction with 4D Gaussian Splatting](https://arxiv.org/abs/2401.16416)**|None|None|Yiming Huang et al.|
|**2024-01-25**|**[Range-Agnostic Multi-View Depth Estimation With Keyframe Selection](https://arxiv.org/abs/2401.14401)**|3DV 2024 Project Page https://andreaconti.github.io/projects/range_agnostic_multi_view_depth GitHub Page https://github.com/andreaconti/ramdepth.git|None|Andrea Conti et al.|
|**2024-01-24**|**[FoVA-Depth: Field-of-View Agnostic Depth Estimation for Cross-Dataset Generalization](https://arxiv.org/abs/2401.13786)**|3DV 2024 (Oral); Project Website: https://research.nvidia.com/labs/lpr/fova-depth/|None|Daniel Lichy et al.|
|**2024-01-23**|**[EndoGaussian: Real-time Gaussian Splatting for Dynamic Endoscopic Scene Reconstruction](https://arxiv.org/abs/2401.12561)**|None|None|Yifan Liu et al.|
|**2024-01-23**|**[InverseMatrixVT3D: An Efficient Projection Matrix-Based Approach for 3D Occupancy Prediction](https://arxiv.org/abs/2401.12422)**|None|None|Zhenxing Ming et al.|
|**2024-01-23**|**[Icy Moon Surface Simulation and Stereo Depth Estimation for Sampling Autonomy](https://arxiv.org/abs/2401.12414)**|Software: https://github.com/nasa-jpl/guiss. IEEE Aerospace Conference 2024|None|Ramchander Bhaskara et al.|
|**2024-01-22**|**[Stereo-Matching Knowledge Distilled Monocular Depth Estimation Filtered by Multiple Disparity Consistency](https://arxiv.org/abs/2401.12019)**|ICASSP 2024. The first two authors are equally contributed|None|Woonghyun Ka et al.|
|**2024-01-22**|**[MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo](https://arxiv.org/abs/2401.11673)**|Accepted to ICLR2024|ICLR(International Conference on Learning Representations) 2024|Chenjie Cao et al.|
|**2024-01-19**|**[Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data](https://arxiv.org/abs/2401.10891)**|Accepted by CVPR 2024. Project page: https://depth-anything.github.io|None|Lihe Yang et al.|
|**2024-01-14**|**[Self-supervised Event-based Monocular Depth Estimation using Cross-modal Consistency](https://arxiv.org/abs/2401.07218)**|Accepted by IROS2023|None|Junyu Zhu et al.|
|**2024-01-11**|**[A Study on Self-Supervised Pretraining for Vision Problems in Gastrointestinal Endoscopy](https://arxiv.org/abs/2401.06278)**|None|None|Edward Sanderson, Bogdan J. Matuszewski|
|**2024-01-11**|**[Surgical-DINO: Adapter Learning of Foundation Models for Depth Estimation in Endoscopic Surgery](https://arxiv.org/abs/2401.06013)**|Accepted by IPCAI 2024 (IJCAR Special Issue)|None|Beilei Cui et al.|
|**2024-01-10**|**[InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes](https://arxiv.org/abs/2401.05335)**|None|None|Mohamad Shahbazi et al.|
|**2024-01-09**|**[RadarCam-Depth: Radar-Camera Fusion for Depth Estimation with Learned Metric Scale](https://arxiv.org/abs/2401.04325)**|None|None|Han Li et al.|
|**2024-01-08**|**[NeRFmentation: NeRF-based Augmentation for Monocular Depth Estimation](https://arxiv.org/abs/2401.03771)**|None|None|Casimir Feldmann et al.|
|**2024-01-06**|**[Hi-Map: Hierarchical Factorized Radiance Field for High-Fidelity Monocular Dense Mapping](https://arxiv.org/abs/2401.03203)**|None|None|Tongyan Hua et al.|
|**2024-01-02**|**[Depth-discriminative Metric Learning for Monocular 3D Object Detection](https://arxiv.org/abs/2401.01075)**|Accepted at NeurIPS 2023|None|Wonhyeok Choi et al.|
|**2023-12-31**|**[SteinDreamer: Variance Reduction for Text-to-3D Score Distillation via Stein Identity](https://arxiv.org/abs/2401.00604)**|Project page: https://vita-group.github.io/SteinDreamer/|None|Peihao Wang et al.|
|**2023-12-26**|**[Learning Deformable Hypothesis Sampling for Accurate PatchMatch Multi-View Stereo](https://arxiv.org/abs/2312.15970)**|None|None|Hongjie Li et al.|
|**2023-12-23**|**[Manydepth2: Motion-Aware Self-Supervised Monocular Depth Estimation in Dynamic Scenes](https://arxiv.org/abs/2312.15268)**|Monocular Depth Estimation, Self-Supervised, Optical Flow|None|Kaichen Zhou et al.|
|**2023-12-22**|**[Lift-Attend-Splat: Bird's-eye-view camera-lidar fusion using transformers](https://arxiv.org/abs/2312.14919)**|Updated method figure; camera ready|None|James Gunn et al.|
|**2023-12-22**|**[Harnessing Diffusion Models for Visual Perception with Meta Prompts](https://arxiv.org/abs/2312.14733)**|None|None|Qiang Wan et al.|
|**2023-12-22**|**[Pola4All: survey of polarimetric applications and an open-source toolkit to analyze polarization](https://arxiv.org/abs/2312.14697)**|None|None|Joaquin Rodriguez et al.|
|**2023-12-21**|**[DUSt3R: Geometric 3D Vision Made Easy](https://arxiv.org/abs/2312.14132)**|fixing the ref for StaticThings3D dataset|None|Shuzhe Wang et al.|
|**2023-12-20**|**[Zero-Shot Metric Depth with a Field-of-View Conditioned Diffusion Model](https://arxiv.org/abs/2312.13252)**|None|None|Saurabh Saxena et al.|
|**2023-12-20**|**[PPEA-Depth: Progressive Parameter-Efficient Adaptation for Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2312.13066)**|Accepted by AAAI 2024 Project homepage: https://yuejiangdong.github.io/PPEADepth/|None|Yue-Jiang Dong et al.|
|**2023-12-19**|**[Atlantis: Enabling Underwater Depth Estimation with Stable Diffusion](https://arxiv.org/abs/2312.12471)**|10 pages|None|Fan Zhang et al.|
|**2023-12-18**|**[SinMPI: Novel View Synthesis from a Single Image with Expanded Multiplane Images](https://arxiv.org/abs/2312.11037)**|10 pages|None|Guo Pu et al.|
|**2023-12-18**|**[Long-Tailed 3D Detection via Multi-Modal Fusion](https://arxiv.org/abs/2312.10986)**|The first two authors contributed equally. Project page: https://mayechi.github.io/lt3d-lf-io/|None|Yechi Ma et al.|
|**2023-12-15**|**[From-Ground-To-Objects: Coarse-to-Fine Self-supervised Monocular Depth Estimation of Dynamic Objects with Ground Contact Prior](https://arxiv.org/abs/2312.10118)**|None|None|Jaeho Moon et al.|
|**2023-12-14**|**[OccNeRF: Advancing 3D Occupancy Prediction in LiDAR-Free Environments](https://arxiv.org/abs/2312.09243)**|Code: https://github.com/LinShan-Bin/OccNeRF|None|Chubin Zhang et al.|
|**2023-12-14**|**[Text2Immersion: Generative Immersive Scene with 3D Gaussians](https://arxiv.org/abs/2312.09242)**|Project page: https://ken-ouyang.github.io/text2immersion/index.html|None|Hao Ouyang et al.|
|**2023-12-14**|**[CT-MVSNet: Efficient Multi-View Stereo with Cross-scale Transformer](https://arxiv.org/abs/2312.08594)**|Accepted at the 30th International Conference on Multimedia Modeling(MMM'24 Oral)|None|Sicheng Wang et al.|
|**2023-12-13**|**[EVP: Enhanced Visual Perception using Inverse Multi-Attentive Feature Refinement and Regularized Image-Text Alignment](https://arxiv.org/abs/2312.08548)**|None|None|Mykola Lavreniuk et al.|
|**2023-12-13**|**[Instance-aware Multi-Camera 3D Object Detection with Structural Priors Mining and Self-Boosting Learning](https://arxiv.org/abs/2312.08004)**|Accepted to AAAI 2024|None|Yang Jiao et al.|
|**2023-12-10**|**[GenDepth: Generalizing Monocular Depth Estimation for Arbitrary Camera Parameters via Ground Plane Embedding](https://arxiv.org/abs/2312.06021)**|None|None|Karlo Koledić et al.|
|**2023-12-08**|**[Fine Dense Alignment of Image Bursts through Camera Pose and Depth Estimation](https://arxiv.org/abs/2312.05190)**|None|None|Bruno Lecouat et al.|
|**2023-12-07**|**[Camera Height Doesn't Change: Unsupervised Training for Metric Monocular Road-Scene Depth Estimation](https://arxiv.org/abs/2312.04530)**|ECCV 2024. Project page: https://vision.ist.i.kyoto-u.ac.jp/research/fumet/|None|Genki Kinoshita, Ko Nishino|
|**2023-12-04**|**[PatchFusion: An End-to-End Tile-Based Framework for High-Resolution Monocular Metric Depth Estimation](https://arxiv.org/abs/2312.02284)**|None|None|Zhenyu Li et al.|
|**2023-12-04**|**[GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesis](https://arxiv.org/abs/2312.02155)**|Accepted by CVPR 2024 (Highlight). Project page: https://shunyuanzheng.github.io/GPS-Gaussian|None|Shunyuan Zheng et al.|
|**2023-12-04**|**[Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation](https://arxiv.org/abs/2312.02145)**|CVPR 2024 camera ready|None|Bingxin Ke et al.|
|**2023-12-04**|**[GIVT: Generative Infinite-Vocabulary Transformers](https://arxiv.org/abs/2312.02116)**|v2: add related NLP work, loss details. v3: Improved GMM formulation, added adapter module, larger models, better image generation results. v4: ECCV 2024 camera ready version (minor changes). Code and model checkpoints are available at: https://github.com/google-research/big_vision|None|Michael Tschannen et al.|
|**2023-12-04**|**[BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection](https://arxiv.org/abs/2312.01696)**|None|None|Zhenxin Li et al.|
|**2023-12-03**|**[Deeper into Self-Supervised Monocular Indoor Depth Estimation](https://arxiv.org/abs/2312.01283)**|None|None|Chao Fan et al.|
|**2023-12-02**|**[Diffusion Handles: Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D](https://arxiv.org/abs/2312.02190)**|Project Webpage: https://diffusionhandles.github.io/|None|Karran Pandey et al.|
|**2023-12-01**|**[Enhancing Diffusion Models with 3D Perspective Geometry Constraints](https://arxiv.org/abs/2312.00944)**|Project Webpage: http://visual.ee.ucla.edu/diffusionperspective.htm/|None|Rishi Upadhyay et al.|
|**2023-12-01**|**[FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting](https://arxiv.org/abs/2312.00451)**|Project page: https://zehaozhu.github.io/FSGS/|None|Zehao Zhu et al.|
|**2023-11-30**|**[Multi-task learning with cross-task consistency for improved depth estimation in colonoscopy](https://arxiv.org/abs/2311.18664)**|19 pages|None|Pedro Esteban Chavarrias Solano et al.|
|**2023-11-28**|**[UC-NeRF: Neural Radiance Field for Under-Calibrated Multi-view Cameras in Autonomous Driving](https://arxiv.org/abs/2311.16945)**|See the project page for code, data: https://kcheng1021.github.io/ucnerf.github.io|None|Kai Cheng et al.|
|**2023-11-28**|**[DGNR: Density-Guided Neural Point Rendering of Large Driving Scenes](https://arxiv.org/abs/2311.16664)**|None|None|Zhuopeng Li et al.|
|**2023-11-22**|**[Depth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot Images](https://arxiv.org/abs/2311.13398)**|10 pages, 5 figures; Project page: robot0321.github.io/DepthRegGS|None|Jaeyoung Chung et al.|
|**2023-11-21**|**[Camera-Independent Single Image Depth Estimation from Defocus Blur](https://arxiv.org/abs/2311.13045)**|None|None|Lahiru Wijayasingha et al.|
|**2023-11-21**|**[SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction](https://arxiv.org/abs/2311.12754)**|Code is available at: https://github.com/huang-yh/SelfOcc|None|Yuanhui Huang et al.|
|**2023-11-21**|**[Transferring to Real-World Layouts: A Depth-aware Framework for Scene Adaptation](https://arxiv.org/abs/2311.12682)**|ACM MM 2024 (Oral)|None|Mu Chen et al.|
|**2023-11-16**|**[Depth Insight -- Contribution of Different Features to Indoor Single-image Depth Estimation](https://arxiv.org/abs/2311.10042)**|None|None|Yihong Wu et al.|
|**2023-11-15**|**[RENI++ A Rotation-Equivariant, Scale-Invariant, Natural Illumination Prior](https://arxiv.org/abs/2311.09361)**|Project Repo - https://github.com/JADGardner/ns_reni. arXiv admin note: substantial text overlap with arXiv:2206.03858|None|James A. D. Gardner et al.|
|**2023-11-15**|**[Why Autonomous Vehicles Are Not Ready Yet: A Multi-Disciplinary Review of Problems, Attempted Solutions, and Future Directions](https://arxiv.org/abs/2311.09093)**|This manuscript extends the work "Applications of Computer Vision in Autonomous Vehicles: Methods, Challenges, and Future Directions." We have added several sections to explore autonomous vehicles from a multidisciplinary perspective. We propose changing the arXiv category to cs.RO, as the expanded content addresses broader autonomous vehicle topics aligning more closely with the Robotics domain|None|Xingshuai Dong et al.|
|**2023-11-14**|**[Learning based Deep Disentangling Light Field Reconstruction and Disparity Estimation Application](https://arxiv.org/abs/2311.08129)**|None|None|Langqing Shi, Ping Zhou|
|**2023-11-13**|**[MonoDiffusion: Self-Supervised Monocular Depth Estimation Using Diffusion Model](https://arxiv.org/abs/2311.07198)**|10 pages, 8 figures|None|Shuwei Shao et al.|
|**2023-11-13**|**[NDDepth: Normal-Distance Assisted Monocular Depth Estimation and Completion](https://arxiv.org/abs/2311.07166)**|Extension of previous work arXiv:2309.10592|None|Shuwei Shao et al.|
|**2023-11-10**|**[MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty](https://arxiv.org/abs/2311.06137)**|Accepted at WACV 2024|None|Rémi Marsal et al.|
|**2023-11-09**|**[PolyMaX: General Dense Prediction with Mask Transformer](https://arxiv.org/abs/2311.05770)**|WACV 2024|None|Xuan Yang et al.|
|**2023-11-08**|**[Leveraging a realistic synthetic database to learn Shape-from-Shading for estimating the colon depth in colonoscopy images](https://arxiv.org/abs/2311.05021)**|None|Ruano, J., Gomez, M., Romero, E., & Manzanera, A. (2024). Leveraging a realistic synthetic database to learn Shape-from-Shading for estimating the colon depth in colonoscopy images. Computerized Medical Imaging and Graphics, 102390|Josué Ruano et al.|
|**2023-11-07**|**[Analysis of NaN Divergence in Training Monocular Depth Estimation Model](https://arxiv.org/abs/2311.03938)**|10 pages, 3 figures|None|Bum Jun Kim et al.|
|**2023-11-06**|**[TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic Scene Understanding](https://arxiv.org/abs/2311.03427)**|WACV 2024|None|Shuo Wang et al.|
|**2023-11-04**|**[Continual Learning of Unsupervised Monocular Depth from Videos](https://arxiv.org/abs/2311.02393)**|Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)|None|Hemang Chawla et al.|
|**2023-11-03**|**[Bridging the Gap between Multi-focus and Multi-modal: A Focused Integration Framework for Multi-modal Image Fusion](https://arxiv.org/abs/2311.01886)**|Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024|None|Xilai Li et al.|
|**2023-11-02**|**[Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation](https://arxiv.org/abs/2311.01034)**|Accepted by WACV 2024|None|Xueting Hu et al.|
|**2023-10-29**|**[Dynamo-Depth: Fixing Unsupervised Depth Estimation for Dynamical Scenes](https://arxiv.org/abs/2310.18887)**|NeurIPS 2023|None|Yihong Sun, Bharath Hariharan|
|**2023-10-26**|**[Learning depth from monocular video sequences](https://arxiv.org/abs/2310.17156)**|None|None|Zhenwei Luo|
|**2023-10-26**|**[Deep Imbalanced Regression via Hierarchical Classification Adjustment](https://arxiv.org/abs/2310.17154)**|14 pages, 5 figures|None|Haipeng Xiong, Angela Yao|
|**2023-10-25**|**[PERF: Panoramic Neural Radiance Field from a Single Panorama](https://arxiv.org/abs/2310.16831)**|Project Page: https://perf-project.github.io/ , Code: https://github.com/perf-project/PeRF|None|Guangcong Wang et al.|
|**2023-10-25**|**[Metrically Scaled Monocular Depth Estimation through Sparse Priors for Underwater Robots](https://arxiv.org/abs/2310.16750)**|Submitted to ICRA 2024|None|Luca Ebner et al.|
|**2023-10-25**|**[Towards Explainability in Monocular Depth Estimation](https://arxiv.org/abs/2310.16457)**|None|None|Vasileios Arampatzakis et al.|
|**2023-10-24**|**[iNVS: Repurposing Diffusion Inpainters for Novel View Synthesis](https://arxiv.org/abs/2310.16167)**|Accepted to SIGGRAPH Asia, 2023 (Conference Papers)|None|Yash Kant et al.|
|**2023-10-24**|**[G2-MonoDepth: A General Framework of Generalized Depth Inference from Monocular RGB+X Data](https://arxiv.org/abs/2310.15422)**|18 pages, 16 figures|None|Haotian Wang et al.|
|**2023-10-23**|**[RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions](https://arxiv.org/abs/2310.15171)**|NeurIPS 2023; 45 pages, 25 figures, 13 tables; Code at https://github.com/ldkong1205/RoboDepth|None|Lingdong Kong et al.|
|**2023-10-22**|**[Mobile AR Depth Estimation: Challenges & Prospects -- Extended Version](https://arxiv.org/abs/2310.14437)**|None|None|Ashkan Ganj et al.|
|**2023-10-22**|**[A Quantitative Evaluation of Dense 3D Reconstruction of Sinus Anatomy from Monocular Endoscopic Video](https://arxiv.org/abs/2310.14364)**|None|None|Jan Emily Mangulabnan et al.|
|**2023-10-22**|**[Guidance system for Visually Impaired Persons using Deep Learning and Optical flow](https://arxiv.org/abs/2310.14239)**|None|None|Shwetang Dubey et al.|
|**2023-10-18**|**[Towards Abdominal 3-D Scene Rendering from Laparoscopy Surgical Videos using NeRFs](https://arxiv.org/abs/2310.11645)**|The Version of Record of this contribution is published in MLMI 2023 Part I, and is available online at https://doi.org/10.1007/978-3-031-45673-2_9|None|Khoa Tuan Nguyen et al.|
|**2023-10-17**|**[FocDepthFormer: Transformer with latent LSTM for Depth Estimation from Focal Stack](https://arxiv.org/abs/2310.11178)**|30 pages, 20 figures, Conference paper|None|Xueyang Kang et al.|
|**2023-10-12**|**[Pseudo-Generalized Dynamic View Synthesis from a Video](https://arxiv.org/abs/2310.08587)**|ICLR 2024; Originally titled as "Is Generalized Dynamic Novel View Synthesis from Monocular Videos Possible Today?"; Project page: https://xiaoming-zhao.github.io/projects/pgdvs|None|Xiaoming Zhao et al.|
|**2023-10-12**|**[EC-Depth: Exploring the consistency of self-supervised monocular depth estimation in challenging scenes](https://arxiv.org/abs/2310.08044)**|Project page: https://ruijiezhu94.github.io/ECDepth_page|None|Ziyang Song et al.|
|**2023-10-11**|**[Multi-Task Learning-Enabled Automatic Vessel Draft Reading for Intelligent Maritime Surveillance](https://arxiv.org/abs/2310.07212)**|12 pages,11 figures, submitted to IEEE T-ITS|None|Jingxiang Qu et al.|
|**2023-10-09**|**[WeatherDepth: Curriculum Contrastive Learning for Self-Supervised Depth Estimation under Adverse Weather Conditions](https://arxiv.org/abs/2310.05556)**|6 pages, accept by ICRA 2024|ICRA 2024|Jiyuan Wang et al.|
|**2023-10-07**|**[Federated Self-Supervised Learning of Monocular Depth Estimators for Autonomous Vehicles](https://arxiv.org/abs/2310.04837)**|16 pages, 8 figures, journal preprint|None|Elton F. de S. Soares, Carlos Alberto V. Campos|
|**2023-10-06**|**[MeSa: Masked, Geometric, and Supervised Pre-training for Monocular Depth Estimation](https://arxiv.org/abs/2310.04551)**|None|None|Muhammad Osama Khan et al.|
|**2023-10-06**|**[Sub-token ViT Embedding via Stochastic Resonance Transformers](https://arxiv.org/abs/2310.03967)**|None|None|Dong Lao et al.|
|**2023-10-05**|**[FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators](https://arxiv.org/abs/2310.03420)**|CameraReady version for ICLR 2024. Project Page: https://whu-usi3dv.github.io/FreeReg/|None|Haiping Wang et al.|
|**2023-10-03**|**[RSRD: A Road Surface Reconstruction Dataset and Benchmark for Safe and Comfortable Autonomous Driving](https://arxiv.org/abs/2310.02262)**|None|None|Tong Zhao et al.|
|**2023-10-03**|**[Selective Feature Adapter for Dense Vision Transformers](https://arxiv.org/abs/2310.01843)**|None|None|Xueqing Deng et al.|
|**2023-10-03**|**[Skin the sheep not only once: Reusing Various Depth Datasets to Drive the Learning of Optical Flow](https://arxiv.org/abs/2310.01833)**|None|None|Sheng-Chi Huang, Wei-Chen Chiu|
|**2023-10-02**|**[Multi-task Learning with 3D-Aware Regularization](https://arxiv.org/abs/2310.00986)**|3D-aware Multi-task Learning, Code will be available at https://github.com/VICO-UoE/MTPSL|None|Wei-Hong Li et al.|
|**2023-09-30**|**[InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists](https://arxiv.org/abs/2310.00390)**|ICLR 2024; Code is available at https://github.com/AlaaLab/InstructCV|None|Yulu Gan et al.|
|**2023-09-29**|**[IFAST: Weakly Supervised Interpretable Face Anti-spoofing from Single-shot Binocular NIR Images](https://arxiv.org/abs/2309.17399)**|None|None|Jiancheng Huang et al.|
|**2023-09-29**|**[GSDC Transformer: An Efficient and Effective Cue Fusion for Monocular Multi-Frame Depth Estimation](https://arxiv.org/abs/2309.17059)**|None|None|Naiyu Fang et al.|
|**2023-09-29**|**[Text-image Alignment for Diffusion-based Perception](https://arxiv.org/abs/2310.00031)**|Project page: https://www.vision.caltech.edu/tadp/, Code page: github.com/damaggu/TADP|None|Neehar Kondapaneni et al.|
|**2023-09-28**|**[Gated Cross-Attention Network for Depth Completion](https://arxiv.org/abs/2309.16301)**|None|None|Xiaogang Jia et al.|
|**2023-09-27**|**[InfraParis: A multi-modal and multi-task autonomous driving dataset](https://arxiv.org/abs/2309.15751)**|15 pages, 7 figures. Accepted at WACV 2024|None|Gianni Franchi et al.|
|**2023-09-27**|**[Finite Scalar Quantization: VQ-VAE Made Simple](https://arxiv.org/abs/2309.15505)**|Code: https://github.com/google-research/google-research/tree/master/fsq|None|Fabian Mentzer et al.|
|**2023-09-26**|**[M$^{3}$3D: Learning 3D priors using Multi-Modal Masked Autoencoders for 2D image and video understanding](https://arxiv.org/abs/2309.15313)**|None|None|Muhammad Abdullah Jamal, Omid Mohareri|
|**2023-09-26**|**[GasMono: Geometry-Aided Self-Supervised Monocular Depth Estimation for Indoor Scenes](https://arxiv.org/abs/2309.16019)**|ICCV 2023. Code: https://github.com/zxcqlf/GasMono|None|Chaoqiang Zhao et al.|
|**2023-09-26**|**[ADU-Depth: Attention-based Distillation with Uncertainty Modeling for Depth Estimation](https://arxiv.org/abs/2309.14744)**|accepted by CoRL 2023|None|Zizhang Wu et al.|
|**2023-09-25**|**[IEBins: Iterative Elastic Bins for Monocular Depth Estimation](https://arxiv.org/abs/2309.14137)**|Accepted by NeurIPS 2023|None|Shuwei Shao et al.|
|**2023-09-25**|**[DISeR: Designing Imaging Systems with Reinforcement Learning](https://arxiv.org/abs/2309.13851)**|ICCV 2023. Project Page: https://tzofi.github.io/diser|None|Tzofi Klinghoffer et al.|
|**2023-09-24**|**[InSpaceType: Reconsider Space Type in Indoor Monocular Depth Estimation](https://arxiv.org/abs/2309.13516)**|Add Depth-Anything|None|Cho-Ying Wu et al.|
|**2023-09-22**|**[SRFNet: Monocular Depth Estimation with Fine-grained Structure via Spatial Reliability-oriented Fusion of Frames and Events](https://arxiv.org/abs/2309.12842)**|Accepted to ICRA 2024|None|Tianbo Pan et al.|
|**2023-09-21**|**[SANPO: A Scene Understanding, Accessibility and Human Navigation Dataset](https://arxiv.org/abs/2309.12172)**|WACV2025 submission version. 8 pages, plus supplementary material|None|Sagar M. Waghmare et al.|
|**2023-09-20**|**[BroadBEV: Collaborative LiDAR-camera Fusion for Broad-sighted Bird's Eye View Map Construction](https://arxiv.org/abs/2309.11119)**|None|None|Minsu Kim et al.|
|**2023-09-20**|**[Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal Distillation](https://arxiv.org/abs/2309.11081)**|Published to ICCV2023|None|Heeseung Yun et al.|
|**2023-09-19**|**[NDDepth: Normal-Distance Assisted Monocular Depth Estimation](https://arxiv.org/abs/2309.10592)**|Accepted by ICCV 2023 (Oral)|None|Shuwei Shao et al.|
|**2023-09-18**|**[GEDepth: Ground Embedding for Monocular Depth Estimation](https://arxiv.org/abs/2309.09975)**|ICCV 2023|None|Xiaodong Yang et al.|
|**2023-09-18**|**[Robust Geometry-Preserving Depth Estimation Using Differentiable Rendering](https://arxiv.org/abs/2309.09724)**|Accepted by ICCV2023|None|Chi Zhang et al.|
|**2023-09-17**|**[Deep Neighbor Layer Aggregation for Lightweight Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2309.09272)**|None|None|Wang Boya et al.|
|**2023-09-16**|**[DEUX: Active Exploration for Learning Unsupervised Depth Perception](https://arxiv.org/abs/2310.06164)**|None|None|Marvin Chancán et al.|
|**2023-09-15**|**[X-PDNet: Accurate Joint Plane Instance Segmentation and Monocular Depth Estimation with Cross-Task Distillation and Boundary Correction](https://arxiv.org/abs/2309.08424)**|Accepted to BMVC 2023|None|Cao Dinh Duc, Jongwoo Lim|
|**2023-09-14**|**[Depth Estimation from a Single Optical Encoded Image using a Learned Colored-Coded Aperture](https://arxiv.org/abs/2309.08033)**|None|None|Jhon Lopez et al.|
|**2023-09-12**|**[AmodalSynthDrive: A Synthetic Amodal Perception Dataset for Autonomous Driving](https://arxiv.org/abs/2309.06547)**|None|None|Ahmed Rida Sekkat et al.|
|**2023-09-11**|**[Towards Better Data Exploitation in Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2309.05254)**|8 pages, 6 figures, accepted by IEEE Robotics and Automation Letters (RA-L 2023)|None|Jinfeng Liu et al.|
|**2023-09-08**|**[Robot Localization and Mapping Final Report -- Sequential Adversarial Learning for Self-Supervised Deep Visual Odometry](https://arxiv.org/abs/2309.04147)**|None|None|Akankshya Kar et al.|
|**2023-09-07**|**[SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with Simpler Solutions](https://arxiv.org/abs/2309.03955)**|SIGGRAPH Asia 2023|None|Nagabhushan Somraj et al.|
|**2023-09-07**|**[Joint Self-supervised Depth and Optical Flow Estimation towards Dynamic Objects](https://arxiv.org/abs/2310.00011)**|None|None|Zhengyang Lu, Ying Chen|
|**2023-09-06**|**[Bayes' Rays: Uncertainty Quantification for Neural Radiance Fields](https://arxiv.org/abs/2309.03185)**|None|None|Lily Goli et al.|
|**2023-09-02**|**[Two-in-One Depth: Bridging the Gap Between Monocular and Binocular Self-supervised Depth Estimation](https://arxiv.org/abs/2309.00933)**|Accepted to ICCV 2023|None|Zhengming Zhou, Qiulei Dong|
|**2023-09-01**|**[SQLdepth: Generalizable Self-Supervised Fine-Structured Monocular Depth Estimation](https://arxiv.org/abs/2309.00526)**|14 pages, 9 figures|None|Youhong Wang et al.|
|**2023-08-29**|**[Learning to Upsample by Learning to Sample](https://arxiv.org/abs/2308.15085)**|Accepted by ICCV 2023|None|Wenze Liu et al.|
|**2023-08-28**|**[Semi-Supervised Semantic Depth Estimation using Symbiotic Transformer and NearFarMix Augmentation](https://arxiv.org/abs/2308.14400)**|Accepted at WACV 2024|None|Md Awsafur Rahman, Shaikh Anowarul Fattah|
|**2023-08-27**|**[Depth self-supervision for single image novel view synthesis](https://arxiv.org/abs/2308.14108)**|None|None|Giovanni Minelli et al.|
|**2023-08-27**|**[Calibrating Panoramic Depth Estimation for Practical Localization and Mapping](https://arxiv.org/abs/2308.14005)**|Accepted to ICCV 2023|None|Junho Kim et al.|
|**2023-08-24**|**[Panoptic-Depth Color Map for Combination of Depth and Image Segmentation](https://arxiv.org/abs/2308.12937)**|None|None|Jia-Quan Yu, Soo-Chang Pei|
|**2023-08-22**|**[WS-SfMLearner: Self-supervised Monocular Depth and Ego-motion Estimation on Surgical Videos with Unknown Camera Parameters](https://arxiv.org/abs/2308.11776)**|Accepted by SPIE 2024|None|Ange Lou, Jack Noble|
|**2023-08-22**|**[SAMSNeRF: Segment Anything Model (SAM) Guides Dynamic Surgical Scene Reconstruction by Neural Radiance Field (NeRF)](https://arxiv.org/abs/2308.11774)**|Accepted by SPIE 2024|None|Ange Lou et al.|
|**2023-08-21**|**[A step towards understanding why classification helps regression](https://arxiv.org/abs/2308.10603)**|Accepted at ICCV-2023|None|Silvia L. Pintea et al.|
|**2023-08-21**|**[Real-time Monocular Depth Estimation on Embedded Systems](https://arxiv.org/abs/2308.10569)**|7 pages, ICIP2024 Accepted|None|Cheng Feng et al.|
|**2023-08-21**|**[LightDepth: Single-View Depth Self-Supervision from Illumination Decline](https://arxiv.org/abs/2308.10525)**|None|None|Javier Rodríguez-Puigvert et al.|
|**2023-08-19**|**[AltNeRF: Learning Robust Neural Radiance Field via Alternating Depth-Pose Optimization](https://arxiv.org/abs/2308.10001)**|Accepted by AAAI-24|None|Kun Wang et al.|
|**2023-08-19**|**[TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo](https://arxiv.org/abs/2308.09990)**|None|None|Zhenlong Yuan et al.|
|**2023-08-18**|**[Robust Monocular Depth Estimation under Challenging Conditions](https://arxiv.org/abs/2308.09711)**|ICCV 2023. Source code and data: https://md4all.github.io|None|Stefano Gasperini et al.|
|**2023-08-17**|**[Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression](https://arxiv.org/abs/2308.09065)**|23 pages with main paper and supplymentary material. Accepted at AAAI 2024|None|Xuanlong Yu et al.|
|**2023-08-17**|**[ARAI-MVSNet: A multi-view stereo depth estimation network with adaptive depth range and depth interval](https://arxiv.org/abs/2308.09022)**|None|None|Song Zhang et al.|
|**2023-08-16**|**[Improving Depth Gradient Continuity in Transformers: A Comparative Study on Monocular Depth Estimation with CNN](https://arxiv.org/abs/2308.08333)**|Accepted by BMVC 2024. Project page: https://github.com/Jiawei-Yao0812/PixelFormer_DGR|None|Jiawei Yao et al.|
|**2023-08-14**|**[DS-Depth: Dynamic and Static Depth Estimation via a Fusion Cost Volume](https://arxiv.org/abs/2308.07225)**|None|None|Xingyu Miao et al.|
|**2023-08-11**|**[DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models](https://arxiv.org/abs/2308.06160)**|None|Proc. Advances In Neural Information Processing Systems (NeurIPS 2023)|Weijia Wu et al.|
|**2023-08-11**|**[Out-of-Distribution Detection for Monocular Depth Estimation](https://arxiv.org/abs/2308.06072)**|Accepted to ICCV 2023|None|Julia Hornauer et al.|
|**2023-08-10**|**[FrozenRecon: Pose-free 3D Scene Reconstruction with Frozen Depth Models](https://arxiv.org/abs/2308.05733)**|Accepted to ICCV 2023. Project webpage is at: https://aim-uofa.github.io/FrozenRecon/|None|Guangkai Xu et al.|
|**2023-08-10**|**[Self-Supervised Monocular Depth Estimation by Direction-aware Cumulative Convolution Network](https://arxiv.org/abs/2308.05605)**|ICCV2023|None|Wencheng Han et al.|
|**2023-08-06**|**[Syn-Mediverse: A Multimodal Synthetic Dataset for Intelligent Scene Understanding of Healthcare Facilities](https://arxiv.org/abs/2308.03193)**|None|IEEE Robotics and Automation Letters, vol. 9, no. 8, pp. 7094-7101, Aug. 2024|Rohit Mohan et al.|
|**2023-08-04**|**[EndoDepthL: Lightweight Endoscopic Monocular Depth Estimation with CNN-Transformer](https://arxiv.org/abs/2308.02716)**|None|None|Yangke Li|
|**2023-08-04**|**[Diffusion-Augmented Depth Prediction with Sparse Annotations](https://arxiv.org/abs/2308.02283)**|Accepted by ACM MM'2023|None|Jiaqi Li et al.|
|**2023-08-04**|**[Robust Self-Supervised Extrinsic Self-Calibration](https://arxiv.org/abs/2308.02153)**|Project page: https://sites.google.com/view/tri-sesc|The IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023|Takayuki Kanai et al.|
|**2023-08-02**|**[Hand tracking for clinical applications: validation of the Google MediaPipe Hand (GMH) and the depth-enhanced GMH-D frameworks](https://arxiv.org/abs/2308.01088)**|None|None|Gianluca Amprimo et al.|
|**2023-07-31**|**[Digging Into Uncertainty-based Pseudo-label for Robust Stereo Matching](https://arxiv.org/abs/2307.16509)**|Accepted by TPAMI|None|Zhelun Shen et al.|
|**2023-07-27**|**[The RoboDepth Challenge: Methods and Advancements Towards Robust Depth Estimation](https://arxiv.org/abs/2307.15061)**|Technical Report; 65 pages, 34 figures, 24 tables; Code at https://github.com/ldkong1205/RoboDepth|None|Lingdong Kong et al.|
|**2023-07-27**|**[Learning Depth Estimation for Transparent and Mirror Surfaces](https://arxiv.org/abs/2307.15052)**|Accepted at ICCV 2023. Project Page: https://cvlab-unibo.github.io/Depth4ToM|None|Alex Costanzino et al.|
|**2023-07-27**|**[Towards Deeply Unified Depth-aware Panoptic Segmentation with Bi-directional Guidance Learning](https://arxiv.org/abs/2307.14786)**|to be published in ICCV 2023|None|Junwen He et al.|
|**2023-07-27**|**[FS-Depth: Focal-and-Scale Depth Estimation from a Single Image in Unseen Indoor Scene](https://arxiv.org/abs/2307.14624)**|None|None|Chengrui Wei et al.|
|**2023-07-27**|**[NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection](https://arxiv.org/abs/2307.14620)**|Accepted by ICCV 2023|None|Chenfeng Xu et al.|
|**2023-07-26**|**[MiDaS v3.1 -- A Model Zoo for Robust Monocular Relative Depth Estimation](https://arxiv.org/abs/2307.14460)**|14 pages, 2 figures|None|Reiner Birkl et al.|
|**2023-07-26**|**[MAMo: Leveraging Memory and Attention for Monocular Video Depth Estimation](https://arxiv.org/abs/2307.14336)**|Accepted at ICCV 2023|None|Rajeev Yasarla et al.|
|**2023-07-25**|**[PlaneRecTR++: Unified Query Learning for Joint 3D Planar Reconstruction and Pose Estimation](https://arxiv.org/abs/2307.13756)**|Journal extension of our ICCV 2023 paper "PlaneRecTR", which expands from single view reconstruction to simultaneous multi-view reconstruction and camera pose estimation. Note that the ICCV23 PlaneRecTR paper could be found in the previous arxiv version [v2](arXiv:2307.13756v2)|None|Jingjia Shi et al.|
|**2023-07-24**|**[LiDAR Meta Depth Completion](https://arxiv.org/abs/2307.12761)**|Accepted at IROS 2023, v2 has updated author list and fixed a figure caption|None|Wolfgang Boettcher et al.|
|**2023-07-23**|**[FDCT: Fast Depth Completion for Transparent Objects](https://arxiv.org/abs/2307.12274)**|9pages,7figures|IEEE Robotics and Automation Letters (RA-L), 2023|Tianan Li et al.|
|**2023-07-20**|**[Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image](https://arxiv.org/abs/2307.10984)**|Accepted to ICCV 2023. Won the championship in the 2nd Monocular Depth Estimation Challenge. The code is available at https://github.com/YvanYin/Metric3D|None|Wei Yin et al.|
|**2023-07-20**|**[OCTraN: 3D Occupancy Convolutional Transformer Network in Unstructured Traffic Scenarios](https://arxiv.org/abs/2307.10934)**|This work was accepted as a spotlight presentation at the Transformers for Vision Workshop @CVPR 2023|None|Aditya Nalgunda Ganesh et al.|
|**2023-07-20**|**[Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV](https://arxiv.org/abs/2307.10713)**|Accepted to ICCV2023|None|Jaime Spencer et al.|
|**2023-07-19**|**[Measuring and Modeling Uncertainty Degree for Monocular Depth Estimation](https://arxiv.org/abs/2307.09929)**|None|None|Mochu Xiang et al.|
|**2023-07-17**|**[NVDS+: Towards Efficient and Versatile Neural Stabilizer for Video Depth Estimation](https://arxiv.org/abs/2307.08695)**|V1/V2: ICCV 2023 accepted; V3: the journal extension accepted by IEEE TPAMI 2024|None|Yiran Wang et al.|
|**2023-07-17**|**[Self-supervised Monocular Depth Estimation: Let's Talk About The Weather](https://arxiv.org/abs/2307.08357)**|ICCV'23|None|Kieran Saunders et al.|
|**2023-07-17**|**[On Point Affiliation in Feature Upsampling](https://arxiv.org/abs/2307.08198)**|17 pages. Extended version of NeurIPS 2022 paper "SAPA: Similarity-Aware Point Affiliation for Feature Upsampling" at arXiv:2209.12866v1. arXiv admin note: text overlap with arXiv:2209.12866|None|Wenze Liu et al.|
|**2023-07-16**|**[Multi-Object Discovery by Low-Dimensional Object Motion](https://arxiv.org/abs/2307.08027)**|ICCV 2023|None|Sadra Safadoust, Fatma Güney|
|**2023-07-16**|**[RayMVSNet++: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo](https://arxiv.org/abs/2307.10233)**|IEEE Transactions on Pattern Analysis and Machine Intelligence. arXiv admin note: substantial text overlap with arXiv:2204.01320|None|Yifei Shi et al.|
|**2023-07-11**|**[DFR: Depth from Rotation by Uncalibrated Image Rectification with Latitudinal Motion Assumption](https://arxiv.org/abs/2307.05129)**|None|None|Yongcong Zhang et al.|
|**2023-07-09**|**[TransPose: A Transformer-based 6D Object Pose Estimation Network with Depth Refinement](https://arxiv.org/abs/2307.05561)**|None|None|Mahmoud Abdulsalam, Nabil Aouf|
|**2023-07-07**|**[Depth Estimation Analysis of Orthogonally Divergent Fisheye Cameras with Distortion Removal](https://arxiv.org/abs/2307.03602)**|None|None|Matvei Panteleev, Houari Bettahar|
|**2023-07-05**|**[SVDM: Single-View Diffusion Model for Pseudo-Stereo 3D Object Detection](https://arxiv.org/abs/2307.02270)**|arXiv admin note: text overlap with arXiv:2203.02112, arXiv:2303.01469 by other authors|None|Yuguang Shi|
|**2023-07-04**|**[Consistent Multimodal Generation via A Unified GAN Framework](https://arxiv.org/abs/2307.01425)**|In review|None|Zhen Zhu et al.|
|**2023-06-30**|**[FlipNeRF: Flipped Reflection Rays for Few-shot Novel View Synthesis](https://arxiv.org/abs/2306.17723)**|ICCV 2023. Project Page: https://shawn615.github.io/flipnerf/|None|Seunghyeon Seo et al.|
|**2023-06-29**|**[Towards Zero-Shot Scale-Aware Monocular Depth Estimation](https://arxiv.org/abs/2306.17253)**|Project page: https://sites.google.com/view/tri-zerodepth|None|Vitor Guizilini et al.|
|**2023-06-27**|**[MIMIC: Masked Image Modeling with Image Correspondences](https://arxiv.org/abs/2306.15128)**|None|None|Kalyani Marathe et al.|
|**2023-06-26**|**[Learnable Differencing Center for Nighttime Depth Perception](https://arxiv.org/abs/2306.14538)**|8 pages|None|Zhiqiang Yan et al.|
|**2023-06-22**|**[Continuous Online Extrinsic Calibration of Fisheye Camera and LiDAR](https://arxiv.org/abs/2306.13240)**|4 pages|None|Jack Borer et al.|
|**2023-06-20**|**[Self-supervised Multi-task Learning Framework for Safety and Health-Oriented Connected Driving Environment Perception using Onboard Camera](https://arxiv.org/abs/2306.11822)**|None|None|Shaocheng Jia, Wei Yao|
|**2023-06-20**|**[BEVScope: Enhancing Self-Supervised Depth Estimation Leveraging Bird's-Eye-View in Dynamic Scenarios](https://arxiv.org/abs/2306.11598)**|None|None|Yucheng Mao et al.|
|**2023-06-20**|**[Depth and DOF Cues Make A Better Defocus Blur Detector](https://arxiv.org/abs/2306.11334)**|Code: https://github.com/yuxinjin-whu/D-DFFNet|None|Yuxin Jin et al.|
|**2023-06-19**|**[Tame a Wild Camera: In-the-Wild Monocular Camera Calibration](https://arxiv.org/abs/2306.10988)**|None|NeurIPS 2023|Shengjie Zhu et al.|
|**2023-06-19**|**[Understanding Depth Map Progressively: Adaptive Distance Interval Separation for Monocular 3d Object Detection](https://arxiv.org/abs/2306.10921)**|None|None|Xianhui Cheng et al.|
|**2023-06-16**|**[C2F2NeUS: Cascade Cost Frustum Fusion for High Fidelity and Generalizable Neural Surface Reconstruction](https://arxiv.org/abs/2306.10003)**|Accepted by ICCV2023|None|Luoyuan Xu et al.|
|**2023-06-14**|**[Predict to Detect: Prediction-guided 3D Object Detection using Sequential Images](https://arxiv.org/abs/2306.08528)**|ICCV 2023, Code: https://github.com/sanmin0312/P2D|None|Sanmin Kim et al.|
|**2023-06-09**|**[Lightweight Monocular Depth Estimation via Token-Sharing Transformer](https://arxiv.org/abs/2306.05682)**|ICRA 2023|None|Dong-Jae Lee et al.|
|**2023-06-08**|**[Tracking Objects with 3D Representation from Videos](https://arxiv.org/abs/2306.05416)**|Technical report|None|Jiawei He et al.|
|**2023-06-08**|**[SparseTrack: Multi-Object Tracking by Performing Scene Decomposition based on Pseudo-Depth](https://arxiv.org/abs/2306.05238)**|12 pages, 8 figures|None|Zelin Liu et al.|
|**2023-06-08**|**[A Dynamic Feature Interaction Framework for Multi-task Visual Perception](https://arxiv.org/abs/2306.05061)**|Accepted by International Journal of Computer Vision. arXiv admin note: text overlap with arXiv:2011.09796|None|Yuling Xi et al.|
|**2023-06-05**|**[Single-Stage 3D Geometry-Preserving Depth Estimation Model Training on Dataset Mixtures with Uncalibrated Stereo Data](https://arxiv.org/abs/2306.02878)**|None|CVPR 2022|Nikolay Patakin et al.|
|**2023-06-02**|**[Towards In-context Scene Understanding](https://arxiv.org/abs/2306.01667)**|None|None|Ivana Balažević et al.|
|**2023-06-02**|**[PanoGRF: Generalizable Spherical Radiance Fields for Wide-baseline Panoramas](https://arxiv.org/abs/2306.01531)**|accepted to NeurIPS2023; Project Page: https://thucz.github.io/PanoGRF/|None|Zheng Chen et al.|
|**2023-05-31**|**[A technique to jointly estimate depth and depth uncertainty for unmanned aerial vehicles](https://arxiv.org/abs/2305.19780)**|The code is available at https://github.com/michael-fonder/M4DepthU|None|Michaël Fonder, Marc Van Droogenbroeck|
|**2023-05-30**|**[DaRF: Boosting Radiance Fields from Sparse Inputs with Monocular Depth Adaptation](https://arxiv.org/abs/2305.19201)**|To appear at NeurIPS 2023. Project Page: https://ku-cvlab.github.io/DaRF/|None|Jiuhn Song et al.|
|**2023-05-30**|**[Independent Component Alignment for Multi-Task Learning](https://arxiv.org/abs/2305.19000)**|None|CVPR2023|Dmitry Senushkin et al.|
|**2023-05-30**|**[HQDec: Self-Supervised Monocular Depth Estimation Based on a High-Quality Decoder](https://arxiv.org/abs/2305.18706)**|None|None|Fei Wang, Jun Cheng|
|**2023-05-28**|**[OccCasNet: Occlusion-aware Cascade Cost Volume for Light Field Depth Estimation](https://arxiv.org/abs/2305.17710)**|None|None|Wentao Chao et al.|
|**2023-05-27**|**[USIM-DAL: Uncertainty-aware Statistical Image Modeling-based Dense Active Learning for Super-resolution](https://arxiv.org/abs/2305.17520)**|Accepted at UAI 2023|None|Vikrant Rangnekar et al.|
|**2023-05-25**|**[SimHaze: game engine simulated data for real-world dehazing](https://arxiv.org/abs/2305.16481)**|Submitted to ICIP 2023|None|Zhengyang Lou et al.|
|**2023-05-25**|**[Learning Occupancy for Monocular 3D Object Detection](https://arxiv.org/abs/2305.15694)**|None|None|Liang Peng et al.|
|**2023-05-24**|**[Polarimetric Imaging for Perception](https://arxiv.org/abs/2305.14787)**|None|None|Michael Baltaxe et al.|
|**2023-05-24**|**[AutoDepthNet: High Frame Rate Depth Map Reconstruction using Commodity Depth and RGB Cameras](https://arxiv.org/abs/2305.14731)**|None|None|Peyman Gholami, Robert Xiao|
|**2023-05-22**|**[FEDORA: Flying Event Dataset fOr Reactive behAvior](https://arxiv.org/abs/2305.14392)**|Published in the Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2024|2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 5859-5866|Amogh Joshi et al.|
|**2023-05-22**|**[Gated Stereo: Joint Depth Estimation from Gated and Wide-Baseline Active Stereo Cues](https://arxiv.org/abs/2305.12955)**|None|None|Stefanie Walz et al.|
|**2023-05-19**|**[Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields](https://arxiv.org/abs/2305.11588)**|Accepted by TVCG; Homepage: https://eckertzhang.github.io/Text2NeRF.github.io/ Code:https://github.com/eckertzhang/Text2NeRF|None|Jingbo Zhang et al.|
|**2023-05-19**|**[Brain Captioning: Decoding human brain activity into images and text](https://arxiv.org/abs/2305.11560)**|None|None|Matteo Ferrante et al.|
|**2023-05-16**|**[PanelNet: Understanding 360 Indoor Environment via Panel Representation](https://arxiv.org/abs/2305.09078)**|To appear in CVPR 2023|None|Haozheng Yu et al.|
|**2023-05-13**|**[MetaMorphosis: Task-oriented Privacy Cognizant Feature Generation for Multi-task Learning](https://arxiv.org/abs/2305.07815)**|Preprint version, 22 pages. Keywords: Multi-task learning, neural networks, collaborative intelligence, differential privacy, task privacy|None|Md Adnan Arefeen et al.|
|**2023-05-12**|**[Learning Monocular Depth in Dynamic Environment via Context-aware Temporal Attention](https://arxiv.org/abs/2305.07397)**|accepted by IJCAI 2023; 9 pages, 5 figures|None|Zizhang Wu et al.|
|**2023-05-11**|**[Virtual Occlusions Through Implicit Depth](https://arxiv.org/abs/2305.07014)**|Accepted to CVPR 2023|None|Jamie Watson et al.|
|**2023-05-10**|**[A Multi-modal Approach to Single-modal Visual Place Classification](https://arxiv.org/abs/2305.06179)**|7 pages, 6 figures, 1 table|None|Tomoya Iwasaki et al.|
|**2023-05-10**|**[FusionDepth: Complement Self-Supervised Monocular Depth Estimation with Cost Volume](https://arxiv.org/abs/2305.06036)**|None|None|Zhuofei Huang et al.|
|**2023-05-08**|**[Improving 2D face recognition via fine-level facial depth generation and RGB-D complementary feature learning](https://arxiv.org/abs/2305.04426)**|None|None|Wenhao Hu|
|**2023-05-04**|**[Edge-aware Consistent Stereo Video Depth Estimation](https://arxiv.org/abs/2305.02645)**|None|None|Elena Kosheleva et al.|
|**2023-05-02**|**[High-Resolution Synthetic RGB-D Datasets for Monocular Depth Estimation](https://arxiv.org/abs/2305.01732)**|None|None|Aakash Rajpal et al.|
|**2023-05-02**|**[AutoColor: Learned Light Power Control for Multi-Color Holograms](https://arxiv.org/abs/2305.01611)**|6 pages, 2 figures, SPIE VR|AR|MR 2024|None|Yicheng Zhan et al.|
|**2023-04-28**|**[ViP-NeRF: Visibility Prior for Sparse Input Neural Radiance Fields](https://arxiv.org/abs/2305.00041)**|SIGGRAPH 2023|ACM SIGGRAPH 2023 Conference Proceedings, Article 71, Pages 1-11|Nagabhushan Somraj, Rajiv Soundararajan|
|**2023-04-25**|**[Depth-Relative Self Attention for Monocular Depth Estimation](https://arxiv.org/abs/2304.12849)**|Accepted for IJCAI 2023|None|Kyuhong Shim et al.|
|**2023-04-25**|**[Exploring the Mutual Influence between Self-Supervised Single-Frame and Multi-Frame Depth Estimation](https://arxiv.org/abs/2304.12685)**|Accepted for publication in the IEEE Robotics and Automation Letters (RA-L). 8 pages, 3figures|None|Jie Xiang et al.|
|**2023-04-22**|**[Dehazing-NeRF: Neural Radiance Fields from Hazy Images](https://arxiv.org/abs/2304.11448)**|None|None|Tian Li et al.|
|**2023-04-20**|**[A geometry-aware deep network for depth estimation in monocular endoscopy](https://arxiv.org/abs/2304.10241)**|None|None|Yongming Yang et al.|
|**2023-04-19**|**[CrossFusion: Interleaving Cross-modal Complementation for Noise-resistant 3D Object Detection](https://arxiv.org/abs/2304.09694)**|None|None|Yang Yang et al.|
|**2023-04-19**|**[DarSwin: Distortion Aware Radial Swin Transformer](https://arxiv.org/abs/2304.09691)**|18 pages, 12 figures|None|Akshaya Athwale et al.|
|**2023-04-19**|**[Reference-guided Controllable Inpainting of Neural Radiance Fields](https://arxiv.org/abs/2304.09677)**|Project Page: https://ashmrz.github.io/reference-guided-3d|None|Ashkan Mirzaei et al.|
|**2023-04-18**|**[Learning to Fuse Monocular and Multi-view Cues for Multi-frame Depth Estimation in Dynamic Scenes](https://arxiv.org/abs/2304.08993)**|Accepted by CVPR 2023. Code and models are available at: https://github.com/ruili3/dynamic-multiframe-depth|None|Rui Li et al.|
|**2023-04-18**|**[Pose Constraints for Consistent Self-supervised Monocular Depth and Ego-motion](https://arxiv.org/abs/2304.08916)**|Scandinavian Conference on Image Analysis (SCIA) 2023|None|Zeeshan Khan Suri|
|**2023-04-17**|**[360$^\circ$ High-Resolution Depth Estimation via Uncertainty-aware Structural Knowledge Transfer](https://arxiv.org/abs/2304.07967)**|10 pages|None|Zidong Cao et al.|
|**2023-04-16**|**[EGformer: Equirectangular Geometry-biased Transformer for 360 Depth Estimation](https://arxiv.org/abs/2304.07803)**|12 pages, Accepted to ICCV23, Camera ready version|None|Ilwi Yun et al.|
|**2023-04-15**|**[Temporally Consistent Online Depth Estimation Using Point-Based Fusion](https://arxiv.org/abs/2304.07435)**|Source code: https://github.com/facebookresearch/TemporallyConsistentDepth|CVPR 2023|Numair Khan et al.|
|**2023-04-14**|**[The Second Monocular Depth Estimation Challenge](https://arxiv.org/abs/2304.07051)**|Published at CVPRW2023|None|Jaime Spencer et al.|
|**2023-04-14**|**[Self-Supervised Learning based Depth Estimation from Monocular Images](https://arxiv.org/abs/2304.06966)**|None|None|Mayank Poddar et al.|
|**2023-04-13**|**[Event-based tracking of human hands](https://arxiv.org/abs/2304.06534)**|None|Sensor Review, Vol. 41 No. 4, pp. 382-389 (2021)|Laura Duarte et al.|
|**2023-04-13**|**[iDisc: Internal Discretization for Monocular Depth Estimation](https://arxiv.org/abs/2304.06334)**|Accepted at CVPR 2023|None|Luigi Piccinelli et al.|
|**2023-04-11**|**[Improving Neural Radiance Fields with Depth-aware Optimization for Novel View Synthesis](https://arxiv.org/abs/2304.05218)**|None|None|Shu Chen et al.|
|**2023-04-07**|**[DualRefine: Self-Supervised Depth and Pose Estimation Through Iterative Epipolar Sampling and Refinement Toward Equilibrium](https://arxiv.org/abs/2304.03560)**|CVPR 2023. Project page: https://antabangun.github.io/projects/DualRefine/ Code: https://github.com/antabangun/DualRefine|None|Antyanta Bangunharcana et al.|
|**2023-04-06**|**[EGA-Depth: Efficient Guided Attention for Self-Supervised Multi-Camera Depth Estimation](https://arxiv.org/abs/2304.03369)**|CVPR 2023 Workshop on Autonomous Driving|None|Yunxiao Shi et al.|
|**2023-04-06**|**[DeLiRa: Self-Supervised Depth, Light, and Radiance Fields](https://arxiv.org/abs/2304.02797)**|Project page: https://sites.google.com/view/tri-delira|None|Vitor Guizilini et al.|
|**2023-04-05**|**[DEFLOW: Self-supervised 3D Motion Estimation of Debris Flow](https://arxiv.org/abs/2304.02569)**|Photogrammetric Computer Vision Workshop, CVPRW 2023, camera ready|None|Liyuan Zhu et al.|
|**2023-04-04**|**[FineRecon: Depth-aware Feed-forward Network for Detailed 3D Reconstruction](https://arxiv.org/abs/2304.01480)**|ICCV 2023|None|Noah Stier et al.|
|**2023-04-03**|**[Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation](https://arxiv.org/abs/2304.00971)**|A supplementary document for "TaskPrompter: Spatial-Channel Multi-Task Prompting for Dense Scene Understanding" accepted by ICLR 2023. Project page: https://github.com/prismformore/Multi-Task-Transformer/tree/main/TaskPrompter|ICLR 2023|Hanrong Ye, Dan Xu|
|**2023-04-02**|**[altiro3D: Scene representation from single image and novel view synthesis](https://arxiv.org/abs/2304.11161)**|In press (2023) Springer International Journal of Information Technology (IJIT) 10 pages, 3 figures|None|E. Canessa, L. Tenze|
|**2023-03-31**|**[SemHint-MD: Learning from Noisy Semantic Labels for Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2303.18219)**|None|None|Shan Lin et al.|
|**2023-03-31**|**[Single Image Depth Prediction Made Better: A Multivariate Gaussian Take](https://arxiv.org/abs/2303.18164)**|Accepted to IEEE/CVF CVPR 2023. Draft info: 17 pages, 13 Figures, 9 Tables|None|Ce Liu et al.|
|**2023-03-31**|**[3D-aware Image Generation using 2D Diffusion Models](https://arxiv.org/abs/2303.17905)**|Website: https://jeffreyxiang.github.io/ivid/|None|Jianfeng Xiang et al.|
|**2023-03-31**|**[EA-LSS: Edge-aware Lift-splat-shot Framework for 3D BEV Object Detection](https://arxiv.org/abs/2303.17895)**|None|None|Haotian Hu et al.|
|**2023-03-31**|**[Joint Depth Estimation and Mixture of Rain Removal From a Single Image](https://arxiv.org/abs/2303.17766)**|11 pages, 7 figures, 5 tables|None|Yongzhen Wang et al.|
|**2023-03-30**|**[TiDy-PSFs: Computational Imaging with Time-Averaged Dynamic Point-Spread-Functions](https://arxiv.org/abs/2303.17583)**|13 pages, 16 figures|None|Sachin Shah et al.|
|**2023-03-30**|**[DDP: Diffusion Model for Dense Visual Prediction](https://arxiv.org/abs/2303.17559)**|Added controlnet exp|None|Yuanfeng Ji et al.|
|**2023-03-29**|**[An intelligent modular real-time vision-based system for environment perception](https://arxiv.org/abs/2303.16710)**|Accepted in NeurIPS 2022 Workshop on Machine Learning for Autonomous Driving|None|Amirhossein Kazerouni et al.|
|**2023-03-29**|**[DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object Detection and Tracking](https://arxiv.org/abs/2303.16628)**|None|None|Qing Lian et al.|
|**2023-03-28**|**[4K-HAZE: A Dehazing Benchmark with 4K Resolution Hazy and Haze-Free Images](https://arxiv.org/abs/2303.15848)**|None|None|Zhuoran Zheng, Xiuyi Jia|
|**2023-03-26**|**[On the Importance of Accurate Geometry Data for Dense 3D Vision Tasks](https://arxiv.org/abs/2303.14840)**|Accepted at CVPR 2023, Main Paper + Supp. Mat. arXiv admin note: substantial text overlap with arXiv:2205.04565|None|HyunJun Jung et al.|
|**2023-03-26**|**[Multi-Frame Self-Supervised Depth Estimation with Multi-Scale Feature Fusion in Dynamic Scenes](https://arxiv.org/abs/2303.14628)**|11 pages, 8 figures, ACM MM'23 accepted|None|Jiquan Zhong et al.|
|**2023-03-23**|**[SCADE: NeRFs from Space Carving with Ambiguity-Aware Depth Estimates](https://arxiv.org/abs/2303.13582)**|CVPR 2023|None|Mikaela Angelina Uy et al.|
|**2023-03-23**|**[Collaboration Helps Camera Overtake LiDAR in 3D Detection](https://arxiv.org/abs/2303.13560)**|Accepted by CVPR23|None|Yue Hu et al.|
|**2023-03-22**|**[LFM-3D: Learnable Feature Matching Across Wide Baselines Using 3D Signals](https://arxiv.org/abs/2303.12779)**|3DV 2024, oral paper|None|Arjun Karpur et al.|
|**2023-03-21**|**[Monocular Visual-Inertial Depth Estimation](https://arxiv.org/abs/2303.12134)**|Accepted for publication at ICRA'23|None|Diana Wofk et al.|
|**2023-03-21**|**[Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models](https://arxiv.org/abs/2303.11989)**|Accepted to ICCV 2023 (Oral) video: https://youtu.be/fjRnFL91EZc project page: https://lukashoel.github.io/text-to-room/ code: https://github.com/lukasHoel/text2room|None|Lukas Höllein et al.|
|**2023-03-21**|**[HRDFuse: Monocular 360°Depth Estimation by Collaboratively Learning Holistic-with-Regional Depth Distributions](https://arxiv.org/abs/2303.11616)**|To appear at CVPR2023, 20 pages|None|Hao Ai et al.|
|**2023-03-20**|**[Versatile Depth Estimator Based on Common Relative Depth Estimation and Camera-Specific Relative-to-Metric Depth Conversion](https://arxiv.org/abs/2303.10991)**|None|None|Jinyoung Jun et al.|
|**2023-03-20**|**[Boosting Weakly Supervised Object Detection using Fusion and Priors from Hallucinated Depth](https://arxiv.org/abs/2303.10937)**|None|None|Cagri Gungor, Adriana Kovashka|
|**2023-03-17**|**[Spectrum-inspired Low-light Image Translation for Saliency Detection](https://arxiv.org/abs/2303.10145)**|Presented at The Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP) 2022|None|Kitty Varghese et al.|
|**2023-03-17**|**[A Simple Framework for 3D Occupancy Estimation in Autonomous Driving](https://arxiv.org/abs/2303.10076)**|15 pages, 8 figures|None|Wanshui Gan et al.|
|**2023-03-17**|**[Exploring Sparse Visual Prompt for Domain Adaptive Dense Prediction](https://arxiv.org/abs/2303.09792)**|Accepted by AAAI 2024|None|Senqiao Yang et al.|
|**2023-03-14**|**[A Simple Baseline for Supervised Surround-view Depth Estimation](https://arxiv.org/abs/2303.07759)**|None|None|Xianda Guo et al.|
|**2023-03-14**|**[Do More With What You Have: Transferring Depth-Scale from Labeled to Unlabeled Domains](https://arxiv.org/abs/2303.07662)**|None|None|Alexandra Dana et al.|
|**2023-03-13**|**[DEHRFormer: Real-time Transformer for Depth Estimation and Haze Removal from Varicolored Haze Scenes](https://arxiv.org/abs/2303.06905)**|Accepted to ICASSP'2023|None|Sixiang Chen et al.|
|**2023-03-09**|**[DiffusionDepth: Diffusion Denoising Approach for Monocular Depth Estimation](https://arxiv.org/abs/2303.05021)**|None|None|Yiqun Duan et al.|
|**2023-03-08**|**[Aberration-Aware Depth-from-Focus](https://arxiv.org/abs/2303.04654)**|[ICCP & TPAMI 2023] Considering optical aberrations during network training can improve the generalizability|None|Xinge Yang et al.|
|**2023-03-08**|**[RM-Depth: Unsupervised Learning of Recurrent Monocular Depth in Dynamic Scenes](https://arxiv.org/abs/2303.04456)**|Accepted to CVPR 2022 (paper is updated)|None|Tak-Wai Hui|
|**2023-03-06**|**[DwinFormer: Dual Window Transformers for End-to-End Monocular Depth Estimation](https://arxiv.org/abs/2303.02968)**|None|IEEE Sensors Journal (Volume: 23, Issue: 18, 15 September 2023)|Md Awsafur Rahman, Shaikh Anowarul Fattah|
|**2023-03-03**|**[Unleashing Text-to-Image Diffusion Models for Visual Perception](https://arxiv.org/abs/2303.02153)**|project page: https://vpd.ivg-research.xyz|None|Wenliang Zhao et al.|
|**2023-03-03**|**[Towards Domain Generalization for Multi-view 3D Object Detection in Bird-Eye-View](https://arxiv.org/abs/2303.01686)**|Accepted to CVPR 2023|None|Shuo Wang et al.|
|**2023-03-02**|**[DejaVu: Conditional Regenerative Learning to Enhance Dense Prediction](https://arxiv.org/abs/2303.01573)**|Accepted to CVPR 2023|None|Shubhankar Borse et al.|
|**2023-03-02**|**[3D generation on ImageNet](https://arxiv.org/abs/2303.01416)**|ICLR 2023 (Oral)|ICLR 2023|Ivan Skorokhodov et al.|
|**2023-03-02**|**[APARATE: Adaptive Adversarial Patch for CNN-based Monocular Depth Estimation for Autonomous Navigation](https://arxiv.org/abs/2303.01351)**|None|None|Amira Guesmi et al.|
|**2023-03-02**|**[I2P-Rec: Recognizing Images on Large-scale Point Cloud Maps through Bird's Eye View Projections](https://arxiv.org/abs/2303.01043)**|Accepted by IROS 2023|None|Shuhang Zheng et al.|
|**2023-02-28**|**[Monocular Depth Estimation using Diffusion Models](https://arxiv.org/abs/2302.14816)**|None|None|Saurabh Saxena et al.|
|**2023-02-25**|**[SUPS: A Simulated Underground Parking Scenario Dataset for Autonomous Driving](https://arxiv.org/abs/2302.12966)**|Accepted for publication at the 25th IEEE Intelligent Transportation Systems Conference (ITSC 2022)|None|Jiawei Hou et al.|
|**2023-02-23**|**[ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth](https://arxiv.org/abs/2302.12288)**|None|None|Shariq Farooq Bhat et al.|
|**2023-02-23**|**[VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion](https://arxiv.org/abs/2302.12251)**|CVPR 2023 Highlight (10% of accepted papers, 2.5% of submissions)|None|Yiming Li et al.|
|**2023-02-21**|**[Bokeh Rendering Based on Adaptive Depth Calibration Network](https://arxiv.org/abs/2302.10808)**|6 pages, 6 figures|None|Lu Liu et al.|
|**2023-02-21**|**[Learning 3D Photography Videos via Self-supervised Diffusion on Single Images](https://arxiv.org/abs/2302.10781)**|10 pages, 7 figures|None|Xiaodong Wang et al.|
|**2023-02-21**|**[Depth Estimation and Image Restoration by Deep Learning from Defocused Images](https://arxiv.org/abs/2302.10730)**|None|IEEE Transactions on Computational Imaging, vol. 9, pp. 607-619, 2023|Saqib Nazir et al.|
|**2023-02-21**|**[MonoPGC: Monocular 3D Object Detection with Pixel Geometry Contexts](https://arxiv.org/abs/2302.10549)**|Accepted by ICRA 2023|None|Zizhang Wu et al.|
|**2023-02-20**|**[On the Metrics for Evaluating Monocular Depth Estimation](https://arxiv.org/abs/2302.10007)**|11 pages, 8 figures|None|Akhil Gurram, Antonio M. Lopez|
|**2023-02-20**|**[GlocalFuse-Depth: Fusing Transformers and CNNs for All-day Self-supervised Monocular Depth Estimation](https://arxiv.org/abs/2302.09884)**|None|None|Zezheng Zhang et al.|
|**2023-02-20**|**[Self-Supervised Monocular Depth Estimation with Self-Reference Distillation and Disparity Offset Refinement](https://arxiv.org/abs/2302.09789)**|None|None|Zhong Liu et al.|
|**2023-02-17**|**[Long Range Object-Level Monocular Depth Estimation for UAVs](https://arxiv.org/abs/2302.08943)**|16 pages, SCIA 2023|None|David Silva et al.|
|**2023-02-17**|**[MixNeRF: Modeling a Ray with Mixture Density for Novel View Synthesis from Sparse Inputs](https://arxiv.org/abs/2302.08788)**|CVPR 2023. Project Page: https://shawn615.github.io/mixnerf/|None|Seunghyeon Seo et al.|
|**2023-02-16**|**[URCDC-Depth: Uncertainty Rectified Cross-Distillation with CutFlip for Monocular Depth Estimation](https://arxiv.org/abs/2302.08149)**|9 pages|None|Shuwei Shao et al.|
|**2023-02-16**|**[Spectral 3D Computer Vision -- A Review](https://arxiv.org/abs/2302.08054)**|None|None|Yajie Sun et al.|
|**2023-02-08**|**[SkyEye: Self-Supervised Bird's-Eye-View Semantic Mapping Using Monocular Frontal View Images](https://arxiv.org/abs/2302.04233)**|14 pages, 7 figures|None|Nikhil Gosala et al.|
|**2023-02-08**|**[EVEN: An Event-Based Framework for Monocular Depth Estimation at Adverse Night Conditions](https://arxiv.org/abs/2302.03860)**|None|None|Peilun Shi et al.|
|**2023-02-06**|**[Structure and Content-Guided Video Synthesis with Diffusion Models](https://arxiv.org/abs/2302.03011)**|Project page at https://research.runwayml.com/gen1|None|Patrick Esser et al.|
|**2023-02-05**|**[A Disparity Refinement Framework for Learning-based Stereo Matching Methods in Cross-domain Setting for Laparoscopic Images](https://arxiv.org/abs/2302.02294)**|None|None|Zixin Yang et al.|
|**2023-02-02**|**[STEPS: Joint Self-supervised Nighttime Image Enhancement and Depth Estimation](https://arxiv.org/abs/2302.01334)**|Accepted by ICRA 2023, Code: https://github.com/ucaszyp/STEPS|None|Yupeng Zheng et al.|
|**2023-02-01**|**[Uncertainty-Driven Dense Two-View Structure from Motion](https://arxiv.org/abs/2302.00523)**|Accepted for publication at IEEE Robotics and Automation Letters (RA-L) 2023|None|Weirong Chen et al.|
|**2023-01-31**|**[Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks](https://arxiv.org/abs/2301.13487)**|Initially accepted at ICLR2023 (Spotlight)|None|Zhiyuan Cheng et al.|
|**2023-01-31**|**[Recurrent Structure Attention Guidance for Depth Super-Resolution](https://arxiv.org/abs/2301.13419)**|Accepted by AAAI-2023|None|Jiayi Yuan et al.|
|**2023-01-30**|**[AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio](https://arxiv.org/abs/2301.12613)**|Accepted by Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)|None|Xiaoyang Huang et al.|
|**2023-01-26**|**[Learning Good Features to Transfer Across Tasks and Domains](https://arxiv.org/abs/2301.11310)**|Extended version of the paper "Learning Across Tasks and Domains" presented at ICCV 2019. Accepted at TPAMI|None|Pierluigi Zama Ramirez et al.|
|**2023-01-25**|**[On the Adversarial Robustness of Camera-based 3D Object Detection](https://arxiv.org/abs/2301.10766)**|Transactions on Machine Learning Research, 2024. ISSN 2835-8856|None|Shaoyuan Xie et al.|
|**2023-01-20**|**[Unsupervised Light Field Depth Estimation via Multi-view Feature Matching with Occlusion Prediction](https://arxiv.org/abs/2301.08433)**|None|None|Shansi Zhang et al.|
|**2023-01-20**|**[FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation](https://arxiv.org/abs/2301.08414)**|Accepted by ICRA2023|None|Junyu Zhu et al.|
|**2023-01-19**|**[Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces](https://arxiv.org/abs/2301.08245)**|Extension of the paper "Open Challenges in Deep Stereo: the Booster Dataset" presented at CVPR 2022. Accepted at TPAMI|None|Pierluigi Zama Ramirez et al.|
|**2023-01-17**|**[SwinDepth: Unsupervised Depth Estimation using Monocular Sequences via Swin Transformer and Densely Cascaded Network](https://arxiv.org/abs/2301.06715)**|ICRA 2023|None|Dongseok Shim, H. Jin Kim|
|**2023-01-14**|**[Dyna-DepthFormer: Multi-frame Transformer for Self-Supervised Depth Estimation in Dynamic Scenes](https://arxiv.org/abs/2301.05871)**|ICRA 2023|None|Songchun Zhang, Chunhui Zhao|
|**2023-01-14**|**[${S}^{2}$Net: Accurate Panorama Depth Estimation on Spherical Surface](https://arxiv.org/abs/2301.05845)**|Accepted by IEEE Robotics and Automation Letters|None|Meng Li et al.|
|**2023-01-09**|**[Deep Planar Parallax for Monocular Depth Estimation](https://arxiv.org/abs/2301.03178)**|None|None|Haoqian Liang et al.|
|**2023-01-09**|**[A Study on the Generality of Neural Network Structures for Monocular Depth Estimation](https://arxiv.org/abs/2301.03169)**|Accepted in TPAMI|None|Jinwoo Bae et al.|
|**2023-01-05**|**[All in Tokens: Unifying Output Space of Visual Tasks via Soft Token](https://arxiv.org/abs/2301.02229)**|None|None|Jia Ning et al.|
|**2023-01-05**|**[DepthP+P: Metric Accurate Monocular Depth Estimation using Planar and Parallax](https://arxiv.org/abs/2301.02092)**|None|None|Sadra Safadoust, Fatma Güney|
|**2023-01-03**|**[BS3D: Building-scale 3D Reconstruction from RGB-D Images](https://arxiv.org/abs/2301.01057)**|None|None|Janne Mustaniemi et al.|
|**2022-12-29**|**[Learning 3D Human Pose Estimation from Dozens of Datasets using a Geometry-Aware Autoencoder to Bridge Between Skeleton Formats](https://arxiv.org/abs/2212.14474)**|Accepted at the 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV'23)|None|István Sárándi et al.|
|**2022-12-24**|**[HandsOff: Labeled Dataset Generation With No Additional Human Annotations](https://arxiv.org/abs/2212.12645)**|22 pages, 20 figures. CVPR 2023|None|Austin Xu et al.|
|**2022-12-22**|**[Depth Estimation maps of lidar and stereo images](https://arxiv.org/abs/2212.11741)**|10 pages, 13 figures|None|Fei Wu, Luoyu Chen|
|**2022-12-22**|**[Vision-Based Environmental Perception for Autonomous Driving](https://arxiv.org/abs/2212.11453)**|39 pages, 17 figures|None|Fei Liu et al.|
|**2022-12-21**|**[Lightweight Monocular Depth Estimation](https://arxiv.org/abs/2212.11363)**|None|None|Ruilin Ma et al.|
|**2022-12-21**|**[MaskingDepth: Masked Consistency Regularization for Semi-supervised Monocular Depth Estimation](https://arxiv.org/abs/2212.10806)**|Project page: https://ku-cvlab.github.io/MaskingDepth/|None|Jongbeom Baek et al.|
|**2022-12-20**|**[Scene-aware Egocentric 3D Human Pose Estimation](https://arxiv.org/abs/2212.11684)**|None|None|Jian Wang et al.|
|**2022-12-17**|**[Are We Ready for Vision-Centric Driving Streaming Perception? The ASAP Benchmark](https://arxiv.org/abs/2212.08914)**|code: https://github.com/JeffWang987/ASAP|None|Xiaofeng Wang et al.|
|**2022-12-17**|**[DAG: Depth-Aware Guidance with Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2212.08861)**|Project page is available at https://ku-cvlab.github.io/DAG/|None|Gyeongnyeon Kim et al.|
|**2022-12-15**|**[Solve the Puzzle of Instance Segmentation in Videos: A Weakly Supervised Framework with Spatio-Temporal Collaboration](https://arxiv.org/abs/2212.07592)**|None|IEEE Transactions on Circuits and Systems for Video Technology (2022)|Liqi Yan et al.|
|**2022-12-12**|**[Towards Practical Plug-and-Play Diffusion Models](https://arxiv.org/abs/2212.05973)**|CVPR 2023 camera-ready|None|Hyojun Go et al.|
|**2022-12-12**|**[ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2212.05729)**|Camera Ready for AAAI 2023|None|Daitao Xing et al.|
|**2022-12-10**|**[Mind The Edge: Refining Depth Edges in Sparsely-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2212.05315)**|Appears in CVPR24'|None|Lior Talker et al.|
|**2022-12-09**|**[Cross-Domain Synthetic-to-Real In-the-Wild Depth and Normal Estimation for 3D Scene Understanding](https://arxiv.org/abs/2212.05040)**|Accepted to OmniCV 2024|None|Jay Bhanushali et al.|
|**2022-12-09**|**[4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions](https://arxiv.org/abs/2212.04701)**|None|None|Zhongshu Wang et al.|
|**2022-12-06**|**[Event-based Monocular Dense Depth Estimation with Recurrent Transformers](https://arxiv.org/abs/2212.02791)**|10 pages, 5 figures|None|Xu Liu et al.|
|**2022-12-05**|**[DARF: Depth-Aware Generalizable Neural Radiance Field](https://arxiv.org/abs/2212.02280)**|None|None|Yue Shi et al.|
|**2022-12-04**|**[3D Object Aided Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2212.01768)**|None|None|Songlin Wei et al.|
|**2022-12-03**|**[Multi-resolution Monocular Depth Map Fusion by Self-supervised Gradient-based Composition](https://arxiv.org/abs/2212.01538)**|19 pages (with supplementary material)|None|Yaqiao Dai et al.|
|**2022-12-02**|**[Geometry-Aware Network for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2212.00920)**|AAAI 2023|None|Yinghong Liao et al.|
|**2022-12-01**|**[BEV-LGKD: A Unified LiDAR-Guided Knowledge Distillation Framework for BEV 3D Object Detection](https://arxiv.org/abs/2212.00623)**|12pages|None|Jianing Li et al.|
|**2022-11-30**|**[ObjCAViT: Improving Monocular Depth Estimation Using Natural Language Models And Image-Object Cross-Attention](https://arxiv.org/abs/2211.17232)**|9 pages, 4 figures. Code is released at https://github.com/DylanAuty/ObjCAViT|None|Dylan Auty, Krystian Mikolajczyk|
|**2022-11-30**|**[Weakly Supervised 3D Multi-person Pose Estimation for Large-scale Scenes based on Monocular Camera and Single LiDAR](https://arxiv.org/abs/2211.16951)**|Accepted by AAAI 2023|None|Peishan Cong et al.|
|**2022-11-30**|**[Attention-Based Depth Distillation with 3D-Aware Positional Encoding for Monocular 3D Object Detection](https://arxiv.org/abs/2211.16779)**|Accepted by AAAI2023|None|Zizhang Wu et al.|
|**2022-11-29**|**[NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with 360° Views](https://arxiv.org/abs/2211.16431)**|Project page: https://vita-group.github.io/NeuralLift-360/|None|Dejia Xu et al.|
|**2022-11-29**|**[Generalized Face Anti-Spoofing via Multi-Task Learning and One-Side Meta Triplet Loss](https://arxiv.org/abs/2211.15955)**|2023 IEEE International Conference on Automatic Face and Gesture Recognition (FG)|None|Chu-Chun Chuang et al.|
|**2022-11-28**|**[SuperFusion: Multilevel LiDAR-Camera Fusion for Long-Range HD Map Generation](https://arxiv.org/abs/2211.15656)**|ICRA 2024|None|Hao Dong et al.|
|**2022-11-25**|**[Copy-Pasting Coherent Depth Regions Improves Contrastive Learning for Urban-Scene Segmentation](https://arxiv.org/abs/2211.14074)**|BMVC 2022 Best Student Paper Award(Honourable Mention)|None|Liang Zeng et al.|
|**2022-11-23**|**[Lite-Mono: A Lightweight CNN and Transformer Architecture for Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2211.13202)**|Accepted to CVPR2023|None|Ning Zhang et al.|
|**2022-11-22**|**[Dynamic Depth-Supervised NeRF for Multi-View RGB-D Operating Room Images](https://arxiv.org/abs/2211.12436)**|Accepted to the Workshop on Ambient Intelligence for HealthCare 2023|None|Beerend G. A. Gerats et al.|
|**2022-11-22**|**[Event Transformer+. A multi-purpose solution for efficient event data processing](https://arxiv.org/abs/2211.12222)**|arXiv admin note: text overlap with arXiv:2204.03355|None|Alberto Sabater et al.|
|**2022-11-22**|**[The Monocular Depth Estimation Challenge](https://arxiv.org/abs/2211.12174)**|WACV-Workshops 2023|None|Jaime Spencer et al.|
|**2022-11-20**|**[Hybrid Transformer Based Feature Fusion for Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2211.11066)**|Presented at the Advances in Image Manipulation Workshop at ECCV 2022|None|Snehal Singh Tomar et al.|
|**2022-11-19**|**[A Practical Stereo Depth System for Smart Glasses](https://arxiv.org/abs/2211.10551)**|Accepted at CVPR2023|None|Jialiang Wang et al.|
|**2022-11-18**|**[Improving Pixel-Level Contrastive Learning by Leveraging Exogenous Depth Information](https://arxiv.org/abs/2211.10177)**|Accepted for WACV 2023|None|Ahmed Ben Saad et al.|
|**2022-11-16**|**[SelfOdom: Self-supervised Egomotion and Depth Learning via Bi-directional Coarse-to-Fine Scale Recovery](https://arxiv.org/abs/2211.08904)**|14 pages, 8 figures, in submission|None|Hao Qu et al.|
|**2022-11-16**|**[LightDepth: A Resource Efficient Depth Estimation Approach for Dealing with Ground Truth Sparsity via Curriculum Learning](https://arxiv.org/abs/2211.08608)**|13 pages, 4 figures|None|Fatemeh Karimi et al.|
|**2022-11-10**|**[Unifying Flow, Stereo and Depth Estimation](https://arxiv.org/abs/2211.05783)**|TPAMI 2023, Project Page: https://haofeixu.github.io/unimatch, Code: https://github.com/autonomousvision/unimatch, Demo: https://huggingface.co/spaces/haofeixu/unimatch|None|Haofei Xu et al.|
|**2022-11-07**|**[Efficient Single-Image Depth Estimation on Mobile Devices, Mobile AI & AIM 2022 Challenge: Report](https://arxiv.org/abs/2211.04470)**|arXiv admin note: substantial text overlap with arXiv:2105.08630, arXiv:2211.03885; text overlap with arXiv:2105.08819, arXiv:2105.08826, arXiv:2105.08629, arXiv:2105.07809, arXiv:2105.07825|None|Andrey Ignatov et al.|
|**2022-11-07**|**[SC-DepthV3: Robust Self-supervised Monocular Depth Estimation for Dynamic Scenes](https://arxiv.org/abs/2211.03660)**|Accepted for publication in TPAMI; The code will be available at https://github.com/JiawangBian/sc_depth_pl|None|Libo Sun et al.|
|**2022-11-04**|**[RCDPT: Radar-Camera fusion Dense Prediction Transformer](https://arxiv.org/abs/2211.02432)**|5 pages, 2 figures and 1 table, accepted to ICASSP2023|None|Chen-Chou Lo, Patrick Vandewalle|
|**2022-11-02**|**[OPA-3D: Occlusion-Aware Pixel-Wise Aggregation for Monocular 3D Object Detection](https://arxiv.org/abs/2211.01142)**|None|None|Yongzhi Su et al.|
|**2022-10-31**|**[Multi-Camera Calibration Free BEV Representation for 3D Object Detection](https://arxiv.org/abs/2210.17252)**|15 pages, 7 figures|None|Hongxiang Jiang et al.|
|**2022-10-29**|**[Boosting Monocular 3D Object Detection with Object-Centric Auxiliary Depth Supervision](https://arxiv.org/abs/2210.16574)**|Accepted by IEEE Transaction on Intelligent Transportation System (T-ITS)|None|Youngseok Kim et al.|
|**2022-10-28**|**[Matching entropy based disparity estimation from light field](https://arxiv.org/abs/2210.15948)**|None|None|Ligen Shi et al.|
|**2022-10-27**|**[Robust Monocular Localization of Drones by Adapting Domain Maps to Depth Prediction Inaccuracies](https://arxiv.org/abs/2210.15559)**|None|None|Priyesh Shukla et al.|
|**2022-10-27**|**[2T-UNET: A Two-Tower UNet with Depth Clues for Robust Stereo Depth Estimation](https://arxiv.org/abs/2210.15374)**|None|None|Rohit Choudhary et al.|
|**2022-10-23**|**[Photo-realistic Neural Domain Randomization](https://arxiv.org/abs/2210.12682)**|Accepted to European Conference on Computer Vision (ECCV), 2022|None|Sergey Zakharov et al.|
|**2022-10-21**|**[Context-Enhanced Stereo Transformer](https://arxiv.org/abs/2210.11719)**|Accepted by ECCV2022|None|Weiyu Guo et al.|
|**2022-10-19**|**[CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View Completion](https://arxiv.org/abs/2210.10716)**|NeurIPS 2022|None|Philippe Weinzaepfel et al.|
|**2022-10-18**|**[Hierarchical Normalization for Robust Monocular Depth Estimation](https://arxiv.org/abs/2210.09670)**|Accepted to NeurIPS 2022|None|Chi Zhang et al.|
|**2022-10-17**|**[Attention Attention Everywhere: Monocular Depth Prediction with Skip Attention](https://arxiv.org/abs/2210.09071)**|Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023|None|Ashutosh Agarwal, Chetan Arora|
|**2022-10-14**|**[MonoDVPS: A Self-Supervised Monocular Depth Estimation Approach to Depth-aware Video Panoptic Segmentation](https://arxiv.org/abs/2210.07577)**|WACV 2023|None|Andra Petrovai, Sergiu Nedevschi|
|**2022-10-13**|**[Composite Learning for Robust and Effective Dense Predictions](https://arxiv.org/abs/2210.07239)**|Winter Conference on Applications of Computer Vision (WACV), 2023|None|Menelaos Kanakis et al.|
|**2022-10-13**|**[MonoNeRF: Learning Generalizable NeRFs from Monocular Videos without Camera Pose](https://arxiv.org/abs/2210.07181)**|ICML 2023 camera ready version. Project page: https://oasisyang.github.io/mononerf|None|Yang Fu et al.|
|**2022-10-13**|**[Multi-Task Meta Learning: learn how to adapt to unseen tasks](https://arxiv.org/abs/2210.06989)**|None|None|Richa Upadhyay et al.|
|**2022-10-13**|**[Improving the Reliability for Confidence Estimation](https://arxiv.org/abs/2210.06776)**|Accepted by ECCV 2022|None|Haoxuan Qu et al.|
|**2022-10-11**|**[Frequency-Aware Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2210.05479)**|8 pages, 5 figures, published to WACV2023|None|Xingyu Chen et al.|
|**2022-10-08**|**[Detaching and Boosting: Dual Engine for Scale-Invariant Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2210.03952)**|Accepted by ICLR and IEEE Robotics and Automation Letters (RAL)|IEEE Robotics and Automation Letters 7.4 (2022): 12094-12101|Peizhe Jiang et al.|
|**2022-10-07**|**[IronDepth: Iterative Refinement of Single-View Depth using Surface Normal and its Uncertainty](https://arxiv.org/abs/2210.03676)**|BMVC 2022|None|Gwangbin Bae et al.|
|**2022-10-06**|**[Self-Supervised Monocular Depth Underwater](https://arxiv.org/abs/2210.03206)**|None|None|Shlomi Amitai et al.|
|**2022-10-06**|**[FloatingFusion: Depth from ToF and Image-stabilized Stereo Cameras](https://arxiv.org/abs/2210.02785)**|None|ECCV 2022, Part I, LNCS 13661|Andreas Meuleman et al.|
|**2022-10-05**|**[Depth Is All You Need for Monocular 3D Detection](https://arxiv.org/abs/2210.02493)**|None|None|Dennis Park et al.|
|**2022-10-05**|**[Image Masking for Robust Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2210.02357)**|Accepted at 2023 IEEE International Conference on Robotics and Automation (ICRA)|None|Hemang Chawla et al.|
|**2022-10-05**|**[MOTSLAM: MOT-assisted monocular dynamic SLAM using single-view depth estimation](https://arxiv.org/abs/2210.02038)**|None|None|Hanwei Zhang et al.|
|**2022-10-05**|**[Multi-Camera Collaborative Depth Prediction via Consistent Structure Estimation](https://arxiv.org/abs/2210.02009)**|None|None|Jialei Xu et al.|
|**2022-10-04**|**[PlaneDepth: Self-supervised Depth Estimation via Orthogonal Planes](https://arxiv.org/abs/2210.01612)**|Accepted by CVPR 2023. Code and models are available at: https://github.com/svip-lab/PlaneDepth|None|Ruoyu Wang et al.|
|**2022-10-04**|**[FreDSNet: Joint Monocular Depth and Semantic Segmentation with Fast Fourier Convolutions](https://arxiv.org/abs/2210.01595)**|7 pages, 5 figures, 3 tables|None|Bruno Berenguel-Baeta et al.|
|**2022-10-04**|**[Non-learning Stereo-aided Depth Completion under Mis-projection via Selective Stereo Matching](https://arxiv.org/abs/2210.01436)**|15 pages, 13 figures|in IEEE Access, vol. 9, pp. 136674-136686, 2021|Yasuhiro Yao et al.|
|**2022-10-03**|**[Probabilistic Volumetric Fusion for Dense Monocular SLAM](https://arxiv.org/abs/2210.01276)**|9 pages, 6 figures, 2 tables|None|Antoni Rosinol et al.|
|**2022-10-03**|**[Expediting Large-Scale Vision Transformer for Dense Prediction without Fine-tuning](https://arxiv.org/abs/2210.01035)**|Accepted at NeurIPS 2022, camera-ready version, 22 pages, 14 figures|None|Weicong Liang et al.|
|**2022-10-02**|**[Self-Supervised Monocular Depth Estimation: Solving the Edge-Fattening Problem](https://arxiv.org/abs/2210.00411)**|8 pages, 7 figures, published to WACV2023|None|Xingyu Chen et al.|
|**2022-09-29**|**[Lightweight Monocular Depth Estimation with an Edge Guided Network](https://arxiv.org/abs/2209.14829)**|None|None|Xingshuai Dong et al.|
|**2022-09-27**|**[Scalable and Equivariant Spherical CNNs by Discrete-Continuous (DISCO) Convolutions](https://arxiv.org/abs/2209.13603)**|19 pages, 7 figures, accepted by ICLR 2023|None|Jeremy Ocampo et al.|
|**2022-09-27**|**[Towards Multimodal Multitask Scene Understanding Models for Indoor Mobile Agents](https://arxiv.org/abs/2209.13156)**|Submitted to ICRA2023|None|Yao-Hung Hubert Tsai et al.|
|**2022-09-26**|**[SAPA: Similarity-Aware Point Affiliation for Feature Upsampling](https://arxiv.org/abs/2209.12866)**|Accepted to NeurIPS 2022. Code is available at https://github.com/poppinace/sapa|None|Hao Lu et al.|
|**2022-09-26**|**[DeepFusion: A Robust and Modular 3D Object Detector for Lidars, Cameras and Radars](https://arxiv.org/abs/2209.12729)**|None|None|Florian Drews et al.|
|**2022-09-26**|**[UDepth: Fast Monocular Depth Estimation for Visually-guided Underwater Robots](https://arxiv.org/abs/2209.12358)**|10 pages, 6 figures|None|Boxiao Yu et al.|
|**2022-09-23**|**[Image-to-Image Translation for Autonomous Driving from Coarsely-Aligned Image Pairs](https://arxiv.org/abs/2209.11673)**|Submitted to the International Conference on Robotics and Automation (ICRA) 2023|None|Youya Xia et al.|
|**2022-09-19**|**[3D-PL: Domain Adaptive Depth Estimation with 3D-aware Pseudo-Labeling](https://arxiv.org/abs/2209.09231)**|Accepted in ECCV 2022. Project page: https://ccc870206.github.io/3D-PL/|None|Yu-Ting Yen et al.|
|**2022-09-19**|**[On Robust Cross-View Consistency in Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2209.08747)**|None|Machine Intelligence Research 2024|Haimei Zhao et al.|
|**2022-09-18**|**[SF2SE3: Clustering Scene Flow into SE(3)-Motions via Proposal and Selection](https://arxiv.org/abs/2209.08532)**|German Conference on Pattern Recognition 2022, Konstanz, Germany|None|Leonhard Sommer et al.|
|**2022-09-18**|**[TODE-Trans: Transparent Object Depth Estimation with Transformer](https://arxiv.org/abs/2209.08455)**|Submitted to ICRA2023|None|Kang Chen et al.|
|**2022-09-15**|**[Self-distilled Feature Aggregation for Self-supervised Monocular Depth Estimation](https://arxiv.org/abs/2209.07088)**|Accepted to ECCV 2022|None|Zhengming Zhou, Qiulei Dong|
|**2022-09-14**|**[FCDSN-DC: An Accurate and Lightweight Convolutional Neural Network for Stereo Estimation with Depth Completion](https://arxiv.org/abs/2209.06525)**|None|None|Dominik Hirner, Friedrich Fraundorfer|
|**2022-09-14**|**[DevNet: Self-supervised Monocular Depth Learning via Density Volume Construction](https://arxiv.org/abs/2209.06351)**|Accepted by European Conference on Computer Vision 2022 (ECCV2022)|None|Kaichen Zhou et al.|
|**2022-09-13**|**[A Benchmark and a Baseline for Robust Multi-view Depth Estimation](https://arxiv.org/abs/2209.06681)**|Accepted at 3DV 2022|None|Philipp Schröppel et al.|
|**2022-09-12**|**[StructNeRF: Neural Radiance Fields for Indoor Scenes with Structural Hints](https://arxiv.org/abs/2209.05277)**|None|None|Zheng Chen et al.|
|**2022-09-07**|**[BiFuse++: Self-supervised and Efficient Bi-projection Fusion for 360 Depth Estimation](https://arxiv.org/abs/2209.02952)**|Accepted in TPAMI 2022; Code: https://github.com/fuenwang/BiFusev2|None|Fu-En Wang et al.|
|**2022-09-03**|**[A comprehensive survey on recent deep learning-based methods applied to surgical data](https://arxiv.org/abs/2209.01435)**|This paper is to be submitted to International journal of computer vision|None|Mansoor Ali et al.|
|**2022-09-02**|**[LiteDepth: Digging into Fast and Accurate Depth Estimation on Mobile Devices](https://arxiv.org/abs/2209.00961)**|Accepted to European Conference on Computer Vision Workshop (ECCVW 2022)|None|Zhenyu Li et al.|
|**2022-08-31**|**[SimpleRecon: 3D Reconstruction Without 3D Convolutions](https://arxiv.org/abs/2208.14743)**|ECCV2022 version with improved timings. 14 pages + 5 pages of references|None|Mohamed Sayed et al.|
|**2022-08-30**|**[Synthehicle: Multi-Vehicle Multi-Camera Tracking in Virtual Cities](https://arxiv.org/abs/2208.14167)**|None|None|Fabian Herzog et al.|
|**2022-08-29**|**[SphereDepth: Panorama Depth Estimation from Spherical Domain](https://arxiv.org/abs/2208.13714)**|Conference accept at 3DV 2022|None|Qingsong Yan et al.|
|**2022-08-29**|**[A Practical Calibration Method for RGB Micro-Grid Polarimetric Cameras](https://arxiv.org/abs/2208.13485)**|This is a preprint version of the paper to appear at IEEE Robotics and Automation Letters (RAL). The final journal version will be available at https://doi.org/10.1109/LRA.2022.3192655|Robotics and Automation Letters - Volume: 7 - Issue: 4 - October 2022 - Pages: 9921 - 9928|Joaquin Rodriguez et al.|
|**2022-08-29**|**[Rethinking Skip Connections in Encoder-decoder Networks for Monocular Depth Estimation](https://arxiv.org/abs/2208.13441)**|None|None|Zhitong Lai et al.|
|**2022-08-28**|**[Towards Accurate Reconstruction of 3D Scene Shape from A Single Monocular Image](https://arxiv.org/abs/2208.13241)**|20 pages. Journal version of the conference paper "Learning to Recover 3D Scene Shape from a Single Image". arXiv admin note: substantial text overlap with arXiv:2012.09365|None|Wei Yin et al.|
|**2022-08-27**|**[Neural Camera Models](https://arxiv.org/abs/2208.12903)**|PhD thesis|None|Igor Vasiljevic|
|**2022-08-26**|**[Uncertainty Guided Depth Fusion for Spike Camera](https://arxiv.org/abs/2208.12653)**|18 pages, 11 figures|None|Jianing Li et al.|
|**2022-08-26**|**[Unsupervised Spike Depth Estimation via Cross-modality Cross-domain Knowledge Transfer](https://arxiv.org/abs/2208.12527)**|Accepted by ICRA2024|None|Jiaming Liu et al.|
|**2022-08-26**|**[Dense Depth Distillation with Out-of-Distribution Simulated Images](https://arxiv.org/abs/2208.12464)**|None|None|Junjie Hu et al.|
|**2022-08-23**|**[DepthFake: a depth-based strategy for detecting Deepfake videos](https://arxiv.org/abs/2208.11074)**|2022 ICPR Workshop on Artificial Intelligence for Multimedia Forensics and Disinformation Detection|Springer 2022|Luca Maiano et al.|
|**2022-08-23**|**[PIFu for the Real World: A Self-supervised Framework to Reconstruct Dressed Human from Single-view Images](https://arxiv.org/abs/2208.10769)**|CVM 2024|None|Zhangyang Xiong et al.|
|**2022-08-23**|**[Depth Map Decomposition for Monocular Depth Estimation](https://arxiv.org/abs/2208.10762)**|None|None|Jinyoung Jun et al.|
|**2022-08-22**|**[Minimizing the Effect of Noise and Limited Dataset Size in Image Classification Using Depth Estimation as an Auxiliary Task with Deep Multitask Learning](https://arxiv.org/abs/2208.10390)**|None|None|Khashayar Namdar et al.|
|**2022-08-21**|**[Multi-task Learning for Monocular Depth and Defocus Estimations with Real Images](https://arxiv.org/abs/2208.09848)**|None|None|Renzhi He et al.|
|**2022-08-20**|**[Learning Sub-Pixel Disparity Distribution for Light Field Depth Estimation](https://arxiv.org/abs/2208.09688)**|Accepted by IEEE Transactions on Computational Imaging|None|Wentao Chao et al.|
|**2022-08-20**|**[Net2Brain: A Toolbox to compare artificial vision models with human brain responses](https://arxiv.org/abs/2208.09677)**|4 Pages, 3 figures, submitted and accepted to CCNeuro 2022. For associated repository, see https://github.com/ToastyDom/Net2Brain Update 1: Changed Citation|None|Domenic Bersch et al.|
|**2022-08-19**|**[MonoSIM: Simulating Learning Behaviors of Heterogeneous Point Cloud Object Detectors for Monocular 3D Object Detection](https://arxiv.org/abs/2208.09446)**|None|None|Han Sun et al.|
|**2022-08-19**|**[Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning](https://arxiv.org/abs/2208.09170)**|code: https://github.com/JeffWang987/MOVEDepth|None|Xiaofeng Wang et al.|
|**2022-08-17**|**[Self-Supervised Depth Estimation in Laparoscopic Image using 3D Geometric Consistency](https://arxiv.org/abs/2208.08407)**|Accepted by MICCAI2022|None|Baoru Huang et al.|
|**2022-08-16**|**[Rain Removal from Light Field Images with 4D Convolution and Multi-scale Gaussian Process](https://arxiv.org/abs/2208.07735)**|This paper has been published on IEEE Transactions on Image Processing|IEEE Transactions on Image Processing (2023), v32, pages 921-936|Tao Yan et al.|
|**2022-08-06**|**[MonoViT: Self-Supervised Monocular Depth Estimation with a Vision Transformer](https://arxiv.org/abs/2208.03543)**|Accepted by 3DV 2022|None|Chaoqiang Zhao et al.|
|**2022-08-03**|**[Gradient-based Uncertainty for Monocular Depth Estimation](https://arxiv.org/abs/2208.02005)**|Accepted to ECCV 2022|None|Julia Hornauer, Vasileios Belagiannis|
|**2022-08-03**|**[Neural Contourlet Network for Monocular 360 Depth Estimation](https://arxiv.org/abs/2208.01817)**|IEEE Transactions on Circuits and Systems for Video Technology|None|Zhijie Shen et al.|
|**2022-08-02**|**[Deconstructing Self-Supervised Monocular Reconstruction: The Design Decisions that Matter](https://arxiv.org/abs/2208.01489)**|https://github.com/jspenmar/monodepth_benchmark|Transactions of Machine Learning Research 2022|Jaime Spencer et al.|
|**2022-08-01**|**[Ithaca365: Dataset and Driving Perception under Repeated and Challenging Weather Conditions](https://arxiv.org/abs/2208.01166)**|Accepted by CVPR 2022|None|Carlos A. Diaz-Ruiz et al.|
|**2022-07-31**|**[Less is More: Consistent Video Depth Estimation with Masked Frames Modeling](https://arxiv.org/abs/2208.00380)**|Accepted by ACM MM 2022|None|Yiran Wang et al.|
|**2022-07-30**|**[Learning Feature Decomposition for Domain Adaptive Monocular Depth Estimation](https://arxiv.org/abs/2208.00160)**|Accepted at IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022|None|Shao-Yuan Lo et al.|
|**2022-07-28**|**[Depth Field Networks for Generalizable Multi-view Scene Representation](https://arxiv.org/abs/2207.14287)**|Accepted to ECCV 2022. Project page: https://sites.google.com/view/tri-define|None|Vitor Guizilini et al.|
|**2022-07-26**|**[Monocular 3D Object Detection with Depth from Motion](https://arxiv.org/abs/2207.12988)**|ECCV 2022 Oral|None|Tai Wang et al.|
|**2022-07-25**|**[Cost Volume Pyramid Network with Multi-strategies Range Searching for Multi-view Stereo](https://arxiv.org/abs/2207.12032)**|Accepted by CGI2022|None|Shiyu Gao et al.|
|**2022-07-25**|**[RA-Depth: Resolution Adaptive Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2207.11984)**|Accepted to ECCV'22|None|Mu He et al.|
|**2022-07-21**|**[DEVIANT: Depth EquiVarIAnt NeTwork for Monocular 3D Object Detection](https://arxiv.org/abs/2207.10758)**|ECCV 2022|None|Abhinav Kumar et al.|
|**2022-07-20**|**[Latent Discriminant deterministic Uncertainty](https://arxiv.org/abs/2207.10130)**|24 pages. Accepted at ECCV 2022|None|Gianni Franchi et al.|
|**2022-07-20**|**[Densely Constrained Depth Estimator for Monocular 3D Object Detection](https://arxiv.org/abs/2207.10047)**|Accepted by ECCV2022|None|Yingyan Li et al.|
|**2022-07-20**|**[Learning Depth from Focus in the Wild](https://arxiv.org/abs/2207.09658)**|None|None|Changyeon Won, Hae-Gon Jeon|
|**2022-07-18**|**[MonoIndoor++:Towards Better Practice of Self-Supervised Monocular Depth Estimation for Indoor Environments](https://arxiv.org/abs/2207.08951)**|Journal version of "MonoIndoor: Towards Good Practice of Self-Supervised Monocular Depth Estimation for Indoor Environments"(ICCV-2021). arXiv admin note: substantial text overlap with arXiv:2107.12429|None|Runze Li et al.|
|**2022-07-18**|**[DID-M3D: Decoupling Instance Depth for Monocular 3D Object Detection](https://arxiv.org/abs/2207.08531)**|ECCV 2022|None|Liang Peng et al.|
|**2022-07-16**|**[DiffuStereo: High Quality Human Reconstruction via Diffusion-based Stereo Using Sparse Cameras](https://arxiv.org/abs/2207.08000)**|Accepted by ECCV2022|None|Ruizhi Shao et al.|
|**2022-07-16**|**[Mutual Adaptive Reasoning for Monocular 3D Multi-Person Pose Estimation](https://arxiv.org/abs/2207.07900)**|Accepted by ACM MM 2022|None|Juze Zhang et al.|
|**2022-07-16**|**[JPerceiver: Joint Perception Network for Depth, Pose and Layout Estimation in Driving Scenes](https://arxiv.org/abs/2207.07895)**|Accepted by ECCV 2022|None|Haimei Zhao et al.|
|**2022-07-14**|**[Adversarial Attacks on Monocular Pose Estimation](https://arxiv.org/abs/2207.07032)**|Accepted at the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)|None|Hemang Chawla et al.|
|**2022-07-14**|**[BayesCap: Bayesian Identity Cap for Calibrated Uncertainty in Frozen Neural Networks](https://arxiv.org/abs/2207.06873)**|Accepted at ECCV 2022. Code is available at https://github.com/ExplainableML/BayesCap|None|Uddeshya Upadhyay et al.|
|**2022-07-13**|**[Joint Prediction of Monocular Depth and Structure using Planar and Parallax Geometry](https://arxiv.org/abs/2207.06351)**|Pattern Recognition, May 2022|None|Hao Xing et al.|
|**2022-07-13**|**[Robust and accurate depth estimation by fusing LiDAR and Stereo](https://arxiv.org/abs/2207.06139)**|None|Meas. Sci. Technol. 34 125107 (2023)|Guangyao Xu et al.|
|**2022-07-11**|**[Hybrid Skip: A Biologically Inspired Skip Connection for the UNet Architecture](https://arxiv.org/abs/2207.04721)**|Project page at https://vcl3d.github.io/HybridSkip/|IEEE Access, Volume 10, 53928 - 53939, 17 May 2022|Nikolaos Zioulis et al.|
|**2022-07-11**|**[Physical Attack on Monocular Depth Estimation with Optimal Adversarial Patches](https://arxiv.org/abs/2207.04718)**|ECCV2022|None|Zhiyuan Cheng et al.|
|**2022-07-10**|**[Depth Perspective-aware Multiple Object Tracking](https://arxiv.org/abs/2207.04551)**|In review PR journal|None|Kha Gia Quach et al.|
|**2022-07-10**|**[Depthformer : Multiscale Vision Transformer For Monocular Depth Estimation With Local Global Information Fusion](https://arxiv.org/abs/2207.04535)**|None|International Conference on Image Processing (ICIP), 2022|Ashutosh Agarwal, Chetan Arora|
|**2022-07-09**|**[Direct Handheld Burst Imaging to Simulated Defocus](https://arxiv.org/abs/2207.04175)**|ICIP 2022|None|Meng-Lin Wu et al.|
|**2022-07-08**|**[BlindSpotNet: Seeing Where We Cannot See](https://arxiv.org/abs/2207.03870)**|None|None|Taichi Fukuda et al.|
|**2022-07-07**|**[False Negative Reduction in Semantic Segmentation under Domain Shift using Depth Estimation](https://arxiv.org/abs/2207.03513)**|None|None|Kira Maag, Matthias Rottmann|
|**2022-07-07**|**[DRL-ISP: Multi-Objective Camera ISP with Deep Reinforcement Learning](https://arxiv.org/abs/2207.03081)**|Accepted by IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022 (*First two authors are equal contributed)|None|Ukcheol Shin et al.|
|**2022-07-06**|**[Network Binarization via Contrastive Learning](https://arxiv.org/abs/2207.02970)**|Accepted to ECCV 2022|None|Yuzhang Shang et al.|
|**2022-07-06**|**[Gaze-Vergence-Controlled See-Through Vision in Augmented Reality](https://arxiv.org/abs/2207.02645)**|11 papges, 13 figures|None|Zhimin Wang et al.|
|**2022-07-05**|**[Multiview Detection with Cardboard Human Modeling](https://arxiv.org/abs/2207.02013)**|None|None|Jiahao Ma et al.|
|**2022-07-03**|**[Beyond Visual Field of View: Perceiving 3D Environment with Echoes and Vision](https://arxiv.org/abs/2207.01136)**|None|None|Lingyu Zhu et al.|
|**2022-07-03**|**[Can Language Understand Depth?](https://arxiv.org/abs/2207.01077)**|None|ACM Multimedia 2022 (Brave New Idea)|Renrui Zhang et al.|
|**2022-07-01**|**[How Far Can I Go ? : A Self-Supervised Approach for Deterministic Video Depth Forecasting](https://arxiv.org/abs/2207.00506)**|Accepted in ML4AD Workshop, NeurIPS 2021|None|Sauradip Nag et al.|
|**2022-07-01**|**[Recovering Detail in 3D Shapes Using Disparity Maps](https://arxiv.org/abs/2207.00182)**|None|None|Marissa Ramirez de Chanlatte et al.|
|**2022-06-28**|**[Accurate and Real-time Pseudo Lidar Detection: Is Stereo Neural Network Really Necessary?](https://arxiv.org/abs/2206.13858)**|None|None|Haitao Meng et al.|
|**2022-06-27**|**[LaRa: Latents and Rays for Multi-Camera Bird's-Eye-View Semantic Segmentation](https://arxiv.org/abs/2206.13294)**|None|CoRL 2022 https://openreview.net/forum?id=abd_D-iVjk0|Florent Bartoccioni et al.|
|**2022-06-27**|**[Monocular Depth Decomposition of Semi-Transparent Volume Renderings](https://arxiv.org/abs/2206.13282)**|accepted at IEEE TVCG 2023|None|Dominik Engel et al.|
|**2022-06-27**|**[MGNet: Monocular Geometric Scene Understanding for Autonomous Driving](https://arxiv.org/abs/2206.13199)**|None|Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021, pp. 15784-15795|Markus Schön et al.|
|**2022-06-24**|**[Ev-NeRF: Event Based Neural Radiance Field](https://arxiv.org/abs/2206.12455)**|Accepted to WACV 2023|None|Inwoo Hwang et al.|
|**2022-06-23**|**[Learning Viewpoint-Agnostic Visual Representations by Recovering Tokens in 3D Space](https://arxiv.org/abs/2206.11895)**|NeurIPS 2022. Our code is at https://github.com/elicassion/3DTRL Our project page is at https://www3.cs.stonybrook.edu/~jishang/3dtrl/3dtrl.html v3, v4 for minor updates on figures and visualizations|None|Jinghuan Shang et al.|
|**2022-06-22**|**[Monocular Spherical Depth Estimation with Explicitly Connected Weak Layout Cues](https://arxiv.org/abs/2206.11358)**|Project page at https://vcl3d.github.io/ExplicitLayoutDepth/|ISPRS Journal of Photogrammetry and Remote Sensing, Volume 183, January 2022, Pages 269-285|Nikolaos Zioulis et al.|
|**2022-06-22**|**[A High Resolution Multi-exposure Stereoscopic Image & Video Database of Natural Scenes](https://arxiv.org/abs/2206.11095)**|None|None|Rohit Choudhary et al.|
|**2022-06-21**|**[Semantics-Depth-Symbiosis: Deeply Coupled Semi-Supervised Learning of Semantics and Depth](https://arxiv.org/abs/2206.10562)**|None|None|Nitin Bansal et al.|
|**2022-06-21**|**[MEStereo-Du2CNN: A Novel Dual Channel CNN for Learning Robust Depth Estimates from Multi-exposure Stereo Images for HDR 3D Applications](https://arxiv.org/abs/2206.10375)**|None|None|Rohit Choudhary et al.|
|**2022-06-21**|**[BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection](https://arxiv.org/abs/2206.10092)**|Accepted by AAAI2023|None|Yinhao Li et al.|
|**2022-06-18**|**[Analysis & Computational Complexity Reduction of Monocular and Stereo Depth Estimation Techniques](https://arxiv.org/abs/2206.09071)**|None|None|Rajeev Patwari, Varo Ly|
|**2022-06-17**|**[Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks](https://arxiv.org/abs/2206.08916)**|None|None|Jiasen Lu et al.|
|**2022-06-17**|**[Colonoscopy 3D Video Dataset with Paired Depth from 2D-3D Registration](https://arxiv.org/abs/2206.08903)**|None|None|Taylor L. Bobrow et al.|
|**2022-06-15**|**[LET-3D-AP: Longitudinal Error Tolerant 3D Average Precision for Camera-Only 3D Detection](https://arxiv.org/abs/2206.07705)**|Find the primary metrics for the 2022 Waymo Open Dataset 3D Camera-Only Detection Challenge at https://waymo.com/open/challenges/2022/3d-camera-only-detection/ . Find the code at https://github.com/waymo-research/waymo-open-dataset|None|Wei-Chih Hung et al.|
|**2022-06-15**|**[MonoGround: Detecting Monocular 3D Objects from the Ground](https://arxiv.org/abs/2206.07372)**|CVPR22|None|Zequn Qin, Xi Li|
|**2022-06-14**|**[TriHorn-Net: A Model for Accurate Depth-Based 3D Hand Pose Estimation](https://arxiv.org/abs/2206.07117)**|None|None|Mohammad Rezaei et al.|
|**2022-06-08**|**[Learning Ego 3D Representation as Ray Tracing](https://arxiv.org/abs/2206.04042)**|ECCV 2022. Code is available at https://github.com/fudan-zvg/Ego3RT|None|Jiachen Lu et al.|
|**2022-06-08**|**[Dyna-DM: Dynamic Object-aware Self-supervised Monocular Depth Maps](https://arxiv.org/abs/2206.03799)**|None|None|Kieran Saunders et al.|
|**2022-06-08**|**[Unsupervised Learning of 3D Scene Flow from Monocular Camera](https://arxiv.org/abs/2206.03673)**|ICRA2021|2021 IEEE International Conference on Robotics and Automation (ICRA)|Guangming Wang et al.|
|**2022-06-08**|**[Depth Estimation Matters Most: Improving Per-Object Depth Estimation for Monocular 3D Detection and Tracking](https://arxiv.org/abs/2206.03666)**|None|ICRA2022|Longlong Jing et al.|
|**2022-06-08**|**[Delving into the Pre-training Paradigm of Monocular 3D Object Detection](https://arxiv.org/abs/2206.03657)**|None|None|Zhuoling Li et al.|
|**2022-06-07**|**[Layered Depth Refinement with Mask Guidance](https://arxiv.org/abs/2206.03048)**|Accepted to CVPR 2022 (camera-ready version)|None|Soo Ye Kim et al.|
|**2022-06-01**|**[PanopticDepth: A Unified Framework for Depth-aware Panoptic Segmentation](https://arxiv.org/abs/2206.00468)**|CVPR2022|None|Naiyu Gao et al.|
|**2022-05-30**|**[Self-Supervised Pre-training of Vision Transformers for Dense Prediction Tasks](https://arxiv.org/abs/2205.15173)**|None|None|Jaonary Rabarisoa et al.|
|**2022-05-30**|**[Learnable Patchmatch and Self-Teaching for Multi-Frame Depth Estimation in Monocular Endoscopy](https://arxiv.org/abs/2205.15034)**|14 pages|None|Shuwei Shao et al.|
|**2022-05-28**|**[RIAV-MVS: Recurrent-Indexing an Asymmetric Volume for Multi-View Stereo](https://arxiv.org/abs/2205.14320)**|CVPR 2023. Code link added|None|Changjiang Cai et al.|
|**2022-05-26**|**[Revealing the Dark Secrets of Masked Image Modeling](https://arxiv.org/abs/2205.13543)**|None|None|Zhenda Xie et al.|
|**2022-05-24**|**[Wavelet Feature Maps Compression for Image-to-Image CNNs](https://arxiv.org/abs/2205.12268)**|None|None|Shahaf E. Finder et al.|
|**2022-05-24**|**[Single-View View Synthesis in the Wild with Learned Adaptive Multiplane Images](https://arxiv.org/abs/2205.11733)**|ACM SIGGRAPH 2022. Project page: https://yxuhan.github.io/AdaMPI/|None|Yuxuan Han et al.|
|**2022-05-23**|**[Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2205.11083)**|Accepted to AAAI 2023|None|Jinwoo Bae et al.|
|**2022-05-20**|**[Self-Supervised Depth Estimation with Isometric-Self-Sample-Based Learning](https://arxiv.org/abs/2205.10006)**|None|None|Geonho Cha et al.|
|**2022-05-19**|**[Diversity Matters: Fully Exploiting Depth Clues for Reliable Monocular 3D Object Detection](https://arxiv.org/abs/2205.09373)**|This paper has been accepted as an oral presentation of CVPR2022|None|Zhuoling Li et al.|
|**2022-05-18**|**[Positional Information is All You Need: A Novel Pipeline for Self-Supervised SVDE from Videos](https://arxiv.org/abs/2205.08851)**|None|None|Juan Luis Gonzalez Bello et al.|
|**2022-05-18**|**[Visual Attention-based Self-supervised Absolute Depth Estimation using Geometric Priors in Autonomous Driving](https://arxiv.org/abs/2205.08780)**|Published on IEEE Robotics and Automation Letters (RA-L)|IEEE Robotics and Automation Letters, vol. 7, no. 4, pp. 11998-12005, Oct. 2022|Jie Xiang et al.|
|**2022-05-18**|**[Learning Monocular Depth Estimation via Selective Distillation of Stereo Knowledge](https://arxiv.org/abs/2205.08668)**|None|None|Kyeongseob Song, Kuk-Jin Yoon|
|**2022-05-17**|**[MulT: An End-to-End Multitask Learning Transformer](https://arxiv.org/abs/2205.08303)**|Accepted to CVPR 2022|None|Deblina Bhattacharjee et al.|
|**2022-05-17**|**[Efficient Stereo Depth Estimation for Pseudo LiDAR: A Self-Supervised Approach Based on Multi-Input ResNet Encoder](https://arxiv.org/abs/2205.08089)**|9 pages, 5 figures|None|Sabir Hossain, Xianke Lin|
|**2022-05-11**|**[Review on Panoramic Imaging and Its Applications in Scene Understanding](https://arxiv.org/abs/2205.05570)**|Accepted to IEEE Transactions on Instrumentation and Measurement. 34 pages, 15 figures, 420 references|None|Shaohua Gao et al.|
|**2022-05-09**|**[Is my Depth Ground-Truth Good Enough? HAMMER -- Highly Accurate Multi-Modal Dataset for DEnse 3D Scene Regression](https://arxiv.org/abs/2205.04565)**|None|None|HyunJun Jung et al.|
|**2022-05-05**|**[FisheyeDistill: Self-Supervised Monocular Depth Estimation with Ordinal Distillation for Fisheye Cameras](https://arxiv.org/abs/2205.02930)**|None|None|Qingan Yan et al.|
|**2022-05-05**|**[Exploiting Correspondences with All-pairs Correlations for Multi-view Depth Estimation](https://arxiv.org/abs/2205.02481)**|10 pages, 9 figures|None|Kai Cheng et al.|
|**2022-05-03**|**[3D Semantic Scene Perception using Distributed Smart Edge Sensors](https://arxiv.org/abs/2205.01460)**|17th International Conference on Intelligent Autonomous Systems (IAS), Zagreb, Croatia, June 2022|None|Simon Bultmann, Sven Behnke|
|**2022-05-03**|**[Outdoor Monocular Depth Estimation: A Research Review](https://arxiv.org/abs/2205.01399)**|None|None|Pulkit Vyas et al.|
|**2022-05-02**|**[MUTR3D: A Multi-camera Tracking Framework via 3D-to-2D Queries](https://arxiv.org/abs/2205.00613)**|Appear on CVPR 2022 Workshop on Autonomous Driving|None|Tianyuan Zhang et al.|
|**2022-04-30**|**[Unsupervised Visible-light Images Guided Cross-Spectrum Depth Estimation from Dual-Modality Cameras](https://arxiv.org/abs/2205.00257)**|None|None|Yubin Guo et al.|
|**2022-04-29**|**[SideRT: A Real-time Pure Transformer Architecture for Single Image Depth Estimation](https://arxiv.org/abs/2204.13892)**|7 pages, 5 figures|None|Chang Shu et al.|
|**2022-04-28**|**[Depth Estimation with Simplified Transformer](https://arxiv.org/abs/2204.13791)**|Accepted for the CVPR 2022 Transformers For Vision (T4V) workshop|None|John Yang et al.|
|**2022-04-28**|**[Semi-MoreGAN: A New Semi-supervised Generative Adversarial Network for Mixture of Rain Removal](https://arxiv.org/abs/2204.13420)**|18 pages|None|Yiyang Shen et al.|
|**2022-04-24**|**[Simulating Fluids in Real-World Still Images](https://arxiv.org/abs/2204.11335)**|Technical Report, 19 pages, 17 figures, project page: https://slr-sfs.github.io/ code: https://github.com/simon3dv/SLR-SFS|None|Siming Fan et al.|
|**2022-04-24**|**[RealNet: Combining Optimized Object Detection with Information Fusion Depth Estimation Co-Design Method on IoT](https://arxiv.org/abs/2204.11216)**|None|None|Zhuohao Li et al.|
|**2022-04-23**|**[Investigating Neural Architectures by Synthetic Dataset Design](https://arxiv.org/abs/2204.11045)**|Accepted at the VDU2022 workshop hosted at CVPR2022|None|Adrien Courtois et al.|
|**2022-04-21**|**[Monocular Depth Estimation Using Cues Inspired by Biological Vision Systems](https://arxiv.org/abs/2204.10384)**|7 pages, 2 figures. Accepted to International Conference on Pattern Recognition (ICPR) 2022. Code available at https://github.com/DylanAuty/MDE-biological-vision-systems|None|Dylan Auty, Krystian Mikolajczyk|
|**2022-04-19**|**[Photometric single-view dense 3D reconstruction in endoscopy](https://arxiv.org/abs/2204.09083)**|7 pages, 7 figures, submitted to IROS 2022|None|Victor M. Batlle et al.|
|**2022-04-18**|**[Cylin-Painting: Seamless {360\textdegree} Panoramic Image Outpainting and Beyond](https://arxiv.org/abs/2204.08563)**|None|None|Kang Liao et al.|
|**2022-04-15**|**[Multi-Frame Self-Supervised Depth with Transformers](https://arxiv.org/abs/2204.07616)**|Accepted to CVPR 2022 (correct project page)|None|Vitor Guizilini et al.|
|**2022-04-15**|**[MVSTER: Epipolar Transformer for Efficient Multi-View Stereo](https://arxiv.org/abs/2204.07346)**|Code: https://github.com/JeffWang987/MVSTER|None|Xiaofeng Wang et al.|
|**2022-04-14**|**[Joint Forecasting of Panoptic Segmentations with Difference Attention](https://arxiv.org/abs/2204.07157)**|Accepted by CVPR 2022 (Oral)|None|Colin Graber et al.|
|**2022-04-13**|**[Does depth estimation help object detection?](https://arxiv.org/abs/2204.06512)**|Accepted to Image and Vision Computing|None|Bedrettin Cetinkaya et al.|
|**2022-04-11**|**[HiMODE: A Hybrid Monocular Omnidirectional Depth Estimation Model](https://arxiv.org/abs/2204.05007)**|IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2022)|None|Masum Shah Junayed et al.|
|**2022-04-07**|**[SurroundDepth: Entangling Surrounding Views for Self-Supervised Multi-Camera Depth Estimation](https://arxiv.org/abs/2204.03636)**|Accepted to CoRL 2022. Project page: https://surrounddepth.ivg-research.xyz Code: https://github.com/weiyithu/SurroundDepth|None|Yi Wei et al.|
|**2022-04-07**|**[Task-Aware Active Learning for Endoscopic Image Analysis](https://arxiv.org/abs/2204.03440)**|None|None|Shrawan Kumar Thapa et al.|
|**2022-04-05**|**[Depth-Guided Sparse Structure-from-Motion for Movies and TV Shows](https://arxiv.org/abs/2204.02509)**|None|None|Sheng Liu et al.|
|**2022-04-05**|**[Pyramid Frequency Network with Spatial Attention Residual Refinement Module for Monocular Depth Estimation](https://arxiv.org/abs/2204.02386)**|None|None|Zhengyang Lu, Ying Chen|
|**2022-04-05**|**[P3Depth: Monocular Depth Estimation with a Piecewise Planarity Prior](https://arxiv.org/abs/2204.02091)**|Accepted at CVPR 2022|None|Vaishakh Patil et al.|
|**2022-04-04**|**[Monitoring social distancing with single image depth estimation](https://arxiv.org/abs/2204.01693)**|Accepted for pubblication on IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI)|None|Alessio Mingozzi et al.|
|**2022-04-04**|**[MultiMAE: Multi-modal Multi-task Masked Autoencoders](https://arxiv.org/abs/2204.01678)**|Project page at https://multimae.epfl.ch|None|Roman Bachmann et al.|
|**2022-04-04**|**[Improving Monocular Visual Odometry Using Learned Depth](https://arxiv.org/abs/2204.01268)**|None|None|Libo Sun et al.|
|**2022-04-03**|**[BinsFormer: Revisiting Adaptive Bins for Monocular Depth Estimation](https://arxiv.org/abs/2204.00987)**|None|None|Zhenyu Li et al.|
|**2022-03-31**|**[Casual 6-DoF: free-viewpoint panorama using a handheld 360 camera](https://arxiv.org/abs/2203.16756)**|12 pages, 13 figures|None|Rongsen Chen et al.|
|**2022-03-30**|**[Towards Multimodal Depth Estimation from Light Fields](https://arxiv.org/abs/2203.16542)**|None|None|Titus Leistner et al.|
|**2022-03-29**|**[Learning Structured Gaussians to Approximate Deep Ensembles](https://arxiv.org/abs/2203.15485)**|Accepted at CVPR 2022|None|Ivor J. A. Simpson et al.|
|**2022-03-29**|**[Light Field Depth Estimation via Stitched Epipolar Plane Images](https://arxiv.org/abs/2203.15201)**|16 pages|None|Ping Zhou et al.|
|**2022-03-29**|**[Self-Supervised Light Field Depth Estimation Using Epipolar Plane Images](https://arxiv.org/abs/2203.15171)**|None|3DV 2021: International Conference on 3D Vision|Kunyuan Li et al.|
|**2022-03-28**|**[LocalBins: Improving Depth Estimation by Learning Local Distributions](https://arxiv.org/abs/2203.15132)**|19 pages|None|Shariq Farooq Bhat et al.|
|**2022-03-28**|**[Learning Optical Flow, Depth, and Scene Flow without Real-World Labels](https://arxiv.org/abs/2203.15089)**|Accepted to RA-L + ICRA 2022 (correct project page)|None|Vitor Guizilini et al.|
|**2022-03-27**|**[DepthFormer: Exploiting Long-Range Correlation and Local Information for Accurate Monocular Depth Estimation](https://arxiv.org/abs/2203.14211)**|None|Machine Intelligence Research 2023|Zhenyu Li et al.|
|**2022-03-26**|**[Learn to Adapt for Monocular Depth Estimation](https://arxiv.org/abs/2203.14005)**|None|None|Qiyu Sun et al.|
|**2022-03-26**|**[On the Viability of Monocular Depth Pre-training for Semantic Segmentation](https://arxiv.org/abs/2203.13987)**|None|None|Dong Lao et al.|
|**2022-03-24**|**[Unsupervised Simultaneous Learning for Camera Re-Localization and Depth Estimation from Video](https://arxiv.org/abs/2203.12804)**|8 pages, 6 figures|None|Shun Taguchi, Noriaki Hirose|
|**2022-03-23**|**[CroMo: Cross-Modal Learning for Monocular Depth Estimation](https://arxiv.org/abs/2203.12485)**|Accepted for publication at CVPR2022|None|Yannick Verdié et al.|
|**2022-03-21**|**[DiffPoseNet: Direct Differentiable Camera Pose Estimation](https://arxiv.org/abs/2203.11174)**|10 pages, 5 figures, Accepted to CVPR 2022|None|Chethan M. Parameshwara et al.|
|**2022-03-21**|**[MonoDTR: Monocular 3D Object Detection with Depth-Aware Transformer](https://arxiv.org/abs/2203.10981)**|Accepted to CVPR 2022|None|Kuan-Chih Huang et al.|
|**2022-03-21**|**[Learning Occlusion-Aware Coarse-to-Fine Depth Map for Self-supervised Monocular Depth Estimation](https://arxiv.org/abs/2203.10925)**|Accepted at ACM Multimedia 2022|None|Zhengming Zhou, Qiulei Dong|
|**2022-03-21**|**[Depth Completion using Geometry-Aware Embedding](https://arxiv.org/abs/2203.10912)**|Accepted by ICRA22|None|Wenchao Du et al.|
|**2022-03-20**|**[Depth Estimation by Combining Binocular Stereo and Monocular Structured-Light](https://arxiv.org/abs/2203.10493)**|CVPR 2022|None|Yuhua Xu et al.|
|**2022-03-18**|**[Semi-Supervised Learning with Mutual Distillation for Monocular Depth Estimation](https://arxiv.org/abs/2203.09737)**|None|IEEE Conference on Robotics and Automation (ICRA) 2022|Jongbeom Baek et al.|
|**2022-03-18**|**[Distortion-Tolerant Monocular Depth Estimation On Omnidirectional Images Using Dual-cubemap](https://arxiv.org/abs/2203.09733)**|Accepted by ICME2021, poster|None|Zhijie Shen et al.|
|**2022-03-17**|**[PanoFormer: Panorama Transformer for Indoor 360 Depth Estimation](https://arxiv.org/abs/2203.09283)**|Accepted to ECCV2022|None|Zhijie Shen et al.|
|**2022-03-16**|**[MonoJSG: Joint Semantic and Geometric Cost Volume for Monocular 3D Object Detection](https://arxiv.org/abs/2203.08563)**|Accepted to CVPR 2022|None|Qing Lian et al.|
|**2022-03-10**|**[SelfTune: Metrically Scaled Monocular Depth Estimation through Self-Supervised Learning](https://arxiv.org/abs/2203.05332)**|None|None|Jaehoon Choi et al.|
|**2022-03-09**|**[Joint Learning of Salient Object Detection, Depth Estimation and Contour Extraction](https://arxiv.org/abs/2203.04895)**|Accepted by IEEE TIP|None|Xiaoqi Zhao et al.|
|**2022-03-09**|**[A high-precision self-supervised monocular visual odometry in foggy weather based on robust cycled generative adversarial networks and multi-task learning aided depth estimation](https://arxiv.org/abs/2203.04812)**|None|None|Xiuyuan Li et al.|
|**2022-03-09**|**[ChiTransformer:Towards Reliable Stereo from Cues](https://arxiv.org/abs/2203.04554)**|Published as a main conference paper at CVPR 2022|None|Qing Su, Shihao Ji|
|**2022-03-09**|**[Monocular Depth Distribution Alignment with Low Computation](https://arxiv.org/abs/2203.04538)**|Accepted by ICRA 2022|None|Fei Sheng et al.|
|**2022-03-08**|**[Lightweight Monocular Depth Estimation through Guided Decoding](https://arxiv.org/abs/2203.04206)**|Accepted to ICRA 2022|None|Michael Rudolph et al.|
|**2022-03-06**|**[Point Spread Function Estimation of Defocus](https://arxiv.org/abs/2203.02953)**|None|None|Renzhi He et al.|
|**2022-03-04**|**[Real-Time Hybrid Mapping of Populated Indoor Scenes using a Low-Cost Monocular UAV](https://arxiv.org/abs/2203.02453)**|Submitted to IROS 2022|None|Stuart Golodetz et al.|
|**2022-03-04**|**[Time-to-Label: Temporal Consistency for Self-Supervised Monocular 3D Object Detection](https://arxiv.org/abs/2203.02193)**|None|None|Issa Mouawad et al.|
|**2022-03-04**|**[PatchMVSNet: Patch-wise Unsupervised Multi-View Stereo for Weakly-Textured Surface Reconstruction](https://arxiv.org/abs/2203.02156)**|None|None|Haonan Dong, Jian Yao|
|**2022-03-04**|**[Pseudo-Stereo for Monocular 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2203.02112)**|Accepted to CVPR 2022|None|Yi-Nan Chen et al.|
|**2022-03-03**|**[Fast Neural Architecture Search for Lightweight Dense Prediction Networks](https://arxiv.org/abs/2203.01994)**|15 pages, 11 figures, 8 tables. arXiv admin note: substantial text overlap with arXiv:2108.11105|None|Lam Huynh et al.|
|**2022-03-03**|**[Occlusion-Aware Cost Constructor for Light Field Depth Estimation](https://arxiv.org/abs/2203.01576)**|Accepted to CVPR 2022|None|Yingqian Wang et al.|
|**2022-03-02**|**[MUAD: Multiple Uncertainties for Autonomous Driving, a benchmark for multiple uncertainty types and tasks](https://arxiv.org/abs/2203.01437)**|Accepted at BMVC 2022|None|Gianni Franchi et al.|
|**2022-03-02**|**[Detecting Adversarial Perturbations in Multi-Task Perception](https://arxiv.org/abs/2203.01177)**|Accepted at IROS 2022|None|Marvin Klingner et al.|
|**2022-03-02**|**[OmniFusion: 360 Monocular Depth Estimation via Geometry-Aware Fusion](https://arxiv.org/abs/2203.00838)**|CVPR 2022, accepted as Oral|None|Yuyan Li et al.|
|**2022-02-26**|**[How Much Depth Information can Radar Contribute to a Depth Estimation Model?](https://arxiv.org/abs/2202.13220)**|published on EI2023, 7 pages, 4 figures, 2 tables|None|Chen-Chou Lo, Patrick Vandewalle|
|**2022-02-26**|**[Uncertainty-Aware Deep Multi-View Photometric Stereo](https://arxiv.org/abs/2202.13071)**|Accepted for publication in IEEE/CVF CVPR 2022. (11 Pages, 6 Figures, 3 Tables)|None|Berk Kaya et al.|
|**2022-02-26**|**[Deep Depth from Focal Stack with Defocus Model for Camera-Setting Invariance](https://arxiv.org/abs/2202.13055)**|13 pages|None|Yuki Fujimura et al.|
|**2022-02-24**|**[Light Robust Monocular Depth Estimation For Outdoor Environment Via Monochrome And Color Camera Fusion](https://arxiv.org/abs/2202.12108)**|None|None|Hyeonsoo Jang et al.|

